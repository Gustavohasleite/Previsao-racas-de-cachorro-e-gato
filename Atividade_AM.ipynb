{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "be0RgROuaE0c"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import os, io, time\n",
        "\n",
        "os.chdir('/content/')\n",
        "try:\n",
        "  os.mkdir('Imagens', )\n",
        "except:\n",
        "  print('A pasta já existe.')\n",
        "os.chdir('./Imagens')\n",
        "os.listdir()\n",
        "uploaded_images = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage.io import imread, imshow\n",
        "from skimage.transform import resize\n",
        "from skimage.feature import hog\n",
        "\n",
        "hog_features_256_20 = []\n",
        "hog_features_256_16 = []\n",
        "hog_features_128_20 = []\n",
        "hog_features_128_16 = []\n",
        "\n",
        "for filename in uploaded_images.keys():\n",
        "    image = imread(filename)\n",
        "    image_resized = resize(image, (128, 128))\n",
        "    fd, hog_image = hog(image_resized, orientations=9, pixels_per_cell=(20, 20),\n",
        "                        cells_per_block=(2, 2), visualize=True, channel_axis=-1)\n",
        "    hog_features_128_20.append(fd)\n",
        "\n",
        "for filename in uploaded_images.keys():\n",
        "    image = imread(filename)\n",
        "    image_resized = resize(image, (128, 128))\n",
        "    fd, hog_image = hog(image_resized, orientations=9, pixels_per_cell=(16, 16),\n",
        "                        cells_per_block=(2, 2), visualize=True, channel_axis=-1)\n",
        "    hog_features_128_16.append(fd)"
      ],
      "metadata": {
        "id": "VDz6D41hcc1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for filename in uploaded_images.keys():\n",
        "    image = imread(filename)\n",
        "    image_resized = resize(image, (256, 256))\n",
        "    fd, hog_image = hog(image_resized, orientations=9, pixels_per_cell=(20, 20),\n",
        "                        cells_per_block=(2, 2), visualize=True, channel_axis=-1)\n",
        "    hog_features_256_20.append(fd)\n",
        "\n",
        "for filename in uploaded_images.keys():\n",
        "    image = imread(filename)\n",
        "    image_resized = resize(image, (256, 256))\n",
        "    fd, hog_image = hog(image_resized, orientations=9, pixels_per_cell=(16, 16),\n",
        "                        cells_per_block=(2, 2), visualize=True, channel_axis=-1)\n",
        "    hog_features_256_16.append(fd)"
      ],
      "metadata": {
        "id": "yv5F5AaIc18Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "labels = []\n",
        "filenames = list(uploaded_images.keys())\n",
        "\n",
        "for filename in filenames:\n",
        "    filename_lower = filename.lower()\n",
        "    if 'american_bulldog' in filename_lower or 'american bulldog' in filename_lower:\n",
        "        labels.append('American_Bulldog')\n",
        "    elif 'bengal' in filename_lower:\n",
        "        labels.append('Bengal')\n",
        "    elif 'pug' in filename_lower:\n",
        "        labels.append('Pug')\n",
        "    elif 'ragdoll' in filename_lower:\n",
        "        labels.append('Ragdoll')\n",
        "    else:\n",
        "        labels.append('unknown')\n",
        "        print(f\"Arquivo não identificado: {filename}\")\n",
        "\n",
        "print(f\"Total de imagens: {len(filenames)}\")\n",
        "print(f\"Labels criados: {len(labels)}\")\n",
        "\n",
        "df_128_20 = pd.DataFrame(hog_features_128_20)\n",
        "df_128_20['label'] = labels\n",
        "df_128_20['filename'] = filenames\n",
        "\n",
        "df_128_16 = pd.DataFrame(hog_features_128_16)\n",
        "df_128_16['label'] = labels\n",
        "df_128_16['filename'] = filenames\n",
        "\n",
        "df_256_20 = pd.DataFrame(hog_features_256_20)\n",
        "df_256_20['label'] = labels\n",
        "df_256_20['filename'] = filenames\n",
        "\n",
        "df_256_16 = pd.DataFrame(hog_features_256_16)\n",
        "df_256_16['label'] = labels\n",
        "df_256_16['filename'] = filenames\n",
        "\n",
        "df_128_20.to_csv('dataset_128x128_cells_20x20.csv', index=False)\n",
        "df_128_16.to_csv('dataset_128x128_cells_16x16.csv', index=False)\n",
        "df_256_20.to_csv('dataset_256x256_cells_20x20.csv', index=False)\n",
        "df_256_16.to_csv('dataset_256x256_cells_16x16.csv', index=False)\n",
        "\n",
        "print(\"Datasets salvos em CSV:\")\n",
        "print(\"- dataset_128x128_cells_20x20.csv\")\n",
        "print(\"- dataset_128x128_cells_16x16.csv\")\n",
        "print(\"- dataset_256x256_cells_20x20.csv\")\n",
        "print(\"- dataset_256x256_cells_16x16.csv\")\n",
        "\n",
        "print(f\"\\nDistribuição das raças:\")\n",
        "print(f\"American Bulldog: {labels.count('American_Bulldog')}\")\n",
        "print(f\"Bengal: {labels.count('Bengal')}\")\n",
        "print(f\"Pug: {labels.count('Pug')}\")\n",
        "print(f\"Ragdoll: {labels.count('Ragdoll')}\")\n",
        "print(f\"Não identificados: {labels.count('unknown')}\")\n",
        "\n",
        "print(f\"\\nInformações dos datasets:\")\n",
        "print(f\"Dataset 128x128 (20x20): {df_128_20.shape}\")\n",
        "print(f\"Dataset 128x128 (16x16): {df_128_16.shape}\")\n",
        "print(f\"Dataset 256x256 (20x20): {df_256_20.shape}\")\n",
        "print(f\"Dataset 256x256 (16x16): {df_256_16.shape}\")\n",
        "\n",
        "# Download dos arquivos CSV (no Google Colab)\n",
        "#from google.colab import files\n",
        "#files.download('dataset_128x128_cells_20x20.csv')\n",
        "#files.download('dataset_128x128_cells_16x16.csv')\n",
        "#files.download('dataset_256x256_cells_20x20.csv')\n",
        "#files.download('dataset_256x256_cells_16x16.csv')"
      ],
      "metadata": {
        "id": "7mZRGgHVe85r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from skimage.io import imread\n",
        "from skimage.transform import resize\n",
        "from tensorflow.keras.applications import VGG16, VGG19\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input as preprocess_vgg16\n",
        "from tensorflow.keras.applications.vgg19 import preprocess_input as preprocess_vgg19\n",
        "from tensorflow.keras.utils import img_to_array\n",
        "import time\n",
        "import os\n",
        "\n",
        "# Gerar rótulos e nomes de arquivos uma única vez\n",
        "print(\"1. Criando rótulos a partir dos nomes dos arquivos...\")\n",
        "filenames = list(uploaded_images.keys())\n",
        "labels = []\n",
        "\n",
        "for filename in filenames:\n",
        "    filename_lower = filename.lower()\n",
        "    if 'american_bulldog' in filename_lower or 'american bulldog' in filename_lower:\n",
        "        labels.append('American_Bulldog')\n",
        "    elif 'bengal' in filename_lower:\n",
        "        labels.append('Bengal')\n",
        "    elif 'pug' in filename_lower:\n",
        "        labels.append('Pug')\n",
        "    elif 'ragdoll' in filename_lower:\n",
        "        labels.append('Ragdoll')\n",
        "    else:\n",
        "        labels.append('unknown')\n",
        "\n",
        "print(f\"Total de {len(filenames)} imagens e {len(labels)} rótulos gerados.\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "\n",
        "# Definir as configurações para a extração\n",
        "configurations = [\n",
        "    {'model_name': 'VGG16', 'model_func': VGG16, 'preprocess': preprocess_vgg16, 'pooling': 'avg'},\n",
        "    {'model_name': 'VGG16', 'model_func': VGG16, 'preprocess': preprocess_vgg16, 'pooling': 'max'},\n",
        "    {'model_name': 'VGG19', 'model_func': VGG19, 'preprocess': preprocess_vgg19, 'pooling': 'avg'},\n",
        "    {'model_name': 'VGG19', 'model_func': VGG19, 'preprocess': preprocess_vgg19, 'pooling': 'max'},\n",
        "]\n",
        "\n",
        "image_sizes = [(128, 128), (256, 256)]\n",
        "all_datasets_info = {}\n",
        "\n",
        "# Loop principal para extração de características\n",
        "for config in configurations:\n",
        "    print(f\"Processando com: Modelo={config['model_name']}, Pooling={config['pooling']}\")\n",
        "\n",
        "    # Carregar o modelo base\n",
        "    model = config['model_func'](weights='imagenet', include_top=False, pooling=config['pooling'])\n",
        "\n",
        "    for size in image_sizes:\n",
        "        start_time = time.time()\n",
        "        cnn_features = []\n",
        "        image_height, image_width = size\n",
        "\n",
        "        print(f\"  > Redimensionando para {image_height}x{image_width} pixels...\")\n",
        "\n",
        "        for filename in filenames:\n",
        "            # Carregar e pré-processar a imagem\n",
        "            image = imread(filename)\n",
        "\n",
        "            image_resized = resize(image, (image_height, image_width))\n",
        "            x = img_to_array(image_resized) * 255.0\n",
        "            x = np.expand_dims(x, axis=0)\n",
        "            x = config['preprocess'](x)\n",
        "\n",
        "            # Extrair, achatar e adicionar características\n",
        "            features = model.predict(x, verbose=0)\n",
        "            cnn_features.append(features.flatten())\n",
        "\n",
        "        # Criar DataFrame e salvar em CSV\n",
        "        df = pd.DataFrame(cnn_features)\n",
        "        df['label'] = labels\n",
        "        df['filename'] = filenames\n",
        "\n",
        "        csv_filename = f\"dataset_{config['model_name'].lower()}_{config['pooling']}_{image_height}x{image_width}.csv\"\n",
        "        df.to_csv(csv_filename, index=False)\n",
        "\n",
        "        all_datasets_info[csv_filename] = df.shape\n",
        "        end_time = time.time()\n",
        "\n",
        "        print(f\"    - Concluído em {end_time - start_time:.2f} segundos. Dataset salvo como '{csv_filename}'\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"RELATÓRIO FINAL DA EXTRAÇÃO\")\n",
        "print(\"=\"*50)\n",
        "print(\"Todos os 8 datasets foram gerados com sucesso:\\n\")\n",
        "\n",
        "for name, shape in all_datasets_info.items():\n",
        "    print(f\"- Arquivo: {name}, Dimensões: {shape[0]} amostras, {shape[1]} colunas (features + label + filename)\")\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "print(\"\\nIniciando o download dos arquivos CSV...\")\n",
        "for filename in all_datasets_info.keys():\n",
        "  files.download(filename)\n",
        "print(\"Download concluído.\")"
      ],
      "metadata": {
        "id": "avmfhwKbg-oM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import cross_val_score, train_test_split, StratifiedKFold\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"Carregando os 12 datasets...\")\n",
        "\n",
        "# --- Datasets HOG (4 bases) ---\n",
        "df_hog_128_16 = pd.read_csv('dataset_128x128_cells_16x16.csv')\n",
        "df_hog_128_20 = pd.read_csv('dataset_128x128_cells_20x20.csv')\n",
        "df_hog_256_16 = pd.read_csv('dataset_256x256_cells_16x16.csv')\n",
        "df_hog_256_20 = pd.read_csv('dataset_256x256_cells_20x20.csv')\n",
        "\n",
        "# --- Datasets CNN VGG16 (4 bases) ---\n",
        "df_vgg16_128_avg = pd.read_csv('dataset_vgg16_avg_128x128.csv')\n",
        "df_vgg16_128_max = pd.read_csv('dataset_vgg16_max_128x128.csv')\n",
        "df_vgg16_256_avg = pd.read_csv('dataset_vgg16_avg_256x256.csv')\n",
        "df_vgg16_256_max = pd.read_csv('dataset_vgg16_max_256x256.csv')\n",
        "\n",
        "# --- Datasets CNN VGG19 (4 bases) ---\n",
        "df_vgg19_128_avg = pd.read_csv('dataset_vgg19_avg_128x128.csv')\n",
        "df_vgg19_128_max = pd.read_csv('dataset_vgg19_max_128x128.csv')\n",
        "df_vgg19_256_avg = pd.read_csv('dataset_vgg19_avg_256x256.csv')\n",
        "df_vgg19_256_max = pd.read_csv('dataset_vgg19_max_256x256.csv')\n",
        "\n",
        "datasets = {\n",
        "    'HOG_128_16x16': df_hog_128_16,\n",
        "    'HOG_128_20x20': df_hog_128_20,\n",
        "    'HOG_256_16x16': df_hog_256_16,\n",
        "    'HOG_256_20x20': df_hog_256_20,\n",
        "    'CNN_VGG16_128_avg': df_vgg16_128_avg,\n",
        "    'CNN_VGG16_128_max': df_vgg16_128_max,\n",
        "    'CNN_VGG16_256_avg': df_vgg16_256_avg,\n",
        "    'CNN_VGG16_256_max': df_vgg16_256_max,\n",
        "    'CNN_VGG19_128_avg': df_vgg19_128_avg,\n",
        "    'CNN_VGG19_128_max': df_vgg19_128_max,\n",
        "    'CNN_VGG19_256_avg': df_vgg19_256_avg,\n",
        "    'CNN_VGG19_256_max': df_vgg19_256_max\n",
        "}\n",
        "\n",
        "print(f\"Total de datasets carregados e prontos para o experimento: {len(datasets)}\")\n",
        "\n",
        "# FUNÇÃO PARA PREPARAR OS DADOS\n",
        "def prepare_data(df):\n",
        "    \"\"\"Prepara os dados separando features e labels\"\"\"\n",
        "    X = df.drop(['label', 'filename'], axis=1)\n",
        "    y = df['label']\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "    return X_scaled, y\n",
        "\n",
        "# EXECUTAR EXPERIMENTOS k-NN\n",
        "k_values = list(range(1, 11))  # k = 1 a 10\n",
        "results_table = []\n",
        "\n",
        "print(\"\\nIniciando experimentos k-NN...\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "for dataset_name, df in datasets.items():\n",
        "    print(f\"\\nProcessando: {dataset_name}\")\n",
        "    print(f\"Shape: {df.shape}\")\n",
        "\n",
        "    X, y = prepare_data(df)\n",
        "    n_features = X.shape[1]\n",
        "\n",
        "    row_70_30 = {'Base': f\"{dataset_name} ({n_features})\", 'Treino/Test': '70/30'}\n",
        "    row_10_fold = {'Base': '', 'Treino/Test': '10-fold CV'}\n",
        "\n",
        "    for k in k_values:\n",
        "        print(f\"  k={k}...\", end=\" \")\n",
        "        knn = KNeighborsClassifier(n_neighbors=k)\n",
        "\n",
        "        # 70/30 Split\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=0.3, random_state=42, stratify=y\n",
        "        )\n",
        "        knn.fit(X_train, y_train)\n",
        "        y_pred = knn.predict(X_test)\n",
        "        accuracy_70_30 = accuracy_score(y_test, y_pred)\n",
        "\n",
        "        # 10-fold Cross Validation\n",
        "        cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "        cv_scores = cross_val_score(knn, X, y, cv=cv, scoring='accuracy')\n",
        "        accuracy_10_fold = cv_scores.mean()\n",
        "\n",
        "        row_70_30[f'k={k}'] = round(accuracy_70_30, 4)\n",
        "        row_10_fold[f'k={k}'] = round(accuracy_10_fold, 4)\n",
        "        print(f\"70/30: {accuracy_70_30:.4f}, 10-fold: {accuracy_10_fold:.4f}\")\n",
        "\n",
        "    results_table.append(row_70_30)\n",
        "    results_table.append(row_10_fold)\n",
        "\n",
        "# CRIAR DATAFRAME DOS RESULTADOS\n",
        "df_results = pd.DataFrame(results_table)\n",
        "columns_order = ['Base', 'Treino/Test'] + [f'k={k}' for k in k_values]\n",
        "df_results = df_results[columns_order]\n",
        "\n",
        "# CALCULAR MÉDIA E DESVIO PADRÃO\n",
        "print(\"\\nCalculando média e desvio padrão para cada coluna k...\")\n",
        "results_70_30 = df_results[df_results['Treino/Test'] == '70/30'].copy()\n",
        "results_10_fold = df_results[df_results['Treino/Test'] == '10-fold CV'].copy()\n",
        "\n",
        "# Preparando as linhas de estatísticas\n",
        "stats_rows = []\n",
        "k_cols = [f'k={k}' for k in k_values]\n",
        "\n",
        "# Processa estatísticas para 70/30\n",
        "mean_70_30 = results_70_30[k_cols].mean()\n",
        "std_70_30 = results_70_30[k_cols].std()\n",
        "stats_rows.append({col: '' for col in columns_order}) # Linha em branco\n",
        "stats_rows.append({'Base': 'Média (70/30)', 'Treino/Test': '=>', **mean_70_30.round(4)})\n",
        "stats_rows.append({'Base': 'Desv. Pad. (70/30)', 'Treino/Test': '=>', **std_70_30.round(4)})\n",
        "\n",
        "# Processa estatísticas para 10-fold\n",
        "mean_10_fold = results_10_fold[k_cols].mean()\n",
        "std_10_fold = results_10_fold[k_cols].std()\n",
        "stats_rows.append({col: '' for col in columns_order}) # Linha em branco\n",
        "stats_rows.append({'Base': 'Média (10-fold CV)', 'Treino/Test': '=>', **mean_10_fold.round(4)})\n",
        "stats_rows.append({'Base': 'Desv. Pad. (10-fold CV)', 'Treino/Test': '=>', **std_10_fold.round(4)})\n",
        "\n",
        "# Concatenar resultados originais com as estatísticas\n",
        "df_final = pd.concat([df_results, pd.DataFrame(stats_rows)], ignore_index=True)\n",
        "\n",
        "# EXIBIR E SALVAR RESULTADOS\n",
        "print(\"\\n\" + \"=\"*120)\n",
        "print(\"TABELA DE RESULTADOS k-NN (Acurácia)\")\n",
        "print(\"=\"*120)\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "print(df_final.to_string(index=False))\n",
        "\n",
        "df_final.to_csv('resultados_knn_experimentos_12_bases.csv', index=False)\n",
        "print(f\"\\nResultados salvos em: resultados_knn_experimentos_12_bases.csv\")\n",
        "\n",
        "\n",
        "# ANÁLISE DOS MELHORES RESULTADOS\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"\\nANÁLISE DOS MELHORES RESULTADOS\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\nMelhores k por base e método:\")\n",
        "\n",
        "# Método 70/30\n",
        "print(\"\\nMétodo 70/30:\")\n",
        "for _, row in results_70_30.iterrows():\n",
        "    base_name = row['Base']\n",
        "    best_k_row = row[k_cols].astype(float).idxmax()\n",
        "    best_acc = row[best_k_row]\n",
        "    print(f\"{base_name}: Melhor {best_k_row} (Acurácia: {best_acc:.4f})\")\n",
        "\n",
        "# Método 10-fold\n",
        "print(\"\\nMétodo 10-fold:\")\n",
        "for _, row in results_10_fold.iterrows():\n",
        "    base_name = df_results.loc[row.name - 1, 'Base'] # Pega o nome da base da linha acima\n",
        "    best_k_row = row[k_cols].astype(float).idxmax()\n",
        "    best_acc = row[best_k_row]\n",
        "    print(f\"{base_name}: Melhor {best_k_row} (Acurácia: {best_acc:.4f})\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"TOP 6 MELHORES RESULTADOS GLOBAIS (Base, k, Validação)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Preparar dados para encontrar o top 6\n",
        "df_analysis = df_results.copy()\n",
        "df_analysis['Base'] = df_analysis['Base'].replace('', np.nan).ffill()\n",
        "df_analysis['Base'] = df_analysis['Base'].str.replace(r'\\s*\\(\\d+\\)', '', regex=True)\n",
        "df_analysis = df_analysis[~df_analysis['Base'].str.contains('=>', na=False)]\n",
        "\n",
        "melted_df = df_analysis.melt(\n",
        "    id_vars=['Base', 'Treino/Test'],\n",
        "    var_name='k',\n",
        "    value_name='Acurácia'\n",
        ")\n",
        "\n",
        "melted_df['Acurácia'] = pd.to_numeric(melted_df['Acurácia'], errors='coerce')\n",
        "melted_df.dropna(subset=['Acurácia'], inplace=True)\n",
        "melted_df['k'] = melted_df['k'].str.replace('k=', '').astype(int)\n",
        "\n",
        "top_6_results = melted_df.sort_values(by='Acurácia', ascending=False).head(6)\n",
        "\n",
        "print(\"As 6 melhores combinações de (Base de Dados, k, Validação) foram:\\n\")\n",
        "top_6_results.index = np.arange(1, len(top_6_results) + 1)\n",
        "print(top_6_results.to_string())\n"
      ],
      "metadata": {
        "id": "I6efNjT5t_cx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de658cbb-a0be-4894-bb18-534024a218a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Carregando os 12 datasets...\n",
            "Total de datasets carregados e prontos para o experimento: 12\n",
            "\n",
            "Iniciando experimentos k-NN...\n",
            "================================================================================\n",
            "\n",
            "Processando: HOG_128_16x16\n",
            "Shape: (800, 1766)\n",
            "  k=1... 70/30: 0.4333, 10-fold: 0.4012\n",
            "  k=2... 70/30: 0.4167, 10-fold: 0.3762\n",
            "  k=3... 70/30: 0.4375, 10-fold: 0.4075\n",
            "  k=4... 70/30: 0.4042, 10-fold: 0.3950\n",
            "  k=5... 70/30: 0.4000, 10-fold: 0.3963\n",
            "  k=6... 70/30: 0.4125, 10-fold: 0.4188\n",
            "  k=7... 70/30: 0.4167, 10-fold: 0.4100\n",
            "  k=8... 70/30: 0.3917, 10-fold: 0.3950\n",
            "  k=9... 70/30: 0.3875, 10-fold: 0.4050\n",
            "  k=10... 70/30: 0.3875, 10-fold: 0.3937\n",
            "\n",
            "Processando: HOG_128_20x20\n",
            "Shape: (800, 902)\n",
            "  k=1... 70/30: 0.4333, 10-fold: 0.4263\n",
            "  k=2... 70/30: 0.4125, 10-fold: 0.3962\n",
            "  k=3... 70/30: 0.4500, 10-fold: 0.4300\n",
            "  k=4... 70/30: 0.4583, 10-fold: 0.4338\n",
            "  k=5... 70/30: 0.4583, 10-fold: 0.4300\n",
            "  k=6... 70/30: 0.4500, 10-fold: 0.4475\n",
            "  k=7... 70/30: 0.4625, 10-fold: 0.4562\n",
            "  k=8... 70/30: 0.4625, 10-fold: 0.4562\n",
            "  k=9... 70/30: 0.4625, 10-fold: 0.4650\n",
            "  k=10... 70/30: 0.4625, 10-fold: 0.4588\n",
            "\n",
            "Processando: HOG_256_16x16\n",
            "Shape: (800, 8102)\n",
            "  k=1... 70/30: 0.2750, 10-fold: 0.3025\n",
            "  k=2... 70/30: 0.2875, 10-fold: 0.2838\n",
            "  k=3... 70/30: 0.3042, 10-fold: 0.2887\n",
            "  k=4... 70/30: 0.3208, 10-fold: 0.3212\n",
            "  k=5... 70/30: 0.3125, 10-fold: 0.3100\n",
            "  k=6... 70/30: 0.3042, 10-fold: 0.3163\n",
            "  k=7... 70/30: 0.3167, 10-fold: 0.3187\n",
            "  k=8... 70/30: 0.3042, 10-fold: 0.3188\n",
            "  k=9... 70/30: 0.2958, 10-fold: 0.3175\n",
            "  k=10... 70/30: 0.2917, 10-fold: 0.3075\n",
            "\n",
            "Processando: HOG_256_20x20\n",
            "Shape: (800, 4358)\n",
            "  k=1... 70/30: 0.3542, 10-fold: 0.3450\n",
            "  k=2... 70/30: 0.3125, 10-fold: 0.3100\n",
            "  k=3... 70/30: 0.3542, 10-fold: 0.3350\n",
            "  k=4... 70/30: 0.3250, 10-fold: 0.3425\n",
            "  k=5... 70/30: 0.3083, 10-fold: 0.3400\n",
            "  k=6... 70/30: 0.3000, 10-fold: 0.3300\n",
            "  k=7... 70/30: 0.2958, 10-fold: 0.3450\n",
            "  k=8... 70/30: 0.3042, 10-fold: 0.3412\n",
            "  k=9... 70/30: 0.3000, 10-fold: 0.3413\n",
            "  k=10... 70/30: 0.3083, 10-fold: 0.3287\n",
            "\n",
            "Processando: CNN_VGG16_128_avg\n",
            "Shape: (800, 514)\n",
            "  k=1... 70/30: 0.8292, 10-fold: 0.8438\n",
            "  k=2... 70/30: 0.8542, 10-fold: 0.8588\n",
            "  k=3... 70/30: 0.8583, 10-fold: 0.8625\n",
            "  k=4... 70/30: 0.8958, 10-fold: 0.8788\n",
            "  k=5... 70/30: 0.8833, 10-fold: 0.8662\n",
            "  k=6... 70/30: 0.8917, 10-fold: 0.8662\n",
            "  k=7... 70/30: 0.8625, 10-fold: 0.8713\n",
            "  k=8... 70/30: 0.8792, 10-fold: 0.8713\n",
            "  k=9... 70/30: 0.8792, 10-fold: 0.8750\n",
            "  k=10... 70/30: 0.8750, 10-fold: 0.8787\n",
            "\n",
            "Processando: CNN_VGG16_128_max\n",
            "Shape: (800, 514)\n",
            "  k=1... 70/30: 0.8417, 10-fold: 0.8650\n",
            "  k=2... 70/30: 0.8708, 10-fold: 0.8775\n",
            "  k=3... 70/30: 0.8667, 10-fold: 0.8700\n",
            "  k=4... 70/30: 0.9000, 10-fold: 0.8812\n",
            "  k=5... 70/30: 0.8958, 10-fold: 0.8738\n",
            "  k=6... 70/30: 0.9167, 10-fold: 0.8888\n",
            "  k=7... 70/30: 0.9042, 10-fold: 0.8762\n",
            "  k=8... 70/30: 0.9042, 10-fold: 0.8938\n",
            "  k=9... 70/30: 0.9000, 10-fold: 0.8800\n",
            "  k=10... 70/30: 0.8958, 10-fold: 0.8925\n",
            "\n",
            "Processando: CNN_VGG16_256_avg\n",
            "Shape: (800, 514)\n",
            "  k=1... 70/30: 0.9083, 10-fold: 0.9313\n",
            "  k=2... 70/30: 0.9333, 10-fold: 0.9462\n",
            "  k=3... 70/30: 0.9292, 10-fold: 0.9412\n",
            "  k=4... 70/30: 0.9458, 10-fold: 0.9575\n",
            "  k=5... 70/30: 0.9417, 10-fold: 0.9387\n",
            "  k=6... 70/30: 0.9625, 10-fold: 0.9537\n",
            "  k=7... 70/30: 0.9625, 10-fold: 0.9450\n",
            "  k=8... 70/30: 0.9667, 10-fold: 0.9525\n",
            "  k=9... 70/30: 0.9625, 10-fold: 0.9512\n",
            "  k=10... 70/30: 0.9542, 10-fold: 0.9500\n",
            "\n",
            "Processando: CNN_VGG16_256_max\n",
            "Shape: (800, 514)\n",
            "  k=1... 70/30: 0.9417, 10-fold: 0.9525\n",
            "  k=2... 70/30: 0.9542, 10-fold: 0.9763\n",
            "  k=3... 70/30: 0.9583, 10-fold: 0.9637\n",
            "  k=4... 70/30: 0.9750, 10-fold: 0.9725\n",
            "  k=5... 70/30: 0.9375, 10-fold: 0.9612\n",
            "  k=6... 70/30: 0.9750, 10-fold: 0.9688\n",
            "  k=7... 70/30: 0.9542, 10-fold: 0.9625\n",
            "  k=8... 70/30: 0.9667, 10-fold: 0.9638\n",
            "  k=9... 70/30: 0.9625, 10-fold: 0.9600\n",
            "  k=10... 70/30: 0.9625, 10-fold: 0.9575\n",
            "\n",
            "Processando: CNN_VGG19_128_avg\n",
            "Shape: (800, 514)\n",
            "  k=1... 70/30: 0.8292, 10-fold: 0.8237\n",
            "  k=2... 70/30: 0.8375, 10-fold: 0.8562\n",
            "  k=3... 70/30: 0.8417, 10-fold: 0.8500\n",
            "  k=4... 70/30: 0.8667, 10-fold: 0.8725\n",
            "  k=5... 70/30: 0.8542, 10-fold: 0.8425\n",
            "  k=6... 70/30: 0.8500, 10-fold: 0.8487\n",
            "  k=7... 70/30: 0.8292, 10-fold: 0.8363\n",
            "  k=8... 70/30: 0.8542, 10-fold: 0.8313\n",
            "  k=9... 70/30: 0.8583, 10-fold: 0.8275\n",
            "  k=10... 70/30: 0.8542, 10-fold: 0.8313\n",
            "\n",
            "Processando: CNN_VGG19_128_max\n",
            "Shape: (800, 514)\n",
            "  k=1... 70/30: 0.8458, 10-fold: 0.8337\n",
            "  k=2... 70/30: 0.8458, 10-fold: 0.8563\n",
            "  k=3... 70/30: 0.8625, 10-fold: 0.8475\n",
            "  k=4... 70/30: 0.8833, 10-fold: 0.8688\n",
            "  k=5... 70/30: 0.8667, 10-fold: 0.8575\n",
            "  k=6... 70/30: 0.8833, 10-fold: 0.8700\n",
            "  k=7... 70/30: 0.8750, 10-fold: 0.8475\n",
            "  k=8... 70/30: 0.8708, 10-fold: 0.8575\n",
            "  k=9... 70/30: 0.8625, 10-fold: 0.8388\n",
            "  k=10... 70/30: 0.8667, 10-fold: 0.8450\n",
            "\n",
            "Processando: CNN_VGG19_256_avg\n",
            "Shape: (800, 514)\n",
            "  k=1... 70/30: 0.9125, 10-fold: 0.9350\n",
            "  k=2... 70/30: 0.9292, 10-fold: 0.9513\n",
            "  k=3... 70/30: 0.9208, 10-fold: 0.9437\n",
            "  k=4... 70/30: 0.9458, 10-fold: 0.9575\n",
            "  k=5... 70/30: 0.9417, 10-fold: 0.9512\n",
            "  k=6... 70/30: 0.9542, 10-fold: 0.9563\n",
            "  k=7... 70/30: 0.9375, 10-fold: 0.9450\n",
            "  k=8... 70/30: 0.9583, 10-fold: 0.9525\n",
            "  k=9... 70/30: 0.9542, 10-fold: 0.9500\n",
            "  k=10... 70/30: 0.9542, 10-fold: 0.9563\n",
            "\n",
            "Processando: CNN_VGG19_256_max\n",
            "Shape: (800, 514)\n",
            "  k=1... 70/30: 0.9417, 10-fold: 0.9575\n",
            "  k=2... 70/30: 0.9583, 10-fold: 0.9750\n",
            "  k=3... 70/30: 0.9333, 10-fold: 0.9512\n",
            "  k=4... 70/30: 0.9625, 10-fold: 0.9625\n",
            "  k=5... 70/30: 0.9625, 10-fold: 0.9575\n",
            "  k=6... 70/30: 0.9542, 10-fold: 0.9563\n",
            "  k=7... 70/30: 0.9417, 10-fold: 0.9525\n",
            "  k=8... 70/30: 0.9500, 10-fold: 0.9537\n",
            "  k=9... 70/30: 0.9417, 10-fold: 0.9500\n",
            "  k=10... 70/30: 0.9375, 10-fold: 0.9500\n",
            "\n",
            "Calculando média e desvio padrão para cada coluna k...\n",
            "\n",
            "========================================================================================================================\n",
            "TABELA DE RESULTADOS k-NN (Acurácia)\n",
            "========================================================================================================================\n",
            "                   Base Treino/Test     k=1     k=2     k=3     k=4     k=5     k=6     k=7     k=8     k=9    k=10\n",
            "   HOG_128_16x16 (1764)       70/30  0.4333  0.4167  0.4375  0.4042     0.4  0.4125  0.4167  0.3917  0.3875  0.3875\n",
            "                         10-fold CV  0.4012  0.3762  0.4075   0.395  0.3963  0.4188    0.41   0.395   0.405  0.3938\n",
            "    HOG_128_20x20 (900)       70/30  0.4333  0.4125    0.45  0.4583  0.4583    0.45  0.4625  0.4625  0.4625  0.4625\n",
            "                         10-fold CV  0.4262  0.3962    0.43  0.4338    0.43  0.4475  0.4562  0.4562   0.465  0.4588\n",
            "   HOG_256_16x16 (8100)       70/30   0.275  0.2875  0.3042  0.3208  0.3125  0.3042  0.3167  0.3042  0.2958  0.2917\n",
            "                         10-fold CV  0.3025  0.2838  0.2887  0.3212    0.31  0.3163  0.3188  0.3188  0.3175  0.3075\n",
            "   HOG_256_20x20 (4356)       70/30  0.3542  0.3125  0.3542   0.325  0.3083     0.3  0.2958  0.3042     0.3  0.3083\n",
            "                         10-fold CV   0.345    0.31   0.335  0.3425    0.34    0.33   0.345  0.3412  0.3413  0.3288\n",
            "CNN_VGG16_128_avg (512)       70/30  0.8292  0.8542  0.8583  0.8958  0.8833  0.8917  0.8625  0.8792  0.8792   0.875\n",
            "                         10-fold CV  0.8438  0.8588  0.8625  0.8788  0.8662  0.8662  0.8712  0.8712   0.875  0.8788\n",
            "CNN_VGG16_128_max (512)       70/30  0.8417  0.8708  0.8667     0.9  0.8958  0.9167  0.9042  0.9042     0.9  0.8958\n",
            "                         10-fold CV   0.865  0.8775    0.87  0.8812  0.8738  0.8888  0.8762  0.8938    0.88  0.8925\n",
            "CNN_VGG16_256_avg (512)       70/30  0.9083  0.9333  0.9292  0.9458  0.9417  0.9625  0.9625  0.9667  0.9625  0.9542\n",
            "                         10-fold CV  0.9312  0.9462  0.9412  0.9575  0.9388  0.9538   0.945  0.9525  0.9512    0.95\n",
            "CNN_VGG16_256_max (512)       70/30  0.9417  0.9542  0.9583   0.975  0.9375   0.975  0.9542  0.9667  0.9625  0.9625\n",
            "                         10-fold CV  0.9525  0.9762  0.9637  0.9725  0.9612  0.9688  0.9625  0.9638    0.96  0.9575\n",
            "CNN_VGG19_128_avg (512)       70/30  0.8292  0.8375  0.8417  0.8667  0.8542    0.85  0.8292  0.8542  0.8583  0.8542\n",
            "                         10-fold CV  0.8237  0.8562    0.85  0.8725  0.8425  0.8487  0.8362  0.8312  0.8275  0.8312\n",
            "CNN_VGG19_128_max (512)       70/30  0.8458  0.8458  0.8625  0.8833  0.8667  0.8833   0.875  0.8708  0.8625  0.8667\n",
            "                         10-fold CV  0.8338  0.8563  0.8475  0.8688  0.8575    0.87  0.8475  0.8575  0.8388   0.845\n",
            "CNN_VGG19_256_avg (512)       70/30  0.9125  0.9292  0.9208  0.9458  0.9417  0.9542  0.9375  0.9583  0.9542  0.9542\n",
            "                         10-fold CV   0.935  0.9513  0.9437  0.9575  0.9512  0.9562   0.945  0.9525    0.95  0.9562\n",
            "CNN_VGG19_256_max (512)       70/30  0.9417  0.9583  0.9333  0.9625  0.9625  0.9542  0.9417    0.95  0.9417  0.9375\n",
            "                         10-fold CV  0.9575   0.975  0.9512  0.9625  0.9575  0.9562  0.9525  0.9538    0.95    0.95\n",
            "                                                                                                                   \n",
            "          Média (70/30)          =>  0.7122  0.7177  0.7264  0.7403  0.7302  0.7379  0.7299  0.7344  0.7306  0.7292\n",
            "     Desv. Pad. (70/30)          =>   0.256  0.2715   0.256  0.2724  0.2708  0.2793  0.2697  0.2778  0.2781  0.2762\n",
            "                                                                                                                   \n",
            "     Média (10-fold CV)          =>  0.7181   0.722  0.7242   0.737  0.7271  0.7351  0.7305  0.7323  0.7301  0.7292\n",
            "Desv. Pad. (10-fold CV)          =>  0.2636  0.2857  0.2703  0.2726  0.2689  0.2687  0.2623   0.267   0.263  0.2693\n",
            "\n",
            "Resultados salvos em: resultados_knn_experimentos_12_bases.csv\n",
            "\n",
            "============================================================\n",
            "\n",
            "ANÁLISE DOS MELHORES RESULTADOS\n",
            "============================================================\n",
            "\n",
            "Melhores k por base e método:\n",
            "\n",
            "Método 70/30:\n",
            "HOG_128_16x16 (1764): Melhor k=3 (Acurácia: 0.4375)\n",
            "HOG_128_20x20 (900): Melhor k=7 (Acurácia: 0.4625)\n",
            "HOG_256_16x16 (8100): Melhor k=4 (Acurácia: 0.3208)\n",
            "HOG_256_20x20 (4356): Melhor k=1 (Acurácia: 0.3542)\n",
            "CNN_VGG16_128_avg (512): Melhor k=4 (Acurácia: 0.8958)\n",
            "CNN_VGG16_128_max (512): Melhor k=6 (Acurácia: 0.9167)\n",
            "CNN_VGG16_256_avg (512): Melhor k=8 (Acurácia: 0.9667)\n",
            "CNN_VGG16_256_max (512): Melhor k=4 (Acurácia: 0.9750)\n",
            "CNN_VGG19_128_avg (512): Melhor k=4 (Acurácia: 0.8667)\n",
            "CNN_VGG19_128_max (512): Melhor k=4 (Acurácia: 0.8833)\n",
            "CNN_VGG19_256_avg (512): Melhor k=8 (Acurácia: 0.9583)\n",
            "CNN_VGG19_256_max (512): Melhor k=4 (Acurácia: 0.9625)\n",
            "\n",
            "Método 10-fold:\n",
            "HOG_128_16x16 (1764): Melhor k=6 (Acurácia: 0.4188)\n",
            "HOG_128_20x20 (900): Melhor k=9 (Acurácia: 0.4650)\n",
            "HOG_256_16x16 (8100): Melhor k=4 (Acurácia: 0.3212)\n",
            "HOG_256_20x20 (4356): Melhor k=1 (Acurácia: 0.3450)\n",
            "CNN_VGG16_128_avg (512): Melhor k=4 (Acurácia: 0.8788)\n",
            "CNN_VGG16_128_max (512): Melhor k=8 (Acurácia: 0.8938)\n",
            "CNN_VGG16_256_avg (512): Melhor k=4 (Acurácia: 0.9575)\n",
            "CNN_VGG16_256_max (512): Melhor k=2 (Acurácia: 0.9762)\n",
            "CNN_VGG19_128_avg (512): Melhor k=4 (Acurácia: 0.8725)\n",
            "CNN_VGG19_128_max (512): Melhor k=6 (Acurácia: 0.8700)\n",
            "CNN_VGG19_256_avg (512): Melhor k=4 (Acurácia: 0.9575)\n",
            "CNN_VGG19_256_max (512): Melhor k=2 (Acurácia: 0.9750)\n",
            "\n",
            "================================================================================\n",
            "TOP 6 MELHORES RESULTADOS GLOBAIS (Base, k, Validação)\n",
            "================================================================================\n",
            "As 6 melhores combinações de (Base de Dados, k, Validação) foram:\n",
            "\n",
            "                Base Treino/Test  k  Acurácia\n",
            "1  CNN_VGG16_256_max  10-fold CV  2    0.9762\n",
            "2  CNN_VGG19_256_max  10-fold CV  2    0.9750\n",
            "3  CNN_VGG16_256_max       70/30  4    0.9750\n",
            "4  CNN_VGG16_256_max       70/30  6    0.9750\n",
            "5  CNN_VGG16_256_max  10-fold CV  4    0.9725\n",
            "6  CNN_VGG16_256_max  10-fold CV  6    0.9688\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('resultados_knn_experimentos_12_bases.csv')"
      ],
      "metadata": {
        "id": "C2XLXmpSGTXb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import cross_val_score, train_test_split, StratifiedKFold\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import accuracy_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# CARREGAR RESULTADOS ANTERIORES E IDENTIFICAR MELHORES/PIORES\n",
        "print(\"Analisando resultados anteriores...\")\n",
        "\n",
        "datasets_original = {\n",
        "    'HOG_128_16x16': pd.read_csv('dataset_128x128_cells_16x16.csv'),\n",
        "    'HOG_128_20x20': pd.read_csv('dataset_128x128_cells_20x20.csv'),\n",
        "    'HOG_256_16x16': pd.read_csv('dataset_256x256_cells_16x16.csv'),\n",
        "    'HOG_256_20x20': pd.read_csv('dataset_256x256_cells_20x20.csv'),\n",
        "    'CNN_VGG16_128_avg': pd.read_csv('dataset_vgg16_avg_128x128.csv'),\n",
        "    'CNN_VGG16_128_max': pd.read_csv('dataset_vgg16_max_128x128.csv'),\n",
        "    'CNN_VGG16_256_avg': pd.read_csv('dataset_vgg16_avg_256x256.csv'),\n",
        "    'CNN_VGG16_256_max': pd.read_csv('dataset_vgg16_max_256x256.csv'),\n",
        "    'CNN_VGG19_128_avg': pd.read_csv('dataset_vgg19_avg_128x128.csv'),\n",
        "    'CNN_VGG19_126_max': pd.read_csv('dataset_vgg19_max_128x128.csv'),\n",
        "    'CNN_VGG19_256_avg': pd.read_csv('dataset_vgg19_avg_256x256.csv'),\n",
        "    'CNN_VGG19_256_max': pd.read_csv('dataset_vgg19_max_256x256.csv')\n",
        "\n",
        "}\n",
        "\n",
        "def prepare_data(df):\n",
        "    X = df.drop(['label', 'filename'], axis=1)\n",
        "    y = df['label']\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "    return X_scaled, y\n",
        "\n",
        "# CALCULAR PERFORMANCE MÉDIA DE CADA BASE\n",
        "print(\"Calculando performance de cada base...\")\n",
        "\n",
        "base_performances = {}\n",
        "k_values = list(range(1, 11))\n",
        "\n",
        "for dataset_name, df in datasets_original.items():\n",
        "    print(f\"Avaliando: {dataset_name}\")\n",
        "    X, y = prepare_data(df)\n",
        "\n",
        "    total_accuracy = 0\n",
        "    count = 0\n",
        "\n",
        "    for k in k_values:\n",
        "        knn = KNeighborsClassifier(n_neighbors=k)\n",
        "\n",
        "        # 70/30 Split\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=0.3, random_state=42, stratify=y\n",
        "        )\n",
        "        knn.fit(X_train, y_train)\n",
        "        y_pred = knn.predict(X_test)\n",
        "        acc_70_30 = accuracy_score(y_test, y_pred)\n",
        "\n",
        "        # 10-fold CV\n",
        "        cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "        cv_scores = cross_val_score(knn, X, y, cv=cv, scoring='accuracy')\n",
        "        acc_10_fold = cv_scores.mean()\n",
        "\n",
        "        # Média das duas validações\n",
        "        avg_acc = (acc_70_30 + acc_10_fold) / 2\n",
        "        total_accuracy += avg_acc\n",
        "        count += 1\n",
        "\n",
        "    # Performance média da base\n",
        "    base_performances[dataset_name] = total_accuracy / count\n",
        "\n",
        "# IDENTIFICAR 6 MELHORES E 6 PIORES\n",
        "sorted_performances = sorted(base_performances.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "best_6 = [item[0] for item in sorted_performances[:6]]\n",
        "worst_6 = [item[0] for item in sorted_performances[-6:]]\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"RANKING DAS BASES\")\n",
        "print(\"=\"*60)\n",
        "for i, (base, performance) in enumerate(sorted_performances, 1):\n",
        "    status = \"MELHOR\" if base in best_6 else \"PIOR\" if base in worst_6 else \"\"\n",
        "    print(f\"{i:2d}. {base:<25} - {performance:.4f} {status}\")\n",
        "\n",
        "print(f\"\\n6 MELHORES BASES:\")\n",
        "for base in best_6:\n",
        "    print(f\"  - {base}\")\n",
        "\n",
        "print(f\"\\n6 PIORES BASES (serão substituídas):\")\n",
        "for base in worst_6:\n",
        "    print(f\"  - {base}\")\n",
        "\n",
        "# APLICAR PCA NAS 6 MELHORES BASES\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"APLICANDO PCA (10 componentes) NAS 6 MELHORES BASES\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "pca_datasets = {}\n",
        "\n",
        "for base_name in best_6:\n",
        "    print(f\"\\nProcessando PCA para: {base_name}\")\n",
        "\n",
        "    df_original = datasets_original[base_name]\n",
        "    X, y = prepare_data(df_original)\n",
        "\n",
        "    print(f\"  Dimensões originais: {X.shape}\")\n",
        "\n",
        "    # Aplicar PCA com 10 componentes\n",
        "    pca = PCA(n_components=10, random_state=42)\n",
        "    X_pca = pca.fit_transform(X)\n",
        "\n",
        "    print(f\"  Dimensões após PCA: {X_pca.shape}\")\n",
        "    print(f\"  Variância explicada: {pca.explained_variance_ratio_.sum():.4f}\")\n",
        "\n",
        "    # Criar novo dataset com PCA\n",
        "    df_pca = pd.DataFrame(X_pca, columns=[f'PC{i+1}' for i in range(10)])\n",
        "    df_pca['label'] = y.values\n",
        "    df_pca['filename'] = df_original['filename'].values\n",
        "\n",
        "    pca_name = f\"PCA_{base_name}\"\n",
        "    pca_datasets[pca_name] = df_pca\n",
        "\n",
        "    filename = f\"dataset_{pca_name}.csv\"\n",
        "    df_pca.to_csv(filename, index=False)\n",
        "    print(f\"  Dataset PCA salvo: {filename}\")\n",
        "\n",
        "# CRIAR NOVA CONFIGURAÇÃO DE DATASETS\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"CRIANDO NOVA CONFIGURAÇÃO DE DATASETS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "new_datasets = {}\n",
        "\n",
        "# Adicionar 6 melhores originais\n",
        "for base_name in best_6:\n",
        "    new_datasets[base_name] = datasets_original[base_name]\n",
        "\n",
        "for pca_name, pca_df in pca_datasets.items():\n",
        "    new_datasets[pca_name] = pca_df\n",
        "\n",
        "print(\"Nova configuração de datasets:\")\n",
        "for i, dataset_name in enumerate(new_datasets.keys(), 1):\n",
        "    dataset_type = \"ORIGINAL\" if not dataset_name.startswith(\"PCA_\") else \"PCA\"\n",
        "    print(f\"{i:2d}. {dataset_name:<35} - {dataset_type}\")\n",
        "\n",
        "# EXECUTAR NOVOS EXPERIMENTOS k-NN\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"EXECUTANDO NOVOS EXPERIMENTOS k-NN\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "new_results_table = []\n",
        "\n",
        "for dataset_name, df in new_datasets.items():\n",
        "    print(f\"\\nProcessando: {dataset_name}\")\n",
        "    print(f\"Shape: {df.shape}\")\n",
        "\n",
        "    X, y = prepare_data(df)\n",
        "\n",
        "    n_features = X.shape[1]\n",
        "\n",
        "    row_70_30 = {'Base': f\"{dataset_name} ({n_features})\", 'Treino/Test': '70/30'}\n",
        "    row_10_fold = {'Base': '', 'Treino/Test': '10-fold CV'}\n",
        "\n",
        "    for k in k_values:\n",
        "        print(f\"  k={k}...\", end=\" \")\n",
        "\n",
        "        knn = KNeighborsClassifier(n_neighbors=k)\n",
        "\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=0.3, random_state=42, stratify=y\n",
        "        )\n",
        "\n",
        "        knn.fit(X_train, y_train)\n",
        "        y_pred = knn.predict(X_test)\n",
        "        accuracy_70_30 = accuracy_score(y_test, y_pred)\n",
        "\n",
        "        cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "        cv_scores = cross_val_score(knn, X, y, cv=cv, scoring='accuracy')\n",
        "        accuracy_10_fold = cv_scores.mean()\n",
        "\n",
        "        row_70_30[f'k={k}'] = round(accuracy_70_30, 4)\n",
        "        row_10_fold[f'k={k}'] = round(accuracy_10_fold, 4)\n",
        "\n",
        "        print(f\"70/30: {accuracy_70_30:.4f}, 10-fold: {accuracy_10_fold:.4f}\")\n",
        "\n",
        "    new_results_table.append(row_70_30)\n",
        "    new_results_table.append(row_10_fold)\n",
        "\n",
        "# CRIAR NOVA TABELA DE RESULTADOS\n",
        "df_new_results = pd.DataFrame(new_results_table)\n",
        "columns_order = ['Base', 'Treino/Test'] + [f'k={k}' for k in k_values]\n",
        "df_new_results = df_new_results[columns_order]\n",
        "\n",
        "# CALCULAR NOVAS ESTATÍSTICAS\n",
        "print(\"\\nCalculando novas estatísticas...\")\n",
        "\n",
        "new_results_70_30 = df_new_results[df_new_results['Treino/Test'] == '70/30'].copy()\n",
        "new_results_10_fold = df_new_results[df_new_results['Treino/Test'] == '10-fold CV'].copy()\n",
        "\n",
        "new_stats_70_30 = {'Base': 'Média =>', 'Treino/Test': ''}\n",
        "new_stats_std_70_30 = {'Base': 'Desv. Pad. =>', 'Treino/Test': ''}\n",
        "new_stats_10_fold = {'Base': 'Média =>', 'Treino/Test': ''}\n",
        "new_stats_std_10_fold = {'Base': 'Desv. Pad. =>', 'Treino/Test': ''}\n",
        "\n",
        "for k in k_values:\n",
        "    k_col = f'k={k}'\n",
        "\n",
        "    # 70/30 stats\n",
        "    values_70_30 = new_results_70_30[k_col].dropna()\n",
        "    mean_70_30 = values_70_30.mean()\n",
        "    std_70_30 = values_70_30.std()\n",
        "\n",
        "    new_stats_70_30[k_col] = f\"{mean_70_30:.4f}\"\n",
        "    new_stats_std_70_30[k_col] = f\"{std_70_30:.4f}\"\n",
        "\n",
        "    # 10-fold stats\n",
        "    values_10_fold = new_results_10_fold[k_col].dropna()\n",
        "    mean_10_fold = values_10_fold.mean()\n",
        "    std_10_fold = values_10_fold.std()\n",
        "\n",
        "    new_stats_10_fold[k_col] = f\"{mean_10_fold:.4f}\"\n",
        "    new_stats_std_10_fold[k_col] = f\"{std_10_fold:.4f}\"\n",
        "\n",
        "# CRIAR TABELA FINAL COM ESTATÍSTICAS\n",
        "new_final_results = df_new_results.to_dict('records')\n",
        "\n",
        "new_final_results.append({col: '' for col in columns_order})\n",
        "\n",
        "new_final_results.append(new_stats_70_30)\n",
        "new_final_results.append(new_stats_std_70_30)\n",
        "\n",
        "new_final_results.append({col: '' for col in columns_order})\n",
        "\n",
        "new_final_results.append(new_stats_10_fold)\n",
        "new_final_results.append(new_stats_std_10_fold)\n",
        "\n",
        "df_new_final = pd.DataFrame(new_final_results)\n",
        "\n",
        "# EXIBIR E SALVAR NOVOS RESULTADOS\n",
        "print(\"\\n\" + \"=\"*120)\n",
        "print(\"NOVA TABELA DE RESULTADOS k-NN (6 MELHORES + 6 PCA)\")\n",
        "print(\"=\"*120)\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)\n",
        "print(df_new_final.to_string(index=False))\n",
        "\n",
        "# Salvar resultados\n",
        "df_new_final.to_csv('resultados_knn_com_pca.csv', index=False)\n",
        "print(f\"\\nNovos resultados salvos em: resultados_knn_com_pca.csv\")\n",
        "\n",
        "# COMPARAÇÃO ANTES E DEPOIS\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"COMPARAÇÃO DE PERFORMANCE\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Calcular performance média antes e depois\n",
        "old_mean_70_30 = new_results_70_30[[f'k={k}' for k in k_values[:6]]].mean().mean()  # Primeiros 6 (originais)\n",
        "old_mean_10_fold = new_results_10_fold[[f'k={k}' for k in k_values[:6]]].mean().mean()\n",
        "\n",
        "new_mean_70_30 = new_results_70_30[[f'k={k}' for k in k_values[6:]]].mean().mean()  # Últimos 6 (PCA)\n",
        "new_mean_10_fold = new_results_10_fold[[f'k={k}' for k in k_values[6:]]].mean().mean()\n",
        "\n",
        "print(f\"Performance média das bases originais mantidas:\")\n",
        "print(f\"  70/30: {old_mean_70_30:.4f}\")\n",
        "print(f\"  10-fold: {old_mean_10_fold:.4f}\")\n",
        "\n",
        "print(f\"\\nPerformance média das novas bases PCA:\")\n",
        "print(f\"  70/30: {new_mean_70_30:.4f}\")\n",
        "print(f\"  10-fold: {new_mean_10_fold:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"EXPERIMENTOS COM PCA CONCLUÍDOS!\")\n",
        "print(\"Arquivos gerados:\")\n",
        "print(\"- Nova tabela de resultados: resultados_knn_com_pca.csv\")\n",
        "print(\"- 6 novos datasets PCA em CSV\")\n",
        "print(f\"{'='*60}\")"
      ],
      "metadata": {
        "id": "u9aC_G8-ut0T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c852faf7-e3f2-44c2-f37b-b6d624c778bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analisando resultados anteriores...\n",
            "Calculando performance de cada base...\n",
            "Avaliando: HOG_128_16x16\n",
            "Avaliando: HOG_128_20x20\n",
            "Avaliando: HOG_256_16x16\n",
            "Avaliando: HOG_256_20x20\n",
            "Avaliando: CNN_VGG16_128_avg\n",
            "Avaliando: CNN_VGG16_128_max\n",
            "Avaliando: CNN_VGG16_256_avg\n",
            "Avaliando: CNN_VGG16_256_max\n",
            "Avaliando: CNN_VGG19_128_avg\n",
            "Avaliando: CNN_VGG19_126_max\n",
            "Avaliando: CNN_VGG19_256_avg\n",
            "Avaliando: CNN_VGG19_256_max\n",
            "\n",
            "============================================================\n",
            "RANKING DAS BASES\n",
            "============================================================\n",
            " 1. CNN_VGG16_256_max         - 0.9613 MELHOR\n",
            " 2. CNN_VGG19_256_max         - 0.9525 MELHOR\n",
            " 3. CNN_VGG16_256_avg         - 0.9467 MELHOR\n",
            " 4. CNN_VGG19_256_avg         - 0.9454 MELHOR\n",
            " 5. CNN_VGG16_128_max         - 0.8847 MELHOR\n",
            " 6. CNN_VGG16_128_avg         - 0.8690 MELHOR\n",
            " 7. CNN_VGG19_126_max         - 0.8593 PIOR\n",
            " 8. CNN_VGG19_128_avg         - 0.8448 PIOR\n",
            " 9. HOG_128_20x20             - 0.4456 PIOR\n",
            "10. HOG_128_16x16             - 0.4043 PIOR\n",
            "11. HOG_256_20x20             - 0.3261 PIOR\n",
            "12. HOG_256_16x16             - 0.3049 PIOR\n",
            "\n",
            "6 MELHORES BASES:\n",
            "  - CNN_VGG16_256_max\n",
            "  - CNN_VGG19_256_max\n",
            "  - CNN_VGG16_256_avg\n",
            "  - CNN_VGG19_256_avg\n",
            "  - CNN_VGG16_128_max\n",
            "  - CNN_VGG16_128_avg\n",
            "\n",
            "6 PIORES BASES (serão substituídas):\n",
            "  - CNN_VGG19_126_max\n",
            "  - CNN_VGG19_128_avg\n",
            "  - HOG_128_20x20\n",
            "  - HOG_128_16x16\n",
            "  - HOG_256_20x20\n",
            "  - HOG_256_16x16\n",
            "\n",
            "============================================================\n",
            "APLICANDO PCA (10 componentes) NAS 6 MELHORES BASES\n",
            "============================================================\n",
            "\n",
            "Processando PCA para: CNN_VGG16_256_max\n",
            "  Dimensões originais: (800, 512)\n",
            "  Dimensões após PCA: (800, 10)\n",
            "  Variância explicada: 0.3392\n",
            "  Dataset PCA salvo: dataset_PCA_CNN_VGG16_256_max.csv\n",
            "\n",
            "Processando PCA para: CNN_VGG19_256_max\n",
            "  Dimensões originais: (800, 512)\n",
            "  Dimensões após PCA: (800, 10)\n",
            "  Variância explicada: 0.3373\n",
            "  Dataset PCA salvo: dataset_PCA_CNN_VGG19_256_max.csv\n",
            "\n",
            "Processando PCA para: CNN_VGG16_256_avg\n",
            "  Dimensões originais: (800, 512)\n",
            "  Dimensões após PCA: (800, 10)\n",
            "  Variância explicada: 0.3545\n",
            "  Dataset PCA salvo: dataset_PCA_CNN_VGG16_256_avg.csv\n",
            "\n",
            "Processando PCA para: CNN_VGG19_256_avg\n",
            "  Dimensões originais: (800, 512)\n",
            "  Dimensões após PCA: (800, 10)\n",
            "  Variância explicada: 0.3456\n",
            "  Dataset PCA salvo: dataset_PCA_CNN_VGG19_256_avg.csv\n",
            "\n",
            "Processando PCA para: CNN_VGG16_128_max\n",
            "  Dimensões originais: (800, 512)\n",
            "  Dimensões após PCA: (800, 10)\n",
            "  Variância explicada: 0.2993\n",
            "  Dataset PCA salvo: dataset_PCA_CNN_VGG16_128_max.csv\n",
            "\n",
            "Processando PCA para: CNN_VGG16_128_avg\n",
            "  Dimensões originais: (800, 512)\n",
            "  Dimensões após PCA: (800, 10)\n",
            "  Variância explicada: 0.2893\n",
            "  Dataset PCA salvo: dataset_PCA_CNN_VGG16_128_avg.csv\n",
            "\n",
            "============================================================\n",
            "CRIANDO NOVA CONFIGURAÇÃO DE DATASETS\n",
            "============================================================\n",
            "Nova configuração de datasets:\n",
            " 1. CNN_VGG16_256_max                   - ORIGINAL\n",
            " 2. CNN_VGG19_256_max                   - ORIGINAL\n",
            " 3. CNN_VGG16_256_avg                   - ORIGINAL\n",
            " 4. CNN_VGG19_256_avg                   - ORIGINAL\n",
            " 5. CNN_VGG16_128_max                   - ORIGINAL\n",
            " 6. CNN_VGG16_128_avg                   - ORIGINAL\n",
            " 7. PCA_CNN_VGG16_256_max               - PCA\n",
            " 8. PCA_CNN_VGG19_256_max               - PCA\n",
            " 9. PCA_CNN_VGG16_256_avg               - PCA\n",
            "10. PCA_CNN_VGG19_256_avg               - PCA\n",
            "11. PCA_CNN_VGG16_128_max               - PCA\n",
            "12. PCA_CNN_VGG16_128_avg               - PCA\n",
            "\n",
            "================================================================================\n",
            "EXECUTANDO NOVOS EXPERIMENTOS k-NN\n",
            "================================================================================\n",
            "\n",
            "Processando: CNN_VGG16_256_max\n",
            "Shape: (800, 514)\n",
            "  k=1... 70/30: 0.9417, 10-fold: 0.9525\n",
            "  k=2... 70/30: 0.9542, 10-fold: 0.9763\n",
            "  k=3... 70/30: 0.9583, 10-fold: 0.9637\n",
            "  k=4... 70/30: 0.9750, 10-fold: 0.9725\n",
            "  k=5... 70/30: 0.9375, 10-fold: 0.9612\n",
            "  k=6... 70/30: 0.9750, 10-fold: 0.9688\n",
            "  k=7... 70/30: 0.9542, 10-fold: 0.9625\n",
            "  k=8... 70/30: 0.9667, 10-fold: 0.9638\n",
            "  k=9... 70/30: 0.9625, 10-fold: 0.9600\n",
            "  k=10... 70/30: 0.9625, 10-fold: 0.9575\n",
            "\n",
            "Processando: CNN_VGG19_256_max\n",
            "Shape: (800, 514)\n",
            "  k=1... 70/30: 0.9417, 10-fold: 0.9575\n",
            "  k=2... 70/30: 0.9583, 10-fold: 0.9750\n",
            "  k=3... 70/30: 0.9333, 10-fold: 0.9512\n",
            "  k=4... 70/30: 0.9625, 10-fold: 0.9625\n",
            "  k=5... 70/30: 0.9625, 10-fold: 0.9575\n",
            "  k=6... 70/30: 0.9542, 10-fold: 0.9563\n",
            "  k=7... 70/30: 0.9417, 10-fold: 0.9525\n",
            "  k=8... 70/30: 0.9500, 10-fold: 0.9537\n",
            "  k=9... 70/30: 0.9417, 10-fold: 0.9500\n",
            "  k=10... 70/30: 0.9375, 10-fold: 0.9500\n",
            "\n",
            "Processando: CNN_VGG16_256_avg\n",
            "Shape: (800, 514)\n",
            "  k=1... 70/30: 0.9083, 10-fold: 0.9313\n",
            "  k=2... 70/30: 0.9333, 10-fold: 0.9462\n",
            "  k=3... 70/30: 0.9292, 10-fold: 0.9412\n",
            "  k=4... 70/30: 0.9458, 10-fold: 0.9575\n",
            "  k=5... 70/30: 0.9417, 10-fold: 0.9387\n",
            "  k=6... 70/30: 0.9625, 10-fold: 0.9537\n",
            "  k=7... 70/30: 0.9625, 10-fold: 0.9450\n",
            "  k=8... 70/30: 0.9667, 10-fold: 0.9525\n",
            "  k=9... 70/30: 0.9625, 10-fold: 0.9512\n",
            "  k=10... 70/30: 0.9542, 10-fold: 0.9500\n",
            "\n",
            "Processando: CNN_VGG19_256_avg\n",
            "Shape: (800, 514)\n",
            "  k=1... 70/30: 0.9125, 10-fold: 0.9350\n",
            "  k=2... 70/30: 0.9292, 10-fold: 0.9513\n",
            "  k=3... 70/30: 0.9208, 10-fold: 0.9437\n",
            "  k=4... 70/30: 0.9458, 10-fold: 0.9575\n",
            "  k=5... 70/30: 0.9417, 10-fold: 0.9512\n",
            "  k=6... 70/30: 0.9542, 10-fold: 0.9563\n",
            "  k=7... 70/30: 0.9375, 10-fold: 0.9450\n",
            "  k=8... 70/30: 0.9583, 10-fold: 0.9525\n",
            "  k=9... 70/30: 0.9542, 10-fold: 0.9500\n",
            "  k=10... 70/30: 0.9542, 10-fold: 0.9563\n",
            "\n",
            "Processando: CNN_VGG16_128_max\n",
            "Shape: (800, 514)\n",
            "  k=1... 70/30: 0.8417, 10-fold: 0.8650\n",
            "  k=2... 70/30: 0.8708, 10-fold: 0.8775\n",
            "  k=3... 70/30: 0.8667, 10-fold: 0.8700\n",
            "  k=4... 70/30: 0.9000, 10-fold: 0.8812\n",
            "  k=5... 70/30: 0.8958, 10-fold: 0.8738\n",
            "  k=6... 70/30: 0.9167, 10-fold: 0.8888\n",
            "  k=7... 70/30: 0.9042, 10-fold: 0.8762\n",
            "  k=8... 70/30: 0.9042, 10-fold: 0.8938\n",
            "  k=9... 70/30: 0.9000, 10-fold: 0.8800\n",
            "  k=10... 70/30: 0.8958, 10-fold: 0.8925\n",
            "\n",
            "Processando: CNN_VGG16_128_avg\n",
            "Shape: (800, 514)\n",
            "  k=1... 70/30: 0.8292, 10-fold: 0.8438\n",
            "  k=2... 70/30: 0.8542, 10-fold: 0.8588\n",
            "  k=3... 70/30: 0.8583, 10-fold: 0.8625\n",
            "  k=4... 70/30: 0.8958, 10-fold: 0.8788\n",
            "  k=5... 70/30: 0.8833, 10-fold: 0.8662\n",
            "  k=6... 70/30: 0.8917, 10-fold: 0.8662\n",
            "  k=7... 70/30: 0.8625, 10-fold: 0.8713\n",
            "  k=8... 70/30: 0.8792, 10-fold: 0.8713\n",
            "  k=9... 70/30: 0.8792, 10-fold: 0.8750\n",
            "  k=10... 70/30: 0.8750, 10-fold: 0.8787\n",
            "\n",
            "Processando: PCA_CNN_VGG16_256_max\n",
            "Shape: (800, 12)\n",
            "  k=1... 70/30: 0.9708, 10-fold: 0.9788\n",
            "  k=2... 70/30: 0.9708, 10-fold: 0.9738\n",
            "  k=3... 70/30: 0.9667, 10-fold: 0.9762\n",
            "  k=4... 70/30: 0.9917, 10-fold: 0.9838\n",
            "  k=5... 70/30: 0.9792, 10-fold: 0.9812\n",
            "  k=6... 70/30: 0.9917, 10-fold: 0.9825\n",
            "  k=7... 70/30: 0.9917, 10-fold: 0.9812\n",
            "  k=8... 70/30: 0.9917, 10-fold: 0.9812\n",
            "  k=9... 70/30: 0.9875, 10-fold: 0.9838\n",
            "  k=10... 70/30: 0.9833, 10-fold: 0.9850\n",
            "\n",
            "Processando: PCA_CNN_VGG19_256_max\n",
            "Shape: (800, 12)\n",
            "  k=1... 70/30: 0.9708, 10-fold: 0.9775\n",
            "  k=2... 70/30: 0.9792, 10-fold: 0.9762\n",
            "  k=3... 70/30: 0.9667, 10-fold: 0.9800\n",
            "  k=4... 70/30: 0.9833, 10-fold: 0.9813\n",
            "  k=5... 70/30: 0.9833, 10-fold: 0.9875\n",
            "  k=6... 70/30: 0.9833, 10-fold: 0.9875\n",
            "  k=7... 70/30: 0.9833, 10-fold: 0.9862\n",
            "  k=8... 70/30: 0.9833, 10-fold: 0.9875\n",
            "  k=9... 70/30: 0.9792, 10-fold: 0.9875\n",
            "  k=10... 70/30: 0.9833, 10-fold: 0.9875\n",
            "\n",
            "Processando: PCA_CNN_VGG16_256_avg\n",
            "Shape: (800, 12)\n",
            "  k=1... 70/30: 0.9500, 10-fold: 0.9488\n",
            "  k=2... 70/30: 0.9583, 10-fold: 0.9463\n",
            "  k=3... 70/30: 0.9500, 10-fold: 0.9575\n",
            "  k=4... 70/30: 0.9500, 10-fold: 0.9638\n",
            "  k=5... 70/30: 0.9542, 10-fold: 0.9613\n",
            "  k=6... 70/30: 0.9583, 10-fold: 0.9675\n",
            "  k=7... 70/30: 0.9583, 10-fold: 0.9625\n",
            "  k=8... 70/30: 0.9583, 10-fold: 0.9613\n",
            "  k=9... 70/30: 0.9583, 10-fold: 0.9600\n",
            "  k=10... 70/30: 0.9583, 10-fold: 0.9613\n",
            "\n",
            "Processando: PCA_CNN_VGG19_256_avg\n",
            "Shape: (800, 12)\n",
            "  k=1... 70/30: 0.9625, 10-fold: 0.9675\n",
            "  k=2... 70/30: 0.9667, 10-fold: 0.9650\n",
            "  k=3... 70/30: 0.9625, 10-fold: 0.9650\n",
            "  k=4... 70/30: 0.9708, 10-fold: 0.9662\n",
            "  k=5... 70/30: 0.9583, 10-fold: 0.9775\n",
            "  k=6... 70/30: 0.9792, 10-fold: 0.9713\n",
            "  k=7... 70/30: 0.9708, 10-fold: 0.9750\n",
            "  k=8... 70/30: 0.9708, 10-fold: 0.9725\n",
            "  k=9... 70/30: 0.9542, 10-fold: 0.9750\n",
            "  k=10... 70/30: 0.9625, 10-fold: 0.9713\n",
            "\n",
            "Processando: PCA_CNN_VGG16_128_max\n",
            "Shape: (800, 12)\n",
            "  k=1... 70/30: 0.9000, 10-fold: 0.9000\n",
            "  k=2... 70/30: 0.8958, 10-fold: 0.9100\n",
            "  k=3... 70/30: 0.8958, 10-fold: 0.9213\n",
            "  k=4... 70/30: 0.9167, 10-fold: 0.9275\n",
            "  k=5... 70/30: 0.9208, 10-fold: 0.9363\n",
            "  k=6... 70/30: 0.9167, 10-fold: 0.9313\n",
            "  k=7... 70/30: 0.9250, 10-fold: 0.9163\n",
            "  k=8... 70/30: 0.9250, 10-fold: 0.9275\n",
            "  k=9... 70/30: 0.9333, 10-fold: 0.9187\n",
            "  k=10... 70/30: 0.9250, 10-fold: 0.9238\n",
            "\n",
            "Processando: PCA_CNN_VGG16_128_avg\n",
            "Shape: (800, 12)\n",
            "  k=1... 70/30: 0.8625, 10-fold: 0.8838\n",
            "  k=2... 70/30: 0.8833, 10-fold: 0.8862\n",
            "  k=3... 70/30: 0.8875, 10-fold: 0.9088\n",
            "  k=4... 70/30: 0.8875, 10-fold: 0.9113\n",
            "  k=5... 70/30: 0.9042, 10-fold: 0.9112\n",
            "  k=6... 70/30: 0.8750, 10-fold: 0.9100\n",
            "  k=7... 70/30: 0.8958, 10-fold: 0.9100\n",
            "  k=8... 70/30: 0.8958, 10-fold: 0.9088\n",
            "  k=9... 70/30: 0.9167, 10-fold: 0.9100\n",
            "  k=10... 70/30: 0.9083, 10-fold: 0.9100\n",
            "\n",
            "Calculando novas estatísticas...\n",
            "\n",
            "========================================================================================================================\n",
            "NOVA TABELA DE RESULTADOS k-NN (6 MELHORES + 6 PCA)\n",
            "========================================================================================================================\n",
            "                      Base Treino/Test     k=1     k=2     k=3     k=4     k=5     k=6     k=7     k=8     k=9    k=10\n",
            "   CNN_VGG16_256_max (512)       70/30  0.9417  0.9542  0.9583   0.975  0.9375   0.975  0.9542  0.9667  0.9625  0.9625\n",
            "                            10-fold CV  0.9525  0.9762  0.9637  0.9725  0.9612  0.9688  0.9625  0.9638    0.96  0.9575\n",
            "   CNN_VGG19_256_max (512)       70/30  0.9417  0.9583  0.9333  0.9625  0.9625  0.9542  0.9417    0.95  0.9417  0.9375\n",
            "                            10-fold CV  0.9575   0.975  0.9512  0.9625  0.9575  0.9562  0.9525  0.9538    0.95    0.95\n",
            "   CNN_VGG16_256_avg (512)       70/30  0.9083  0.9333  0.9292  0.9458  0.9417  0.9625  0.9625  0.9667  0.9625  0.9542\n",
            "                            10-fold CV  0.9312  0.9462  0.9412  0.9575  0.9388  0.9538   0.945  0.9525  0.9512    0.95\n",
            "   CNN_VGG19_256_avg (512)       70/30  0.9125  0.9292  0.9208  0.9458  0.9417  0.9542  0.9375  0.9583  0.9542  0.9542\n",
            "                            10-fold CV   0.935  0.9513  0.9437  0.9575  0.9512  0.9562   0.945  0.9525    0.95  0.9562\n",
            "   CNN_VGG16_128_max (512)       70/30  0.8417  0.8708  0.8667     0.9  0.8958  0.9167  0.9042  0.9042     0.9  0.8958\n",
            "                            10-fold CV   0.865  0.8775    0.87  0.8812  0.8738  0.8888  0.8762  0.8938    0.88  0.8925\n",
            "   CNN_VGG16_128_avg (512)       70/30  0.8292  0.8542  0.8583  0.8958  0.8833  0.8917  0.8625  0.8792  0.8792   0.875\n",
            "                            10-fold CV  0.8438  0.8588  0.8625  0.8788  0.8662  0.8662  0.8712  0.8712   0.875  0.8788\n",
            "PCA_CNN_VGG16_256_max (10)       70/30  0.9708  0.9708  0.9667  0.9917  0.9792  0.9917  0.9917  0.9917  0.9875  0.9833\n",
            "                            10-fold CV  0.9788  0.9738  0.9762  0.9838  0.9812  0.9825  0.9812  0.9812  0.9838   0.985\n",
            "PCA_CNN_VGG19_256_max (10)       70/30  0.9708  0.9792  0.9667  0.9833  0.9833  0.9833  0.9833  0.9833  0.9792  0.9833\n",
            "                            10-fold CV  0.9775  0.9762    0.98  0.9813  0.9875  0.9875  0.9862  0.9875  0.9875  0.9875\n",
            "PCA_CNN_VGG16_256_avg (10)       70/30    0.95  0.9583    0.95    0.95  0.9542  0.9583  0.9583  0.9583  0.9583  0.9583\n",
            "                            10-fold CV  0.9488  0.9462  0.9575  0.9638  0.9612  0.9675  0.9625  0.9612    0.96  0.9612\n",
            "PCA_CNN_VGG19_256_avg (10)       70/30  0.9625  0.9667  0.9625  0.9708  0.9583  0.9792  0.9708  0.9708  0.9542  0.9625\n",
            "                            10-fold CV  0.9675   0.965   0.965  0.9662  0.9775  0.9712   0.975  0.9725   0.975  0.9712\n",
            "PCA_CNN_VGG16_128_max (10)       70/30     0.9  0.8958  0.8958  0.9167  0.9208  0.9167   0.925   0.925  0.9333   0.925\n",
            "                            10-fold CV     0.9    0.91  0.9212  0.9275  0.9362  0.9312  0.9162  0.9275  0.9188  0.9238\n",
            "PCA_CNN_VGG16_128_avg (10)       70/30  0.8625  0.8833  0.8875  0.8875  0.9042   0.875  0.8958  0.8958  0.9167  0.9083\n",
            "                            10-fold CV  0.8838  0.8862  0.9088  0.9113  0.9112    0.91    0.91  0.9088    0.91    0.91\n",
            "                                                                                                                      \n",
            "                  Média =>              0.9160  0.9295  0.9246  0.9437  0.9385  0.9465  0.9406  0.9458  0.9441  0.9417\n",
            "             Desv. Pad. =>              0.0494  0.0429  0.0391  0.0358  0.0320  0.0378  0.0382  0.0362  0.0319  0.0342\n",
            "                                                                                                                      \n",
            "                  Média =>              0.9285  0.9369  0.9367  0.9453  0.9420  0.9450  0.9403  0.9439  0.9418  0.9436\n",
            "             Desv. Pad. =>              0.0451  0.0426  0.0389  0.0368  0.0397  0.0382  0.0388  0.0361  0.0377  0.0350\n",
            "\n",
            "Novos resultados salvos em: resultados_knn_com_pca.csv\n",
            "\n",
            "============================================================\n",
            "COMPARAÇÃO DE PERFORMANCE\n",
            "============================================================\n",
            "Performance média das bases originais mantidas:\n",
            "  70/30: 0.9332\n",
            "  10-fold: 0.9391\n",
            "\n",
            "Performance média das novas bases PCA:\n",
            "  70/30: 0.9431\n",
            "  10-fold: 0.9424\n",
            "\n",
            "============================================================\n",
            "EXPERIMENTOS COM PCA CONCLUÍDOS!\n",
            "Arquivos gerados:\n",
            "- Nova tabela de resultados: resultados_knn_com_pca.csv\n",
            "- 6 novos datasets PCA em CSV\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download dos arquivos\n",
        "from google.colab import files\n",
        "files.download('resultados_knn_com_pca.csv')\n",
        "\n",
        "# Download dos datasets PCA\n",
        "for pca_name in pca_datasets.keys():\n",
        "    filename = f\"dataset_{pca_name}.csv\"\n",
        "    files.download(filename)"
      ],
      "metadata": {
        "id": "w7zt7IlWQew0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Qual foi o melhor método de extração HOG ou CNN? Tente explicar o motivo do\n",
        "comportamento da sua base de dados\n",
        "\n",
        "R:\n",
        "A CNN teve um desempenho melhor que o HOG na extração de características para classificação das imagens de cães e gatos. Isso ocorre porque as CNNs são capazes de aprender automaticamente características hierárquicas e mais complexas diretamente dos pixels da imagem, capturando desde bordas simples até padrões mais complexos como texturas e formas específicas de cada raça. O HOG por outro lado, se baseia apenas em gradientes locais de intensidade que são úteis para detectar bordas mas não conseguem representar bem a grande variabilidade de aparência entre diferentes espécies e raças."
      ],
      "metadata": {
        "id": "SmGhnPxf3uAy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O que aconteceu com a acurácia quando diminuímos o número de atributos com o PCA?\n",
        "Explique o comportamento dos modelos.\n",
        "\n",
        "R:\n",
        "A acurácia teve uma melhora após a redução de atributos com PCA, apesar da diminuição no número de características. Esse comportamento ocorreu porque o PCA eliminou redundâncias e ruídos presentes nas features originais preservando as componentes principais que capturam a variância mais relevante dos dados."
      ],
      "metadata": {
        "id": "WqIv44vp3xdr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Em relação ao k-NN, o que aconteceu quando aumentamos o número de vizinhos? Explique o\n",
        "motivo deste comportamento\n",
        "\n",
        "R:\n",
        "Quando aumenta o número de vizinhos no k-NN, a acurácia começa a melhorar porque o modelo fica menos \"impulsivo\" ou seja em vez de decidir com base em apenas 1 ou 2 exemplos (que podem ser erros ou casos atípicos), ele olha mais ao redor e toma decisões mais ponderadas. Isso ajuda a filtrar ruídos e deixa o resultado mais estável.\n",
        "Mas se exagerar no k, o modelo começa a \"perder o foco\". Ele passa a considerar muitos vizinhos que talvez nem sejam tão relevantes, misturando informações de classes diferentes e piorando a precisão."
      ],
      "metadata": {
        "id": "Pv6gi3Af32ju"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Experimentos com Árvores de Decisão\n",
        "Utilizando bases já processadas via upload\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import cross_val_score, train_test_split, StratifiedKFold\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# UPLOAD DAS BASES PROCESSADAS\n",
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "print(\"Faça upload dos arquivos CSV das bases processadas:\")\n",
        "\n",
        "uploaded_files = files.upload()\n",
        "\n",
        "print(f\"\\nArquivos carregados: {len(uploaded_files)}\")\n",
        "for filename in uploaded_files.keys():\n",
        "    print(f\"  - {filename}\")\n",
        "\n",
        "# IDENTIFICAR E CARREGAR DATASETS\n",
        "datasets = {}\n",
        "\n",
        "for filename in uploaded_files.keys():\n",
        "    try:\n",
        "        df = pd.read_csv(filename)\n",
        "\n",
        "        if 'label' in df.columns and 'filename' in df.columns:\n",
        "            if filename.startswith('dataset_'):\n",
        "                base_name = filename.replace('dataset_', '').replace('.csv', '')\n",
        "            else:\n",
        "                base_name = filename.replace('.csv', '')\n",
        "\n",
        "            datasets[base_name] = df\n",
        "            print(f\"   {base_name}: {df.shape}\")\n",
        "        else:\n",
        "            print(f\"   {filename}: Formato inválido (faltam colunas 'label' ou 'filename')\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"   Erro ao carregar {filename}: {e}\")\n",
        "\n",
        "print(f\"\\nTotal de datasets válidos carregados: {len(datasets)}\")\n",
        "\n",
        "if len(datasets) == 0:\n",
        "    print(\"ERRO: Nenhum dataset válido foi carregado!\")\n",
        "    print(\"Certifique-se de fazer upload dos arquivos CSV corretos.\")\n",
        "    exit()\n",
        "\n",
        "# FUNÇÃO PARA PREPARAR OS DADOS\n",
        "def prepare_data(df):\n",
        "    \"\"\"Prepara os dados separando features e labels\"\"\"\n",
        "    X = df.drop(['label', 'filename'], axis=1)\n",
        "    y = df['label']\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "    return X_scaled, y\n",
        "\n",
        "# CONFIGURAR EXPERIMENTOS\n",
        "max_depth_values = [2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
        "\n",
        "print(f\"\\nConfiguração dos experimentos:\")\n",
        "print(f\"- Algoritmo: Árvore de Decisão (Decision Tree)\")\n",
        "print(f\"- Parâmetro: max_depth\")\n",
        "print(f\"- Valores testados: {max_depth_values}\")\n",
        "print(f\"- Métodos de validação: 70/30 split e 10-fold Cross Validation\")\n",
        "print(f\"- Bases: {len(datasets)} datasets\")\n",
        "\n",
        "# EXECUTAR EXPERIMENTOS COM ÁRVORES DE DECISÃO\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"EXECUTANDO EXPERIMENTOS COM ÁRVORES DE DECISÃO\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "results_table = []\n",
        "\n",
        "for dataset_name, df in datasets.items():\n",
        "    print(f\"\\nProcessando: {dataset_name}\")\n",
        "    print(f\"Shape: {df.shape}\")\n",
        "\n",
        "    class_counts = df['label'].value_counts()\n",
        "    print(f\"Distribuição de classes: {dict(class_counts)}\")\n",
        "\n",
        "    X, y = prepare_data(df)\n",
        "\n",
        "    n_features = X.shape[1]\n",
        "\n",
        "    row_70_30 = {'Bases': f\"{dataset_name} ({n_features})\", 'Treino/Teste': '70/30'}\n",
        "    row_10_fold = {'Bases': '', 'Treino/Teste': '10-fold CV'}\n",
        "\n",
        "    for max_depth in max_depth_values:\n",
        "        print(f\"  max_depth={max_depth}...\", end=\" \")\n",
        "\n",
        "        dt = DecisionTreeClassifier(\n",
        "            max_depth=max_depth,\n",
        "            random_state=42,\n",
        "            criterion='gini'\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            X_train, X_test, y_train, y_test = train_test_split(\n",
        "                X, y, test_size=0.3, random_state=42, stratify=y\n",
        "            )\n",
        "\n",
        "            dt.fit(X_train, y_train)\n",
        "            y_pred = dt.predict(X_test)\n",
        "            accuracy_70_30 = accuracy_score(y_test, y_pred)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Erro 70/30: {e}\")\n",
        "            accuracy_70_30 = 0.0\n",
        "\n",
        "        try:\n",
        "            cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "            cv_scores = cross_val_score(dt, X, y, cv=cv, scoring='accuracy')\n",
        "            accuracy_10_fold = cv_scores.mean()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Erro 10-fold: {e}\")\n",
        "            accuracy_10_fold = 0.0\n",
        "\n",
        "        col_name = f'md={max_depth}'\n",
        "        row_70_30[col_name] = round(accuracy_70_30, 4)\n",
        "        row_10_fold[col_name] = round(accuracy_10_fold, 4)\n",
        "\n",
        "        print(f\"70/30: {accuracy_70_30:.4f}, 10-fold: {accuracy_10_fold:.4f}\")\n",
        "\n",
        "    results_table.append(row_70_30)\n",
        "    results_table.append(row_10_fold)\n",
        "\n",
        "# CRIAR DATAFRAME DOS RESULTADOS\n",
        "print(\"\\nCriando tabela de resultados...\")\n",
        "\n",
        "df_results = pd.DataFrame(results_table)\n",
        "\n",
        "columns_order = ['Bases', 'Treino/Teste'] + [f'md={depth}' for depth in max_depth_values]\n",
        "df_results = df_results[columns_order]\n",
        "\n",
        "\n",
        "# CALCULAR MÉDIA E DESVIO PADRÃO\n",
        "print(\"Calculando estatísticas...\")\n",
        "\n",
        "results_70_30 = df_results[df_results['Treino/Teste'] == '70/30'].copy()\n",
        "results_10_fold = df_results[df_results['Treino/Teste'] == '10-fold CV'].copy()\n",
        "\n",
        "stats_70_30 = {'Bases': 'Média =>', 'Treino/Teste': '#DIV/0!'}\n",
        "stats_std_70_30 = {'Bases': 'Desv. Pad. =>', 'Treino/Teste': '#DIV/0!'}\n",
        "\n",
        "stats_10_fold = {'Bases': 'Média =>', 'Treino/Teste': '#DIV/0!'}\n",
        "stats_std_10_fold = {'Bases': 'Desv. Pad. =>', 'Treino/Teste': '#DIV/0!'}\n",
        "\n",
        "for depth in max_depth_values:\n",
        "    col_name = f'md={depth}'\n",
        "\n",
        "    values_70_30 = results_70_30[col_name].dropna()\n",
        "    mean_70_30 = values_70_30.mean()\n",
        "    std_70_30 = values_70_30.std()\n",
        "\n",
        "    stats_70_30[col_name] = f\"{mean_70_30:.4f}\"\n",
        "    stats_std_70_30[col_name] = f\"{std_70_30:.4f}\"\n",
        "\n",
        "    values_10_fold = results_10_fold[col_name].dropna()\n",
        "    mean_10_fold = values_10_fold.mean()\n",
        "    std_10_fold = values_10_fold.std()\n",
        "\n",
        "    stats_10_fold[col_name] = f\"{mean_10_fold:.4f}\"\n",
        "    stats_std_10_fold[col_name] = f\"{std_10_fold:.4f}\"\n",
        "\n",
        "# CRIAR TABELA FINAL COM ESTATÍSTICAS\n",
        "final_results = df_results.to_dict('records')\n",
        "\n",
        "final_results.append({col: '' for col in columns_order})\n",
        "\n",
        "final_results.append(stats_70_30)\n",
        "final_results.append(stats_std_70_30)\n",
        "\n",
        "final_results.append({col: '' for col in columns_order})\n",
        "\n",
        "final_results.append(stats_10_fold)\n",
        "final_results.append(stats_std_10_fold)\n",
        "\n",
        "df_final = pd.DataFrame(final_results)\n",
        "\n",
        "# EXIBIR E SALVAR RESULTADOS\n",
        "print(\"\\n\" + \"=\"*120)\n",
        "print(\"TABELA DE RESULTADOS - ÁRVORE DE DECISÃO (Acurácia)\")\n",
        "print(\"=\"*120)\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "print(df_final.to_string(index=False))\n",
        "\n",
        "filename_results = 'resultados_arvore_decisao.csv'\n",
        "df_final.to_csv(filename_results, index=False)\n",
        "print(f\"\\nResultados salvos em: {filename_results}\")\n",
        "\n",
        "# ANÁLISE DOS MELHORES RESULTADOS\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ANÁLISE DOS MELHORES RESULTADOS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\\nMelhores max_depth por método de validação:\")\n",
        "\n",
        "best_depth_70_30 = {}\n",
        "for depth in max_depth_values:\n",
        "    col_name = f'md={depth}'\n",
        "    values = results_70_30[col_name].dropna()\n",
        "    if len(values) > 0:\n",
        "        mean_acc = values.mean()\n",
        "        best_depth_70_30[depth] = mean_acc\n",
        "\n",
        "if best_depth_70_30:\n",
        "    best_depth_70_30_sorted = sorted(best_depth_70_30.items(), key=lambda x: x[1], reverse=True)\n",
        "    print(f\"70/30 - Melhor max_depth: {best_depth_70_30_sorted[0][0]} (Acurácia: {best_depth_70_30_sorted[0][1]:.4f})\")\n",
        "\n",
        "best_depth_10_fold = {}\n",
        "for depth in max_depth_values:\n",
        "    col_name = f'md={depth}'\n",
        "    values = results_10_fold[col_name].dropna()\n",
        "    if len(values) > 0:\n",
        "        mean_acc = values.mean()\n",
        "        best_depth_10_fold[depth] = mean_acc\n",
        "\n",
        "if best_depth_10_fold:\n",
        "    best_depth_10_fold_sorted = sorted(best_depth_10_fold.items(), key=lambda x: x[1], reverse=True)\n",
        "    print(f\"10-fold - Melhor max_depth: {best_depth_10_fold_sorted[0][0]} (Acurácia: {best_depth_10_fold_sorted[0][1]:.4f})\")\n",
        "\n",
        "print(f\"\\nAnálise de Overfitting:\")\n",
        "print(\"Comparando performance entre 70/30 e 10-fold CV por max_depth:\")\n",
        "\n",
        "for depth in max_depth_values:\n",
        "    col_name = f'md={depth}'\n",
        "\n",
        "    values_70_30 = results_70_30[col_name].dropna()\n",
        "    values_10_fold = results_10_fold[col_name].dropna()\n",
        "\n",
        "    if len(values_70_30) > 0 and len(values_10_fold) > 0:\n",
        "        mean_70_30 = values_70_30.mean()\n",
        "        mean_10_fold = values_10_fold.mean()\n",
        "        diff = mean_70_30 - mean_10_fold\n",
        "\n",
        "        status = \"Possível overfitting\" if diff > 0.05 else \"OK\"\n",
        "        print(f\"max_depth={depth}: 70/30={mean_70_30:.4f}, 10-fold={mean_10_fold:.4f}, diff={diff:.4f} {status}\")\n",
        "\n",
        "# IDENTIFICAR MELHORES BASES POR MAX_DEPTH\n",
        "print(f\"\\nMelhores bases por max_depth:\")\n",
        "\n",
        "for depth in max_depth_values:\n",
        "    col_name = f'md={depth}'\n",
        "\n",
        "    base_results = results_70_30[['Bases', col_name]].copy()\n",
        "    base_results = base_results[base_results[col_name] > 0]\n",
        "\n",
        "    if len(base_results) > 0:\n",
        "        best_base = base_results.loc[base_results[col_name].idxmax()]\n",
        "        print(f\"max_depth={depth}: {best_base['Bases']} (Acurácia: {best_base[col_name]:.4f})\")\n",
        "\n",
        "# Download do arquivo\n",
        "files.download(filename_results)\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"EXPERIMENTOS COM ÁRVORE DE DECISÃO CONCLUÍDOS!\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"Arquivo gerado: {filename_results}\")\n"
      ],
      "metadata": {
        "id": "XtqXUF2QFOB2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5efb2559-849c-4c55-e89d-9b96ef202782"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Faça upload dos arquivos CSV das bases processadas:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ba60fe7a-9a4a-427e-8054-4cc391a85a99\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-ba60fe7a-9a4a-427e-8054-4cc391a85a99\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving dataset_PCA_CNN_VGG16_128_avg.csv to dataset_PCA_CNN_VGG16_128_avg (1).csv\n",
            "Saving dataset_PCA_CNN_VGG16_128_max.csv to dataset_PCA_CNN_VGG16_128_max (1).csv\n",
            "Saving dataset_PCA_CNN_VGG16_256_avg.csv to dataset_PCA_CNN_VGG16_256_avg (1).csv\n",
            "Saving dataset_PCA_CNN_VGG16_256_max.csv to dataset_PCA_CNN_VGG16_256_max (1).csv\n",
            "Saving dataset_PCA_CNN_VGG19_256_avg.csv to dataset_PCA_CNN_VGG19_256_avg (1).csv\n",
            "Saving dataset_PCA_CNN_VGG19_256_max.csv to dataset_PCA_CNN_VGG19_256_max (1).csv\n",
            "Saving dataset_vgg16_avg_128x128.csv to dataset_vgg16_avg_128x128 (1).csv\n",
            "Saving dataset_vgg16_avg_256x256.csv to dataset_vgg16_avg_256x256 (1).csv\n",
            "Saving dataset_vgg16_max_128x128.csv to dataset_vgg16_max_128x128 (1).csv\n",
            "Saving dataset_vgg16_max_256x256.csv to dataset_vgg16_max_256x256 (1).csv\n",
            "Saving dataset_vgg19_avg_256x256.csv to dataset_vgg19_avg_256x256 (1).csv\n",
            "Saving dataset_vgg19_max_256x256.csv to dataset_vgg19_max_256x256 (1).csv\n",
            "\n",
            "Arquivos carregados: 12\n",
            "  - dataset_PCA_CNN_VGG16_128_avg (1).csv\n",
            "  - dataset_PCA_CNN_VGG16_128_max (1).csv\n",
            "  - dataset_PCA_CNN_VGG16_256_avg (1).csv\n",
            "  - dataset_PCA_CNN_VGG16_256_max (1).csv\n",
            "  - dataset_PCA_CNN_VGG19_256_avg (1).csv\n",
            "  - dataset_PCA_CNN_VGG19_256_max (1).csv\n",
            "  - dataset_vgg16_avg_128x128 (1).csv\n",
            "  - dataset_vgg16_avg_256x256 (1).csv\n",
            "  - dataset_vgg16_max_128x128 (1).csv\n",
            "  - dataset_vgg16_max_256x256 (1).csv\n",
            "  - dataset_vgg19_avg_256x256 (1).csv\n",
            "  - dataset_vgg19_max_256x256 (1).csv\n",
            "   PCA_CNN_VGG16_128_avg (1): (800, 12)\n",
            "   PCA_CNN_VGG16_128_max (1): (800, 12)\n",
            "   PCA_CNN_VGG16_256_avg (1): (800, 12)\n",
            "   PCA_CNN_VGG16_256_max (1): (800, 12)\n",
            "   PCA_CNN_VGG19_256_avg (1): (800, 12)\n",
            "   PCA_CNN_VGG19_256_max (1): (800, 12)\n",
            "   vgg16_avg_128x128 (1): (800, 514)\n",
            "   vgg16_avg_256x256 (1): (800, 514)\n",
            "   vgg16_max_128x128 (1): (800, 514)\n",
            "   vgg16_max_256x256 (1): (800, 514)\n",
            "   vgg19_avg_256x256 (1): (800, 514)\n",
            "   vgg19_max_256x256 (1): (800, 514)\n",
            "\n",
            "Total de datasets válidos carregados: 12\n",
            "\n",
            "Configuração dos experimentos:\n",
            "- Algoritmo: Árvore de Decisão (Decision Tree)\n",
            "- Parâmetro: max_depth\n",
            "- Valores testados: [2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
            "- Métodos de validação: 70/30 split e 10-fold Cross Validation\n",
            "- Bases: 12 datasets\n",
            "\n",
            "================================================================================\n",
            "EXECUTANDO EXPERIMENTOS COM ÁRVORES DE DECISÃO\n",
            "================================================================================\n",
            "\n",
            "Processando: PCA_CNN_VGG16_128_avg (1)\n",
            "Shape: (800, 12)\n",
            "Distribuição de classes: {'American_Bulldog': np.int64(200), 'Bengal': np.int64(200), 'Pug': np.int64(200), 'Ragdoll': np.int64(200)}\n",
            "  max_depth=2... 70/30: 0.8667, 10-fold: 0.8350\n",
            "  max_depth=3... 70/30: 0.8792, 10-fold: 0.8788\n",
            "  max_depth=4... 70/30: 0.8625, 10-fold: 0.8850\n",
            "  max_depth=5... 70/30: 0.8875, 10-fold: 0.8762\n",
            "  max_depth=6... 70/30: 0.8958, 10-fold: 0.8925\n",
            "  max_depth=7... 70/30: 0.9083, 10-fold: 0.8938\n",
            "  max_depth=8... 70/30: 0.8958, 10-fold: 0.8825\n",
            "  max_depth=9... 70/30: 0.8958, 10-fold: 0.8875\n",
            "  max_depth=10... 70/30: 0.8958, 10-fold: 0.8888\n",
            "\n",
            "Processando: PCA_CNN_VGG16_128_max (1)\n",
            "Shape: (800, 12)\n",
            "Distribuição de classes: {'American_Bulldog': np.int64(200), 'Bengal': np.int64(200), 'Pug': np.int64(200), 'Ragdoll': np.int64(200)}\n",
            "  max_depth=2... 70/30: 0.8000, 10-fold: 0.7913\n",
            "  max_depth=3... 70/30: 0.7375, 10-fold: 0.8100\n",
            "  max_depth=4... 70/30: 0.8333, 10-fold: 0.8538\n",
            "  max_depth=5... 70/30: 0.8542, 10-fold: 0.8575\n",
            "  max_depth=6... 70/30: 0.8500, 10-fold: 0.8700\n",
            "  max_depth=7... 70/30: 0.8708, 10-fold: 0.8712\n",
            "  max_depth=8... 70/30: 0.8792, 10-fold: 0.8650\n",
            "  max_depth=9... 70/30: 0.8792, 10-fold: 0.8675\n",
            "  max_depth=10... 70/30: 0.8792, 10-fold: 0.8612\n",
            "\n",
            "Processando: PCA_CNN_VGG16_256_avg (1)\n",
            "Shape: (800, 12)\n",
            "Distribuição de classes: {'American_Bulldog': np.int64(200), 'Bengal': np.int64(200), 'Pug': np.int64(200), 'Ragdoll': np.int64(200)}\n",
            "  max_depth=2... 70/30: 0.9000, 10-fold: 0.8825\n",
            "  max_depth=3... 70/30: 0.9000, 10-fold: 0.9238\n",
            "  max_depth=4... 70/30: 0.9083, 10-fold: 0.9262\n",
            "  max_depth=5... 70/30: 0.9208, 10-fold: 0.9412\n",
            "  max_depth=6... 70/30: 0.9167, 10-fold: 0.9387\n",
            "  max_depth=7... 70/30: 0.9208, 10-fold: 0.9387\n",
            "  max_depth=8... 70/30: 0.9208, 10-fold: 0.9387\n",
            "  max_depth=9... 70/30: 0.9208, 10-fold: 0.9387\n",
            "  max_depth=10... 70/30: 0.9208, 10-fold: 0.9387\n",
            "\n",
            "Processando: PCA_CNN_VGG16_256_max (1)\n",
            "Shape: (800, 12)\n",
            "Distribuição de classes: {'American_Bulldog': np.int64(200), 'Bengal': np.int64(200), 'Pug': np.int64(200), 'Ragdoll': np.int64(200)}\n",
            "  max_depth=2... 70/30: 0.8583, 10-fold: 0.8775\n",
            "  max_depth=3... 70/30: 0.8917, 10-fold: 0.9200\n",
            "  max_depth=4... 70/30: 0.9250, 10-fold: 0.9350\n",
            "  max_depth=5... 70/30: 0.9625, 10-fold: 0.9563\n",
            "  max_depth=6... 70/30: 0.9625, 10-fold: 0.9563\n",
            "  max_depth=7... 70/30: 0.9667, 10-fold: 0.9537\n",
            "  max_depth=8... 70/30: 0.9667, 10-fold: 0.9537\n",
            "  max_depth=9... 70/30: 0.9667, 10-fold: 0.9537\n",
            "  max_depth=10... 70/30: 0.9667, 10-fold: 0.9537\n",
            "\n",
            "Processando: PCA_CNN_VGG19_256_avg (1)\n",
            "Shape: (800, 12)\n",
            "Distribuição de classes: {'American_Bulldog': np.int64(200), 'Bengal': np.int64(200), 'Pug': np.int64(200), 'Ragdoll': np.int64(200)}\n",
            "  max_depth=2... 70/30: 0.8625, 10-fold: 0.8650\n",
            "  max_depth=3... 70/30: 0.8875, 10-fold: 0.9050\n",
            "  max_depth=4... 70/30: 0.8958, 10-fold: 0.9287\n",
            "  max_depth=5... 70/30: 0.9000, 10-fold: 0.9287\n",
            "  max_depth=6... 70/30: 0.8792, 10-fold: 0.9362\n",
            "  max_depth=7... 70/30: 0.8917, 10-fold: 0.9350\n",
            "  max_depth=8... 70/30: 0.8958, 10-fold: 0.9337\n",
            "  max_depth=9... 70/30: 0.8958, 10-fold: 0.9337\n",
            "  max_depth=10... 70/30: 0.8958, 10-fold: 0.9337\n",
            "\n",
            "Processando: PCA_CNN_VGG19_256_max (1)\n",
            "Shape: (800, 12)\n",
            "Distribuição de classes: {'American_Bulldog': np.int64(200), 'Bengal': np.int64(200), 'Pug': np.int64(200), 'Ragdoll': np.int64(200)}\n",
            "  max_depth=2... 70/30: 0.8625, 10-fold: 0.9088\n",
            "  max_depth=3... 70/30: 0.9208, 10-fold: 0.9437\n",
            "  max_depth=4... 70/30: 0.9208, 10-fold: 0.9563\n",
            "  max_depth=5... 70/30: 0.9250, 10-fold: 0.9500\n",
            "  max_depth=6... 70/30: 0.9250, 10-fold: 0.9513\n",
            "  max_depth=7... 70/30: 0.9250, 10-fold: 0.9525\n",
            "  max_depth=8... 70/30: 0.9250, 10-fold: 0.9538\n",
            "  max_depth=9... 70/30: 0.9250, 10-fold: 0.9538\n",
            "  max_depth=10... 70/30: 0.9250, 10-fold: 0.9538\n",
            "\n",
            "Processando: vgg16_avg_128x128 (1)\n",
            "Shape: (800, 514)\n",
            "Distribuição de classes: {'American_Bulldog': np.int64(200), 'Bengal': np.int64(200), 'Pug': np.int64(200), 'Ragdoll': np.int64(200)}\n",
            "  max_depth=2... 70/30: 0.8083, 10-fold: 0.7638\n",
            "  max_depth=3... 70/30: 0.8375, 10-fold: 0.7850\n",
            "  max_depth=4... 70/30: 0.8333, 10-fold: 0.8238\n",
            "  max_depth=5... 70/30: 0.8583, 10-fold: 0.8438\n",
            "  max_depth=6... 70/30: 0.8125, 10-fold: 0.8250\n",
            "  max_depth=7... 70/30: 0.8125, 10-fold: 0.8113\n",
            "  max_depth=8... 70/30: 0.8125, 10-fold: 0.8300\n",
            "  max_depth=9... 70/30: 0.8125, 10-fold: 0.8288\n",
            "  max_depth=10... 70/30: 0.8125, 10-fold: 0.8288\n",
            "\n",
            "Processando: vgg16_avg_256x256 (1)\n",
            "Shape: (800, 514)\n",
            "Distribuição de classes: {'American_Bulldog': np.int64(200), 'Bengal': np.int64(200), 'Pug': np.int64(200), 'Ragdoll': np.int64(200)}\n",
            "  max_depth=2... 70/30: 0.8875, 10-fold: 0.8825\n",
            "  max_depth=3... 70/30: 0.8875, 10-fold: 0.8950\n",
            "  max_depth=4... 70/30: 0.9208, 10-fold: 0.9025\n",
            "  max_depth=5... 70/30: 0.9083, 10-fold: 0.8975\n",
            "  max_depth=6... 70/30: 0.9083, 10-fold: 0.8912\n",
            "  max_depth=7... 70/30: 0.9083, 10-fold: 0.8938\n",
            "  max_depth=8... 70/30: 0.9083, 10-fold: 0.8938\n",
            "  max_depth=9... 70/30: 0.9083, 10-fold: 0.8938\n",
            "  max_depth=10... 70/30: 0.9083, 10-fold: 0.8938\n",
            "\n",
            "Processando: vgg16_max_128x128 (1)\n",
            "Shape: (800, 514)\n",
            "Distribuição de classes: {'American_Bulldog': np.int64(200), 'Bengal': np.int64(200), 'Pug': np.int64(200), 'Ragdoll': np.int64(200)}\n",
            "  max_depth=2... 70/30: 0.7917, 10-fold: 0.7562\n",
            "  max_depth=3... 70/30: 0.7792, 10-fold: 0.7612\n",
            "  max_depth=4... 70/30: 0.8292, 10-fold: 0.7863\n",
            "  max_depth=5... 70/30: 0.8458, 10-fold: 0.7975\n",
            "  max_depth=6... 70/30: 0.8375, 10-fold: 0.8063\n",
            "  max_depth=7... 70/30: 0.8292, 10-fold: 0.7775\n",
            "  max_depth=8... 70/30: 0.7917, 10-fold: 0.7788\n",
            "  max_depth=9... 70/30: 0.8333, 10-fold: 0.7812\n",
            "  max_depth=10... 70/30: 0.8333, 10-fold: 0.7762\n",
            "\n",
            "Processando: vgg16_max_256x256 (1)\n",
            "Shape: (800, 514)\n",
            "Distribuição de classes: {'American_Bulldog': np.int64(200), 'Bengal': np.int64(200), 'Pug': np.int64(200), 'Ragdoll': np.int64(200)}\n",
            "  max_depth=2... 70/30: 0.8792, 10-fold: 0.8525\n",
            "  max_depth=3... 70/30: 0.9292, 10-fold: 0.9138\n",
            "  max_depth=4... 70/30: 0.9083, 10-fold: 0.9137\n",
            "  max_depth=5... 70/30: 0.9042, 10-fold: 0.8950\n",
            "  max_depth=6... 70/30: 0.9083, 10-fold: 0.9013\n",
            "  max_depth=7... 70/30: 0.9083, 10-fold: 0.9025\n",
            "  max_depth=8... 70/30: 0.9083, 10-fold: 0.9037\n",
            "  max_depth=9... 70/30: 0.9083, 10-fold: 0.9037\n",
            "  max_depth=10... 70/30: 0.9083, 10-fold: 0.9037\n",
            "\n",
            "Processando: vgg19_avg_256x256 (1)\n",
            "Shape: (800, 514)\n",
            "Distribuição de classes: {'American_Bulldog': np.int64(200), 'Bengal': np.int64(200), 'Pug': np.int64(200), 'Ragdoll': np.int64(200)}\n",
            "  max_depth=2... 70/30: 0.8833, 10-fold: 0.8862\n",
            "  max_depth=3... 70/30: 0.9292, 10-fold: 0.9212\n",
            "  max_depth=4... 70/30: 0.9125, 10-fold: 0.9100\n",
            "  max_depth=5... 70/30: 0.9125, 10-fold: 0.9088\n",
            "  max_depth=6... 70/30: 0.8958, 10-fold: 0.9150\n",
            "  max_depth=7... 70/30: 0.9083, 10-fold: 0.9088\n",
            "  max_depth=8... 70/30: 0.9083, 10-fold: 0.9088\n",
            "  max_depth=9... 70/30: 0.9083, 10-fold: 0.9088\n",
            "  max_depth=10... 70/30: 0.9083, 10-fold: 0.9088\n",
            "\n",
            "Processando: vgg19_max_256x256 (1)\n",
            "Shape: (800, 514)\n",
            "Distribuição de classes: {'American_Bulldog': np.int64(200), 'Bengal': np.int64(200), 'Pug': np.int64(200), 'Ragdoll': np.int64(200)}\n",
            "  max_depth=2... 70/30: 0.9083, 10-fold: 0.8825\n",
            "  max_depth=3... 70/30: 0.9375, 10-fold: 0.9075\n",
            "  max_depth=4... 70/30: 0.9292, 10-fold: 0.9100\n",
            "  max_depth=5... 70/30: 0.9292, 10-fold: 0.9113\n",
            "  max_depth=6... 70/30: 0.9250, 10-fold: 0.9100\n",
            "  max_depth=7... 70/30: 0.9375, 10-fold: 0.9113\n",
            "  max_depth=8... 70/30: 0.9375, 10-fold: 0.9138\n",
            "  max_depth=9... 70/30: 0.9375, 10-fold: 0.9138\n",
            "  max_depth=10... 70/30: 0.9375, 10-fold: 0.9138\n",
            "\n",
            "Criando tabela de resultados...\n",
            "Calculando estatísticas...\n",
            "\n",
            "========================================================================================================================\n",
            "TABELA DE RESULTADOS - ÁRVORE DE DECISÃO (Acurácia)\n",
            "========================================================================================================================\n",
            "                         Bases Treino/Teste    md=2    md=3    md=4    md=5    md=6    md=7    md=8    md=9   md=10\n",
            "PCA_CNN_VGG16_128_avg (1) (10)        70/30  0.8667  0.8792  0.8625  0.8875  0.8958  0.9083  0.8958  0.8958  0.8958\n",
            "                                 10-fold CV   0.835  0.8788   0.885  0.8762  0.8925  0.8938  0.8825  0.8875  0.8888\n",
            "PCA_CNN_VGG16_128_max (1) (10)        70/30     0.8  0.7375  0.8333  0.8542    0.85  0.8708  0.8792  0.8792  0.8792\n",
            "                                 10-fold CV  0.7912    0.81  0.8538  0.8575    0.87  0.8712   0.865  0.8675  0.8612\n",
            "PCA_CNN_VGG16_256_avg (1) (10)        70/30     0.9     0.9  0.9083  0.9208  0.9167  0.9208  0.9208  0.9208  0.9208\n",
            "                                 10-fold CV  0.8825  0.9238  0.9262  0.9412  0.9388  0.9388  0.9388  0.9388  0.9388\n",
            "PCA_CNN_VGG16_256_max (1) (10)        70/30  0.8583  0.8917   0.925  0.9625  0.9625  0.9667  0.9667  0.9667  0.9667\n",
            "                                 10-fold CV  0.8775    0.92   0.935  0.9562  0.9562  0.9538  0.9538  0.9538  0.9538\n",
            "PCA_CNN_VGG19_256_avg (1) (10)        70/30  0.8625  0.8875  0.8958     0.9  0.8792  0.8917  0.8958  0.8958  0.8958\n",
            "                                 10-fold CV   0.865   0.905  0.9288  0.9288  0.9362   0.935  0.9337  0.9337  0.9337\n",
            "PCA_CNN_VGG19_256_max (1) (10)        70/30  0.8625  0.9208  0.9208   0.925   0.925   0.925   0.925   0.925   0.925\n",
            "                                 10-fold CV  0.9088  0.9438  0.9563    0.95  0.9513  0.9525  0.9538  0.9538  0.9538\n",
            "   vgg16_avg_128x128 (1) (512)        70/30  0.8083  0.8375  0.8333  0.8583  0.8125  0.8125  0.8125  0.8125  0.8125\n",
            "                                 10-fold CV  0.7638   0.785  0.8238  0.8438   0.825  0.8112    0.83  0.8288  0.8288\n",
            "   vgg16_avg_256x256 (1) (512)        70/30  0.8875  0.8875  0.9208  0.9083  0.9083  0.9083  0.9083  0.9083  0.9083\n",
            "                                 10-fold CV  0.8825   0.895  0.9025  0.8975  0.8912  0.8938  0.8938  0.8938  0.8938\n",
            "   vgg16_max_128x128 (1) (512)        70/30  0.7917  0.7792  0.8292  0.8458  0.8375  0.8292  0.7917  0.8333  0.8333\n",
            "                                 10-fold CV  0.7562  0.7612  0.7862  0.7975  0.8062  0.7775  0.7788  0.7812  0.7762\n",
            "   vgg16_max_256x256 (1) (512)        70/30  0.8792  0.9292  0.9083  0.9042  0.9083  0.9083  0.9083  0.9083  0.9083\n",
            "                                 10-fold CV  0.8525  0.9138  0.9138   0.895  0.9013  0.9025  0.9038  0.9038  0.9038\n",
            "   vgg19_avg_256x256 (1) (512)        70/30  0.8833  0.9292  0.9125  0.9125  0.8958  0.9083  0.9083  0.9083  0.9083\n",
            "                                 10-fold CV  0.8862  0.9212    0.91  0.9088   0.915  0.9088  0.9088  0.9088  0.9088\n",
            "   vgg19_max_256x256 (1) (512)        70/30  0.9083  0.9375  0.9292  0.9292   0.925  0.9375  0.9375  0.9375  0.9375\n",
            "                                 10-fold CV  0.8825  0.9075    0.91  0.9113    0.91  0.9113  0.9138  0.9138  0.9138\n",
            "                                                                                                                   \n",
            "                      Média =>      #DIV/0!  0.8590  0.8764  0.8899  0.9007  0.8931  0.8990  0.8958  0.8993  0.8993\n",
            "                 Desv. Pad. =>      #DIV/0!  0.0388  0.0622  0.0390  0.0344  0.0421  0.0434  0.0493  0.0423  0.0423\n",
            "                                                                                                                   \n",
            "                      Média =>      #DIV/0!  0.8486  0.8804  0.8943  0.8970  0.8995  0.8958  0.8964  0.8971  0.8963\n",
            "                 Desv. Pad. =>      #DIV/0!  0.0512  0.0604  0.0496  0.0470  0.0471  0.0541  0.0520  0.0514  0.0528\n",
            "\n",
            "Resultados salvos em: resultados_arvore_decisao.csv\n",
            "\n",
            "============================================================\n",
            "ANÁLISE DOS MELHORES RESULTADOS\n",
            "============================================================\n",
            "\n",
            "Melhores max_depth por método de validação:\n",
            "70/30 - Melhor max_depth: 5 (Acurácia: 0.9007)\n",
            "10-fold - Melhor max_depth: 6 (Acurácia: 0.8995)\n",
            "\n",
            "Análise de Overfitting:\n",
            "Comparando performance entre 70/30 e 10-fold CV por max_depth:\n",
            "max_depth=2: 70/30=0.8590, 10-fold=0.8486, diff=0.0104 OK\n",
            "max_depth=3: 70/30=0.8764, 10-fold=0.8804, diff=-0.0040 OK\n",
            "max_depth=4: 70/30=0.8899, 10-fold=0.8943, diff=-0.0044 OK\n",
            "max_depth=5: 70/30=0.9007, 10-fold=0.8970, diff=0.0037 OK\n",
            "max_depth=6: 70/30=0.8931, 10-fold=0.8995, diff=-0.0064 OK\n",
            "max_depth=7: 70/30=0.8990, 10-fold=0.8958, diff=0.0031 OK\n",
            "max_depth=8: 70/30=0.8958, 10-fold=0.8964, diff=-0.0006 OK\n",
            "max_depth=9: 70/30=0.8993, 10-fold=0.8971, diff=0.0022 OK\n",
            "max_depth=10: 70/30=0.8993, 10-fold=0.8963, diff=0.0030 OK\n",
            "\n",
            "Melhores bases por max_depth:\n",
            "max_depth=2: vgg19_max_256x256 (1) (512) (Acurácia: 0.9083)\n",
            "max_depth=3: vgg19_max_256x256 (1) (512) (Acurácia: 0.9375)\n",
            "max_depth=4: vgg19_max_256x256 (1) (512) (Acurácia: 0.9292)\n",
            "max_depth=5: PCA_CNN_VGG16_256_max (1) (10) (Acurácia: 0.9625)\n",
            "max_depth=6: PCA_CNN_VGG16_256_max (1) (10) (Acurácia: 0.9625)\n",
            "max_depth=7: PCA_CNN_VGG16_256_max (1) (10) (Acurácia: 0.9667)\n",
            "max_depth=8: PCA_CNN_VGG16_256_max (1) (10) (Acurácia: 0.9667)\n",
            "max_depth=9: PCA_CNN_VGG16_256_max (1) (10) (Acurácia: 0.9667)\n",
            "max_depth=10: PCA_CNN_VGG16_256_max (1) (10) (Acurácia: 0.9667)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_34b6613b-d789-408a-8e57-795f41b3296c\", \"resultados_arvore_decisao.csv\", 2451)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "EXPERIMENTOS COM ÁRVORE DE DECISÃO CONCLUÍDOS!\n",
            "============================================================\n",
            "Arquivo gerado: resultados_arvore_decisao.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import cross_val_score, train_test_split, StratifiedKFold\n",
        "from sklearn.naive_bayes import GaussianNB, MultinomialNB, ComplementNB\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score\n",
        "import warnings\n",
        "from google.colab import files\n",
        "import io\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"Por favor, faça o upload dos arquivos CSV dos datasets (HOG, CNN, PCA, etc.).\")\n",
        "arquivos_uploaded = files.upload()\n",
        "\n",
        "datasets = {}\n",
        "for nome_arquivo, conteudo in arquivos_uploaded.items():\n",
        "    try:\n",
        "        nome_base = nome_arquivo.replace('dataset_', '').replace('.csv', '')\n",
        "        df = pd.read_csv(io.StringIO(conteudo.decode('utf-8')))\n",
        "\n",
        "        if 'label' in df.columns and 'filename' in df.columns:\n",
        "            datasets[nome_base] = df\n",
        "            print(f\" Arquivo {nome_arquivo} carregado com sucesso como '{nome_base}'\")\n",
        "        else:\n",
        "            print(f\" Ignorando {nome_arquivo}: faltam as colunas 'label' ou 'filename'.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\" Erro ao processar {nome_arquivo}: {e}\")\n",
        "\n",
        "if not datasets:\n",
        "    print(\"\\nERRO: Nenhum dataset válido foi carregado. Por favor, faça o upload dos arquivos CSV corretos.\")\n",
        "else:\n",
        "    print(f\"\\n{len(datasets)} datasets carregados com sucesso.\")\n",
        "\n",
        "classificadores = {\n",
        "    'GaussianNB': (GaussianNB(), StandardScaler()),\n",
        "    'MultinomialNB': (MultinomialNB(), MinMaxScaler()),\n",
        "    'ComplementNB': (ComplementNB(), MinMaxScaler())\n",
        "}\n",
        "\n",
        "lista_resultados = []\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Executando Experimentos com Naive Bayes\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "nomes_datasets_ordenados = sorted(datasets.keys())\n",
        "\n",
        "for nome_dataset in nomes_datasets_ordenados:\n",
        "    df = datasets[nome_dataset]\n",
        "    print(f\"\\nProcessando dataset: {nome_dataset} (Shape: {df.shape})\")\n",
        "\n",
        "    X = df.drop(columns=['label', 'filename'])\n",
        "    y = df['label']\n",
        "\n",
        "    linha_70_30 = {'Bases': nome_dataset, 'Treino/Teste': '70/30'}\n",
        "    linha_10_fold = {'Bases': '', 'Treino/Teste': '10-fold CV'}\n",
        "\n",
        "    for nome_clf, (clf, normalizador) in classificadores.items():\n",
        "        print(f\"  -> Classificador: {nome_clf}...\")\n",
        "\n",
        "        X_treino, X_teste, y_treino, y_teste = train_test_split(\n",
        "            X, y, test_size=0.3, random_state=42, stratify=y\n",
        "        )\n",
        "\n",
        "        X_treino_normalizado = normalizador.fit_transform(X_treino)\n",
        "        X_teste_normalizado = normalizador.transform(X_teste)\n",
        "\n",
        "        clf.fit(X_treino_normalizado, y_treino)\n",
        "        y_pred = clf.predict(X_teste_normalizado)\n",
        "        acuracia_70_30 = accuracy_score(y_teste, y_pred)\n",
        "        linha_70_30[nome_clf] = round(acuracia_70_30, 4)\n",
        "\n",
        "        pipeline = Pipeline([\n",
        "            ('normalizador', normalizador),\n",
        "            ('classificador', clf)\n",
        "        ])\n",
        "\n",
        "        estrategia_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "        scores_cv = cross_val_score(pipeline, X, y, cv=estrategia_cv, scoring='accuracy')\n",
        "        acuracia_10_fold = scores_cv.mean()\n",
        "        linha_10_fold[nome_clf] = round(acuracia_10_fold, 4)\n",
        "\n",
        "        print(f\"     Acurácia (70/30): {acuracia_70_30:.4f}\")\n",
        "        print(f\"     Acurácia (10-fold): {acuracia_10_fold:.4f}\")\n",
        "\n",
        "    lista_resultados.append(linha_70_30)\n",
        "    lista_resultados.append(linha_10_fold)\n",
        "\n",
        "if lista_resultados:\n",
        "    df_resultados = pd.DataFrame(lista_resultados)\n",
        "\n",
        "    linhas_estatisticas = []\n",
        "\n",
        "    linha_separadora = {col: '' for col in df_resultados.columns}\n",
        "    linhas_estatisticas.append(linha_separadora)\n",
        "\n",
        "    for metodo in ['70/30', '10-fold CV']:\n",
        "        df_metodo = df_resultados[df_resultados['Treino/Teste'] == metodo]\n",
        "\n",
        "        linha_media = {'Bases': 'Média =>', 'Treino/Teste': ''}\n",
        "        for nome_clf in classificadores.keys():\n",
        "            linha_media[nome_clf] = round(df_metodo[nome_clf].astype(float).mean(), 4)\n",
        "        linhas_estatisticas.append(linha_media)\n",
        "\n",
        "        linha_desvio_padrao = {'Bases': 'Desv. Pad. =>', 'Treino/Teste': ''}\n",
        "        for nome_clf in classificadores.keys():\n",
        "            linha_desvio_padrao[nome_clf] = round(df_metodo[nome_clf].astype(float).std(), 4)\n",
        "        linhas_estatisticas.append(linha_desvio_padrao)\n",
        "\n",
        "    df_estatisticas = pd.DataFrame(linhas_estatisticas)\n",
        "    df_final = pd.concat([df_resultados, df_estatisticas], ignore_index=True)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"Tabela Final de Resultados: Naive Bayes (Acurácia)\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    pd.set_option('display.max_rows', None)\n",
        "    pd.set_option('display.max_columns', None)\n",
        "    pd.set_option('display.width', 120)\n",
        "\n",
        "    print(df_final.to_string(index=False))\n",
        "\n",
        "    nome_arquivo_csv = 'resultados_naive_bayes.csv'\n",
        "    df_final.to_csv(nome_arquivo_csv, index=False)\n",
        "    print(f\"\\nResultados salvos em '{nome_arquivo_csv}'\")\n",
        "    files.download(nome_arquivo_csv)\n",
        "else:\n",
        "    print(\"\\nNenhum experimento foi executado. Não é possível gerar resultados.\")"
      ],
      "metadata": {
        "id": "-eRQDzeRywaQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a08ab40e-9a2e-4bfc-94c2-ba2e2304fea8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Por favor, faça o upload dos arquivos CSV dos datasets (HOG, CNN, PCA, etc.).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-9b07facc-c3fe-466e-afa3-71c5b1410e90\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-9b07facc-c3fe-466e-afa3-71c5b1410e90\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving dataset_PCA_CNN_VGG16_128_avg.csv to dataset_PCA_CNN_VGG16_128_avg (2).csv\n",
            "Saving dataset_PCA_CNN_VGG16_128_max.csv to dataset_PCA_CNN_VGG16_128_max (2).csv\n",
            "Saving dataset_PCA_CNN_VGG16_256_avg.csv to dataset_PCA_CNN_VGG16_256_avg (2).csv\n",
            "Saving dataset_PCA_CNN_VGG16_256_max.csv to dataset_PCA_CNN_VGG16_256_max (2).csv\n",
            "Saving dataset_PCA_CNN_VGG19_256_avg.csv to dataset_PCA_CNN_VGG19_256_avg (2).csv\n",
            "Saving dataset_PCA_CNN_VGG19_256_max.csv to dataset_PCA_CNN_VGG19_256_max (2).csv\n",
            "Saving dataset_vgg16_avg_128x128.csv to dataset_vgg16_avg_128x128 (2).csv\n",
            "Saving dataset_vgg16_avg_256x256.csv to dataset_vgg16_avg_256x256 (2).csv\n",
            "Saving dataset_vgg16_max_128x128.csv to dataset_vgg16_max_128x128 (2).csv\n",
            "Saving dataset_vgg16_max_256x256.csv to dataset_vgg16_max_256x256 (2).csv\n",
            "Saving dataset_vgg19_avg_256x256.csv to dataset_vgg19_avg_256x256 (2).csv\n",
            "Saving dataset_vgg19_max_256x256.csv to dataset_vgg19_max_256x256 (2).csv\n",
            " Arquivo dataset_PCA_CNN_VGG16_128_avg (2).csv carregado com sucesso como 'PCA_CNN_VGG16_128_avg (2)'\n",
            " Arquivo dataset_PCA_CNN_VGG16_128_max (2).csv carregado com sucesso como 'PCA_CNN_VGG16_128_max (2)'\n",
            " Arquivo dataset_PCA_CNN_VGG16_256_avg (2).csv carregado com sucesso como 'PCA_CNN_VGG16_256_avg (2)'\n",
            " Arquivo dataset_PCA_CNN_VGG16_256_max (2).csv carregado com sucesso como 'PCA_CNN_VGG16_256_max (2)'\n",
            " Arquivo dataset_PCA_CNN_VGG19_256_avg (2).csv carregado com sucesso como 'PCA_CNN_VGG19_256_avg (2)'\n",
            " Arquivo dataset_PCA_CNN_VGG19_256_max (2).csv carregado com sucesso como 'PCA_CNN_VGG19_256_max (2)'\n",
            " Arquivo dataset_vgg16_avg_128x128 (2).csv carregado com sucesso como 'vgg16_avg_128x128 (2)'\n",
            " Arquivo dataset_vgg16_avg_256x256 (2).csv carregado com sucesso como 'vgg16_avg_256x256 (2)'\n",
            " Arquivo dataset_vgg16_max_128x128 (2).csv carregado com sucesso como 'vgg16_max_128x128 (2)'\n",
            " Arquivo dataset_vgg16_max_256x256 (2).csv carregado com sucesso como 'vgg16_max_256x256 (2)'\n",
            " Arquivo dataset_vgg19_avg_256x256 (2).csv carregado com sucesso como 'vgg19_avg_256x256 (2)'\n",
            " Arquivo dataset_vgg19_max_256x256 (2).csv carregado com sucesso como 'vgg19_max_256x256 (2)'\n",
            "\n",
            "12 datasets carregados com sucesso.\n",
            "\n",
            "================================================================================\n",
            "Executando Experimentos com Naive Bayes\n",
            "================================================================================\n",
            "\n",
            "Processando dataset: PCA_CNN_VGG16_128_avg (2) (Shape: (800, 12))\n",
            "  -> Classificador: GaussianNB...\n",
            "     Acurácia (70/30): 0.9208\n",
            "     Acurácia (10-fold): 0.9287\n",
            "  -> Classificador: MultinomialNB...\n",
            "     Acurácia (70/30): 0.9042\n",
            "     Acurácia (10-fold): 0.8887\n",
            "  -> Classificador: ComplementNB...\n",
            "     Acurácia (70/30): 0.8875\n",
            "     Acurácia (10-fold): 0.8913\n",
            "\n",
            "Processando dataset: PCA_CNN_VGG16_128_max (2) (Shape: (800, 12))\n",
            "  -> Classificador: GaussianNB...\n",
            "     Acurácia (70/30): 0.9208\n",
            "     Acurácia (10-fold): 0.9387\n",
            "  -> Classificador: MultinomialNB...\n",
            "     Acurácia (70/30): 0.9333\n",
            "     Acurácia (10-fold): 0.9288\n",
            "  -> Classificador: ComplementNB...\n",
            "     Acurácia (70/30): 0.9250\n",
            "     Acurácia (10-fold): 0.9238\n",
            "\n",
            "Processando dataset: PCA_CNN_VGG16_256_avg (2) (Shape: (800, 12))\n",
            "  -> Classificador: GaussianNB...\n",
            "     Acurácia (70/30): 0.9542\n",
            "     Acurácia (10-fold): 0.9600\n",
            "  -> Classificador: MultinomialNB...\n",
            "     Acurácia (70/30): 0.9417\n",
            "     Acurácia (10-fold): 0.9225\n",
            "  -> Classificador: ComplementNB...\n",
            "     Acurácia (70/30): 0.9458\n",
            "     Acurácia (10-fold): 0.9325\n",
            "\n",
            "Processando dataset: PCA_CNN_VGG16_256_max (2) (Shape: (800, 12))\n",
            "  -> Classificador: GaussianNB...\n",
            "     Acurácia (70/30): 0.9667\n",
            "     Acurácia (10-fold): 0.9688\n",
            "  -> Classificador: MultinomialNB...\n",
            "     Acurácia (70/30): 0.9792\n",
            "     Acurácia (10-fold): 0.9825\n",
            "  -> Classificador: ComplementNB...\n",
            "     Acurácia (70/30): 0.9792\n",
            "     Acurácia (10-fold): 0.9775\n",
            "\n",
            "Processando dataset: PCA_CNN_VGG19_256_avg (2) (Shape: (800, 12))\n",
            "  -> Classificador: GaussianNB...\n",
            "     Acurácia (70/30): 0.9542\n",
            "     Acurácia (10-fold): 0.9600\n",
            "  -> Classificador: MultinomialNB...\n",
            "     Acurácia (70/30): 0.9667\n",
            "     Acurácia (10-fold): 0.9375\n",
            "  -> Classificador: ComplementNB...\n",
            "     Acurácia (70/30): 0.9583\n",
            "     Acurácia (10-fold): 0.9412\n",
            "\n",
            "Processando dataset: PCA_CNN_VGG19_256_max (2) (Shape: (800, 12))\n",
            "  -> Classificador: GaussianNB...\n",
            "     Acurácia (70/30): 0.9542\n",
            "     Acurácia (10-fold): 0.9800\n",
            "  -> Classificador: MultinomialNB...\n",
            "     Acurácia (70/30): 0.9458\n",
            "     Acurácia (10-fold): 0.9550\n",
            "  -> Classificador: ComplementNB...\n",
            "     Acurácia (70/30): 0.9458\n",
            "     Acurácia (10-fold): 0.9713\n",
            "\n",
            "Processando dataset: vgg16_avg_128x128 (2) (Shape: (800, 514))\n",
            "  -> Classificador: GaussianNB...\n",
            "     Acurácia (70/30): 0.9208\n",
            "     Acurácia (10-fold): 0.9250\n",
            "  -> Classificador: MultinomialNB...\n",
            "     Acurácia (70/30): 0.9500\n",
            "     Acurácia (10-fold): 0.9375\n",
            "  -> Classificador: ComplementNB...\n",
            "     Acurácia (70/30): 0.9500\n",
            "     Acurácia (10-fold): 0.9375\n",
            "\n",
            "Processando dataset: vgg16_avg_256x256 (2) (Shape: (800, 514))\n",
            "  -> Classificador: GaussianNB...\n",
            "     Acurácia (70/30): 0.9542\n",
            "     Acurácia (10-fold): 0.9675\n",
            "  -> Classificador: MultinomialNB...\n",
            "     Acurácia (70/30): 0.9875\n",
            "     Acurácia (10-fold): 0.9875\n",
            "  -> Classificador: ComplementNB...\n",
            "     Acurácia (70/30): 0.9875\n",
            "     Acurácia (10-fold): 0.9850\n",
            "\n",
            "Processando dataset: vgg16_max_128x128 (2) (Shape: (800, 514))\n",
            "  -> Classificador: GaussianNB...\n",
            "     Acurácia (70/30): 0.9250\n",
            "     Acurácia (10-fold): 0.9225\n",
            "  -> Classificador: MultinomialNB...\n",
            "     Acurácia (70/30): 0.9458\n",
            "     Acurácia (10-fold): 0.9462\n",
            "  -> Classificador: ComplementNB...\n",
            "     Acurácia (70/30): 0.9458\n",
            "     Acurácia (10-fold): 0.9400\n",
            "\n",
            "Processando dataset: vgg16_max_256x256 (2) (Shape: (800, 514))\n",
            "  -> Classificador: GaussianNB...\n",
            "     Acurácia (70/30): 0.9583\n",
            "     Acurácia (10-fold): 0.9700\n",
            "  -> Classificador: MultinomialNB...\n",
            "     Acurácia (70/30): 0.9875\n",
            "     Acurácia (10-fold): 0.9850\n",
            "  -> Classificador: ComplementNB...\n",
            "     Acurácia (70/30): 0.9875\n",
            "     Acurácia (10-fold): 0.9887\n",
            "\n",
            "Processando dataset: vgg19_avg_256x256 (2) (Shape: (800, 514))\n",
            "  -> Classificador: GaussianNB...\n",
            "     Acurácia (70/30): 0.9417\n",
            "     Acurácia (10-fold): 0.9600\n",
            "  -> Classificador: MultinomialNB...\n",
            "     Acurácia (70/30): 0.9917\n",
            "     Acurácia (10-fold): 0.9875\n",
            "  -> Classificador: ComplementNB...\n",
            "     Acurácia (70/30): 0.9917\n",
            "     Acurácia (10-fold): 0.9887\n",
            "\n",
            "Processando dataset: vgg19_max_256x256 (2) (Shape: (800, 514))\n",
            "  -> Classificador: GaussianNB...\n",
            "     Acurácia (70/30): 0.9500\n",
            "     Acurácia (10-fold): 0.9625\n",
            "  -> Classificador: MultinomialNB...\n",
            "     Acurácia (70/30): 0.9958\n",
            "     Acurácia (10-fold): 0.9925\n",
            "  -> Classificador: ComplementNB...\n",
            "     Acurácia (70/30): 0.9875\n",
            "     Acurácia (10-fold): 0.9875\n",
            "\n",
            "================================================================================\n",
            "Tabela Final de Resultados: Naive Bayes (Acurácia)\n",
            "================================================================================\n",
            "                    Bases Treino/Teste GaussianNB MultinomialNB ComplementNB\n",
            "PCA_CNN_VGG16_128_avg (2)        70/30     0.9208        0.9042       0.8875\n",
            "                            10-fold CV     0.9288        0.8888       0.8913\n",
            "PCA_CNN_VGG16_128_max (2)        70/30     0.9208        0.9333        0.925\n",
            "                            10-fold CV     0.9388        0.9288       0.9238\n",
            "PCA_CNN_VGG16_256_avg (2)        70/30     0.9542        0.9417       0.9458\n",
            "                            10-fold CV       0.96        0.9225       0.9325\n",
            "PCA_CNN_VGG16_256_max (2)        70/30     0.9667        0.9792       0.9792\n",
            "                            10-fold CV     0.9688        0.9825       0.9775\n",
            "PCA_CNN_VGG19_256_avg (2)        70/30     0.9542        0.9667       0.9583\n",
            "                            10-fold CV       0.96        0.9375       0.9412\n",
            "PCA_CNN_VGG19_256_max (2)        70/30     0.9542        0.9458       0.9458\n",
            "                            10-fold CV       0.98         0.955       0.9712\n",
            "    vgg16_avg_128x128 (2)        70/30     0.9208          0.95         0.95\n",
            "                            10-fold CV      0.925        0.9375       0.9375\n",
            "    vgg16_avg_256x256 (2)        70/30     0.9542        0.9875       0.9875\n",
            "                            10-fold CV     0.9675        0.9875        0.985\n",
            "    vgg16_max_128x128 (2)        70/30      0.925        0.9458       0.9458\n",
            "                            10-fold CV     0.9225        0.9462         0.94\n",
            "    vgg16_max_256x256 (2)        70/30     0.9583        0.9875       0.9875\n",
            "                            10-fold CV       0.97         0.985       0.9887\n",
            "    vgg19_avg_256x256 (2)        70/30     0.9417        0.9917       0.9917\n",
            "                            10-fold CV       0.96        0.9875       0.9887\n",
            "    vgg19_max_256x256 (2)        70/30       0.95        0.9958       0.9875\n",
            "                            10-fold CV     0.9625        0.9925       0.9875\n",
            "                                                                            \n",
            "                 Média =>                  0.9434        0.9608       0.9576\n",
            "            Desv. Pad. =>                  0.0169        0.0284       0.0313\n",
            "                 Média =>                  0.9537        0.9543       0.9554\n",
            "            Desv. Pad. =>                  0.0196         0.033        0.032\n",
            "\n",
            "Resultados salvos em 'resultados_naive_bayes.csv'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_91124eca-4580-424f-a2dc-10b7ccdade86\", \"resultados_naive_bayes.csv\", 1180)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multilayer Perceptron"
      ],
      "metadata": {
        "id": "PrxJ_2_Llk4_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "import warnings\n",
        "from google.colab import files\n",
        "import io\n",
        "\n",
        "warnings.filterwarnings('ignore', category=UserWarning)"
      ],
      "metadata": {
        "id": "fwrAMVHhhj1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\"*80)\n",
        "print(\"INICIALIZANDO O CARREGAMENTO DOS DADOS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Solicita o upload dos arquivos .csv\n",
        "print(\"\\nPor favor, faça o upload dos arquivos CSV dos datasets a serem utilizados.\")\n",
        "try:\n",
        "    uploaded_files = files.upload()\n",
        "    if not uploaded_files:\n",
        "        raise ValueError(\"Nenhum arquivo foi selecionado.\")\n",
        "except Exception as e:\n",
        "    print(f\"\\nOcorreu um erro durante o upload: {e}\")\n",
        "    # Interrompe a execução se o upload falhar\n",
        "    exit()\n",
        "\n",
        "# Dicionário para armazenar os dataframes carregados\n",
        "datasets = {}\n",
        "\n",
        "# Processa e valida cada arquivo carregado\n",
        "print(\"\\n--- Validando arquivos carregados ---\")\n",
        "for filename, content in uploaded_files.items():\n",
        "    try:\n",
        "        # Cria um nome base para o dataset removendo prefixos e sufixos\n",
        "        base_name = filename.replace('dataset_', '').replace('.csv', '')\n",
        "        df = pd.read_csv(io.StringIO(content.decode('utf-8')))\n",
        "\n",
        "        # Verifica a presença das colunas essenciais\n",
        "        if 'label' in df.columns and 'filename' in df.columns:\n",
        "            datasets[base_name] = df\n",
        "            print(f\"  - SUCESSO: Arquivo '{filename}' carregado como '{base_name}'. Shape: {df.shape}\")\n",
        "        else:\n",
        "            print(f\"  - AVISO: Arquivo '{filename}' ignorado por não conter as colunas 'label' ou 'filename'.\")\n",
        "    except Exception as e:\n",
        "        print(f\"  - ERRO: Falha ao processar o arquivo '{filename}': {e}\")\n",
        "\n",
        "if not datasets:\n",
        "    print(\"\\nERRO  Nenhum dataset válido foi carregado. Os experimentos não podem continuar.\")\n",
        "else:\n",
        "    print(f\"\\nTotal de {len(datasets)} datasets prontos para o experimento.\")"
      ],
      "metadata": {
        "id": "X24n2uNzlwih",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "9ef8febb-65dc-4a77-d99d-058e116a853f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "INICIALIZANDO O CARREGAMENTO DOS DADOS\n",
            "================================================================================\n",
            "\n",
            "Por favor, faça o upload dos arquivos CSV dos datasets a serem utilizados.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-23dacd7c-9f81-4f6d-929e-4df53adff05f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-23dacd7c-9f81-4f6d-929e-4df53adff05f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving dataset_PCA_CNN_VGG16_256_max.csv to dataset_PCA_CNN_VGG16_256_max.csv\n",
            "\n",
            "--- Validando arquivos carregados ---\n",
            "  - SUCESSO: Arquivo 'dataset_PCA_CNN_VGG16_256_max.csv' carregado como 'PCA_CNN_VGG16_256_max'. Shape: (800, 12)\n",
            "\n",
            "Total de 1 datasets prontos para o experimento.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data(df):\n",
        "    \"\"\"\n",
        "    Prepara os dados para o modelo:\n",
        "    1. Separa features (X) e rótulos (y).\n",
        "    2. Aplica padronização (StandardScaler) nas features.\n",
        "    \"\"\"\n",
        "    X = df.drop(columns=['label', 'filename'])\n",
        "    y = df['label']\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "    return X_scaled, y"
      ],
      "metadata": {
        "id": "-5j044dpnBcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"EXPERIMENTO 1: AVALIAÇÃO DAS FUNÇÕES DE ATIVAÇÃO\")\n",
        "print(\"Utilizando o solver 'adam' (padrão) e outros parâmetros default.\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "activation_functions = ['identity', 'logistic', 'tanh', 'relu']\n",
        "results_activation = []\n",
        "\n",
        "# Garante que existem datasets para processar\n",
        "if not datasets:\n",
        "    print(\"ERRO: Nenhum dataset disponível para o experimento.\")\n",
        "else:\n",
        "    for dataset_name, df in sorted(datasets.items()):\n",
        "        print(f\"\\nProcessando dataset: {dataset_name}\")\n",
        "        X, y = prepare_data(df)\n",
        "\n",
        "        row_70_30 = {'Base': dataset_name, 'Treino/Teste': '70/30'}\n",
        "        row_10_fold = {'Base': '', 'Treino/Teste': '10-fold CV'}\n",
        "\n",
        "        for activation in activation_functions:\n",
        "            print(f\"  -> Testando ativação: '{activation}'...\")\n",
        "            mlp = MLPClassifier(activation=activation, random_state=42, max_iter=500)\n",
        "\n",
        "            # Validação 70/30\n",
        "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "            mlp.fit(X_train, y_train)\n",
        "            acc_70_30 = accuracy_score(y_test, mlp.predict(X_test))\n",
        "\n",
        "            # Validação 10-fold Cross-Validation\n",
        "            cv_strategy = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "            acc_10_fold = cross_val_score(mlp, X, y, cv=cv_strategy, scoring='accuracy').mean()\n",
        "\n",
        "            row_70_30[activation] = round(acc_70_30, 4)\n",
        "            row_10_fold[activation] = round(acc_10_fold, 4)\n",
        "\n",
        "        results_activation.append(row_70_30)\n",
        "        results_activation.append(row_10_fold)\n",
        "\n",
        "    df_results_activation = pd.DataFrame(results_activation)\n",
        "    df_results_activation = df_results_activation[['Base', 'Treino/Teste'] + activation_functions]\n",
        "\n",
        "    avg_scores = {func: df_results_activation[func].astype(float).mean() for func in activation_functions}\n",
        "    best_activation = max(avg_scores, key=avg_scores.get)\n",
        "\n",
        "    print(\"\\nTABELA DE RESULTADOS - FUNÇÕES DE ATIVAÇÃO\\n\")\n",
        "    print(df_results_activation.to_string(index=False))\n",
        "    print(\"\\n--- Análise das Funções de Ativação ---\")\n",
        "    for func, score in sorted(avg_scores.items(), key=lambda item: item[1], reverse=True):\n",
        "        print(f\"  - Média de acurácia para '{func}': {score:.4f}\")\n",
        "\n",
        "    print(f\"\\n=> MELHOR FUNÇÃO DE ATIVAÇÃO ESCOLHIDA: '{best_activation}'\")\n",
        "\n",
        "    filename_activation = 'resultados_mlp_ativacao.csv'\n",
        "    df_results_activation.to_csv(filename_activation, index=False)\n",
        "    print(f\"\\nTabela de resultados salva em '{filename_activation}'.\")\n",
        "    files.download(filename_activation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "id": "rL7vB8NZnJwP",
        "outputId": "cd6b4594-20fd-4e6a-a7a1-0e0391d8e65c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "EXPERIMENTO 1: AVALIAÇÃO DAS FUNÇÕES DE ATIVAÇÃO\n",
            "Utilizando o solver 'adam' (padrão) e outros parâmetros default.\n",
            "================================================================================\n",
            "\n",
            "Processando dataset: PCA_CNN_VGG16_256_max\n",
            "  -> Testando ativação: 'identity'...\n",
            "  -> Testando ativação: 'logistic'...\n",
            "  -> Testando ativação: 'tanh'...\n",
            "  -> Testando ativação: 'relu'...\n",
            "\n",
            "TABELA DE RESULTADOS - FUNÇÕES DE ATIVAÇÃO\n",
            "\n",
            "                 Base Treino/Teste  identity  logistic   tanh   relu\n",
            "PCA_CNN_VGG16_256_max        70/30    0.9833    0.9875 0.9875 0.9917\n",
            "                        10-fold CV    0.9862    0.9900 0.9850 0.9875\n",
            "\n",
            "--- Análise das Funções de Ativação ---\n",
            "  - Média de acurácia para 'relu': 0.9896\n",
            "  - Média de acurácia para 'logistic': 0.9888\n",
            "  - Média de acurácia para 'tanh': 0.9863\n",
            "  - Média de acurácia para 'identity': 0.9848\n",
            "\n",
            "=> MELHOR FUNÇÃO DE ATIVAÇÃO ESCOLHIDA: 'relu'\n",
            "\n",
            "Tabela de resultados salva em 'resultados_mlp_ativacao.csv'.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_5df3dc7c-d050-4e34-b859-8795b4f7a1fc\", \"resultados_mlp_ativacao.csv\", 139)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"EXPERIMENTO 2: AVALIAÇÃO DOS SOLVERS\")\n",
        "# A variável 'best_activation' foi definida na célula anterior\n",
        "print(f\"Utilizando a função de ativação '{best_activation}' (escolhida no passo anterior).\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "solvers = ['sgd', 'adam']\n",
        "results_solver = []\n",
        "\n",
        "if 'best_activation' not in locals():\n",
        "     print(\"ERRO: A célula anterior (Experimento 1) precisa ser executada primeiro.\")\n",
        "else:\n",
        "    for dataset_name, df in sorted(datasets.items()):\n",
        "        print(f\"\\nProcessando dataset: {dataset_name}\")\n",
        "        X, y = prepare_data(df)\n",
        "\n",
        "        row_70_30 = {'Base': dataset_name, 'Treino/Teste': '70/30'}\n",
        "        row_10_fold = {'Base': '', 'Treino/Teste': '10-fold CV'}\n",
        "\n",
        "        for solver in solvers:\n",
        "            print(f\"  -> Testando solver: '{solver}'...\")\n",
        "            mlp = MLPClassifier(activation=best_activation, solver=solver, random_state=42, max_iter=500)\n",
        "\n",
        "            # Validação 70/30\n",
        "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "            mlp.fit(X_train, y_train)\n",
        "            acc_70_30 = accuracy_score(y_test, mlp.predict(X_test))\n",
        "\n",
        "            # Validação 10-fold\n",
        "            cv_strategy = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "            acc_10_fold = cross_val_score(mlp, X, y, cv=cv_strategy, scoring='accuracy').mean()\n",
        "\n",
        "            row_70_30[solver] = round(acc_70_30, 4)\n",
        "            row_10_fold[solver] = round(acc_10_fold, 4)\n",
        "\n",
        "        results_solver.append(row_70_30)\n",
        "        results_solver.append(row_10_fold)\n",
        "\n",
        "    # Análise e exibição dos resultados\n",
        "    df_results_solver = pd.DataFrame(results_solver)\n",
        "    df_results_solver = df_results_solver[['Base', 'Treino/Teste'] + solvers]\n",
        "\n",
        "    avg_scores_solver = {solver: df_results_solver[solver].astype(float).mean() for solver in solvers}\n",
        "    best_solver = max(avg_scores_solver, key=avg_scores_solver.get)\n",
        "\n",
        "    print(\"\\nTABELA DE RESULTADOS - SOLVERS\\n\")\n",
        "    print(df_results_solver.to_string(index=False))\n",
        "    print(\"\\n--- Análise dos Solvers ---\")\n",
        "    for solver, score in sorted(avg_scores_solver.items(), key=lambda item: item[1], reverse=True):\n",
        "        print(f\"  - Média de acurácia para '{solver}': {score:.4f}\")\n",
        "\n",
        "    print(f\"\\n=> MELHOR SOLVER ESCOLHIDO: '{best_solver}'\")\n",
        "\n",
        "    filename_solver = 'resultados_mlp_solver.csv'\n",
        "    df_results_solver.to_csv(filename_solver, index=False)\n",
        "    print(f\"\\nTabela de resultados salva em '{filename_solver}'.\")\n",
        "    files.download(filename_solver)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "id": "hJvhWdqZppG6",
        "outputId": "49e35bcd-0951-498e-ce09-c2e06a17ed2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "EXPERIMENTO 2: AVALIAÇÃO DOS SOLVERS\n",
            "Utilizando a função de ativação 'relu' (escolhida no passo anterior).\n",
            "================================================================================\n",
            "\n",
            "Processando dataset: PCA_CNN_VGG16_256_max\n",
            "  -> Testando solver: 'sgd'...\n",
            "  -> Testando solver: 'adam'...\n",
            "\n",
            "TABELA DE RESULTADOS - SOLVERS\n",
            "\n",
            "                 Base Treino/Teste    sgd   adam\n",
            "PCA_CNN_VGG16_256_max        70/30 0.9875 0.9917\n",
            "                        10-fold CV 0.9888 0.9875\n",
            "\n",
            "--- Análise dos Solvers ---\n",
            "  - Média de acurácia para 'adam': 0.9896\n",
            "  - Média de acurácia para 'sgd': 0.9882\n",
            "\n",
            "=> MELHOR SOLVER ESCOLHIDO: 'adam'\n",
            "\n",
            "Tabela de resultados salva em 'resultados_mlp_solver.csv'.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_4420de4a-2c36-4089-97d1-fd0a1fc08916\", \"resultados_mlp_solver.csv\", 95)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"EXPERIMENTO 3: AVALIAÇÃO DO NÚMERO DE NEURÔNIOS NA CAMADA ESCONDIDA\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "#Verificação de Pré-requisitos\n",
        "# Garante que as variáveis dos experimentos 1 e 2 ('best_activation', 'best_solver') existam\n",
        "if 'best_activation' not in locals() or 'best_solver' not in locals():\n",
        "    print(\"ERRO: É necessário executar as células dos experimentos 1 e 2 primeiro.\")\n",
        "    print(\"      As variáveis 'best_activation' e 'best_solver' não foram encontradas.\")\n",
        "    # Interrompe a execução se os pré-requisitos não forem atendidos\n",
        "    exit()\n",
        "else:\n",
        "    print(f\"Parâmetros utilizados (definidos anteriormente):\")\n",
        "    print(f\"  - Função de Ativação: '{best_activation}' \")\n",
        "    print(f\"  - Solver: '{best_solver}' \")\n",
        "\n",
        "# Inicializa a lista que guardará os resultados\n",
        "results_hidden_layer = []\n",
        "\n"
      ],
      "metadata": {
        "id": "98MBQFAYqEmJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "317330c3-ddf8-45a9-ac5c-12e8ac9718e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "EXPERIMENTO 3: AVALIAÇÃO DO NÚMERO DE NEURÔNIOS NA CAMADA ESCONDIDA\n",
            "================================================================================\n",
            "Parâmetros utilizados (definidos anteriormente):\n",
            "  - Função de Ativação: 'relu' \n",
            "  - Solver: 'adam' \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import mean\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
        "warnings.filterwarnings('ignore', category=UserWarning)\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"EXPERIMENTO 4: INDUZINDO E OBSERVANDO OVERFITTING\")\n",
        "print(\"Testando configurações com número de neurônios bem altos.\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Inicializa uma nova lista de resultados para este experimento\n",
        "results_overfit_experiment = []\n",
        "\n",
        "for dataset_name, df in sorted(datasets.items()):\n",
        "\n",
        "    X, y = prepare_data(df)\n",
        "\n",
        "    print(f\"\\nProcessando dataset: {dataset_name}\")\n",
        "\n",
        "\n",
        "    num_attribs = X.shape[1]\n",
        "    num_classes = len(y.unique())\n",
        "    baseline_neurons = num_attribs + num_classes\n",
        "\n",
        "    extended_layer_configs = {\n",
        "        # Melhor configuração do experimento anterior (ponto de referência)\n",
        "        'Baseline': (baseline_neurons,),\n",
        "        #Configurações progressivamente maiores para forçar overfitting\n",
        "        '(over_1)(1)': (1,),\n",
        "        '(over_2)(50)': (50,),\n",
        "        '(over_3)(200)': (200,),\n",
        "        '(over_4)(500)': (500,),\n",
        "        '(over_5)(200, 100)': (200, 100,) # Rede com 2 camadas escondidas\n",
        "    }\n",
        "\n",
        "    print(f\"  - Configurações de neurônios a serem testadas: {extended_layer_configs}\")\n",
        "\n",
        "    # Dicionários para armazenar resultados\n",
        "    row_train = {'Base': dataset_name, 'Treino/Teste': 'Treino'}\n",
        "    row_70_30 = {'Base': '', 'Treino/Teste': '70/30'}\n",
        "    row_10_fold = {'Base': '', 'Treino/Teste': '10-fold CV'}\n",
        "\n",
        "    for config_name, layer_size in extended_layer_configs.items():\n",
        "        print(f\"    -> Testando hidden_layer_sizes = {layer_size}...\")\n",
        "\n",
        "        mlp = MLPClassifier(\n",
        "            hidden_layer_sizes=layer_size,\n",
        "            activation=best_activation,\n",
        "            solver=best_solver,\n",
        "            random_state=42,\n",
        "            max_iter=700,\n",
        "            alpha=1e-5\n",
        "        )\n",
        "\n",
        "        # Validação\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "        mlp.fit(X_train, y_train)\n",
        "\n",
        "        #CÁLCULO DAS ACURÁCIAS\n",
        "        #Acurácia no próprio dado de TREINO (chave para ver overfitting)\n",
        "        acc_train = metrics.accuracy_score(y_train, mlp.predict(X_train))\n",
        "\n",
        "        #Acurácia no dado de TESTE (validação 70/30)\n",
        "        acc_70_30 = metrics.accuracy_score(y_test, mlp.predict(X_test))\n",
        "\n",
        "        #Acurácia na VALIDAÇÃO CRUZADA\n",
        "        cv_strategy = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "        acc_10_fold = mean(cross_val_score(mlp, X, y, cv=cv_strategy, scoring='accuracy'))\n",
        "\n",
        "        # Armazenar resultados\n",
        "        row_train[config_name] = round(acc_train, 4)\n",
        "        row_70_30[config_name] = round(acc_70_30, 4)\n",
        "        row_10_fold[config_name] = round(acc_10_fold, 4)\n",
        "\n",
        "    results_overfit_experiment.append(row_train)\n",
        "    results_overfit_experiment.append(row_70_30)\n",
        "    results_overfit_experiment.append(row_10_fold)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zi6KWzugrK9w",
        "outputId": "5b116912-58bf-4c0a-fe03-0e07a307d8ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "EXPERIMENTO 4: INDUZINDO E OBSERVANDO OVERFITTING\n",
            "Testando configurações com número de neurônios bem altos.\n",
            "================================================================================\n",
            "\n",
            "Processando dataset: PCA_CNN_VGG16_256_max\n",
            "  - Configurações de neurônios a serem testadas: {'Baseline': (14,), '(over_1)(1)': (1,), '(over_2)(50)': (50,), '(over_3)(200)': (200,), '(over_4)(500)': (500,), '(over_5)(200, 100)': (200, 100)}\n",
            "    -> Testando hidden_layer_sizes = (14,)...\n",
            "    -> Testando hidden_layer_sizes = (1,)...\n",
            "    -> Testando hidden_layer_sizes = (50,)...\n",
            "    -> Testando hidden_layer_sizes = (200,)...\n",
            "    -> Testando hidden_layer_sizes = (500,)...\n",
            "    -> Testando hidden_layer_sizes = (200, 100)...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ANÁLISE DOS RESULTADOS DO EXPERIMENTO DE OVERFITTING\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "if not results_overfit_experiment:\n",
        "    print(\"ERRO: A lista de resultados 'results_overfit_experiment' está vazia. Por favor, execute a Célula 8 (Versão para Overfitting) primeiro.\")\n",
        "else:\n",
        "    # Cria o DataFrame com os resultados\n",
        "    df_results_overfit = pd.DataFrame(results_overfit_experiment)\n",
        "    # Define a ordem das colunas para melhor visualização\n",
        "    column_order_overfit = ['Base', 'Treino/Teste'] + list(list(extended_layer_configs.keys()))\n",
        "    df_results_overfit = df_results_overfit[column_order_overfit]\n",
        "\n",
        "    print(\"\\nTABELA DE RESULTADOS - EXPERIMENTO DE OVERFITTING\\n\")\n",
        "    print(df_results_overfit.to_string(index=False))\n",
        "\n",
        "    #isola os dados de treino e de validação\n",
        "    df_train_accs = df_results_overfit[df_results_overfit['Treino/Teste'] == 'Treino']\n",
        "    df_cv_accs = df_results_overfit[df_results_overfit['Treino/Teste'] == '10-fold CV']\n",
        "\n",
        "\n",
        "    # Salva e baixa o arqu\n",
        "    filename_overfit = 'resultados_mlp_overfitting.csv'\n",
        "    df_results_overfit.to_csv(filename_overfit, index=False)\n",
        "    print(f\"\\nTabela de resultados salva em '{filename_overfit}'.\")\n",
        "    files.download(filename_overfit)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "AozYOI3OxPO_",
        "outputId": "15ea120d-da38-481d-dbe8-8c960da37e39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ANÁLISE DOS RESULTADOS DO EXPERIMENTO DE OVERFITTING\n",
            "================================================================================\n",
            "\n",
            "TABELA DE RESULTADOS - EXPERIMENTO DE OVERFITTING\n",
            "\n",
            "                 Base Treino/Teste  Baseline  (over_1)(1)  (over_2)(50)  (over_3)(200)  (over_4)(500)  (over_5)(200, 100)\n",
            "PCA_CNN_VGG16_256_max       Treino    0.9964       0.6464        0.9982         1.0000         1.0000              1.0000\n",
            "                             70/30    0.9917       0.6708        0.9917         0.9917         0.9917              0.9917\n",
            "                        10-fold CV    0.9925       0.6175        0.9887         0.9900         0.9875              0.9887\n",
            "\n",
            "Tabela de resultados salva em 'resultados_mlp_overfitting.csv'.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_1659371f-ec1f-4bee-af06-05f4aaaaa8e4\", \"resultados_mlp_overfitting.csv\", 264)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "a. O que aconteceu com o desempenho da rede quando o número de neurônios aumentou?\n",
        "\n",
        "  O desempenho da rede seguiu uma curva clássica de aprendizado ao variar o número de neurônios:\n",
        "\n",
        "  De 1 para 14 neurônios: Ocorreu um salto drástico e positivo no desempenho. A acurácia de validação (10-fold CV) subiu de 61.75% para 99.25%. Isso mostra que 1 neurônio era insuficiente e que 14 neurônios foram capazes de capturar a complexidade do problema de forma muito eficaz.\n",
        "\n",
        "  De 14 para 50+ neurônios: O desempenho na validação se manteve estável e extremamente alto (em torno de 99%), com pequenas flutuações. Em contraste, o desempenho no treino continuou a subir até atingir 100%, indicando que a rede estava usando os neurônios extras para memorizar os dados de treino.\n",
        "\n",
        "b. Quais as regiões de overfitting e underfitting do MLP em relação ao número de neurônios?\n",
        "\n",
        "  Região de Underfitting (Subajuste):\n",
        "\n",
        "  A configuração (over_1)(1) com 1 neurônio.\n",
        "  Justificativa: O desempenho foi muito baixo em todas as métricas (64.6% no treino, 61.75% na validação). Isso é a definição de underfitting: o modelo é simples demais e não tem capacidade para aprender a função que mapeia as features ao resultado desejado, resultando em um erro alto tanto para dados de treino quanto para dados novos.\n",
        "\n",
        "  Região de Overfitting (Sobreajuste):\n",
        "\n",
        "  As configurações (over_3)(200), (over_4)(500) e (over_5)(200, 100).\n",
        "  Justificativa: Estes modelos, com um número excessivo de neurônios nas camadas escondidas, alcançaram 100% de acurácia no treino, o que significa que decoraram os dados."
      ],
      "metadata": {
        "id": "QQmhKVYPFxmG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"EXPERIMENTO 5: AVALIAÇÃO DA TAXA DE APRENDIZADO (learning_rate_init)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Verificação de Pré-requisitos\n",
        "if 'best_activation' not in locals() or 'best_solver' not in locals():\n",
        "    print(\"ERRO: É necessário executar as células dos experimentos anteriores primeiro.\")\n",
        "    exit()\n",
        "else:\n",
        "    # Define a melhor arquitetura encontrada no passo anterior\n",
        "    best_neuron_config = (14,)\n",
        "\n",
        "    print(f\"Parâmetros utilizados (definidos anteriormente):\")\n",
        "    print(f\"  - Hidden Layer Sizes: {best_neuron_config} (melhor configuração do exp. anterior)\")\n",
        "    print(f\"  - Função de Ativação: '{best_activation}'\")\n",
        "    print(f\"  - Solver: '{best_solver}'\")\n",
        "\n",
        "# Define as taxas de aprendizado a serem testadas\n",
        "learning_rates_to_test = [0.001, 0.01, 0.1]\n",
        "print(f\"  - Taxas de Aprendizado a serem testadas: {learning_rates_to_test}\")\n",
        "\n",
        "# Inicializa a lista de resultados\n",
        "results_lr_experiment = []\n",
        "\n",
        "#Início dos Experimentos\n",
        "for dataset_name, df in sorted(datasets.items()):\n",
        "\n",
        "    print(f\"\\nProcessando dataset: {dataset_name}\")\n",
        "    X, y = prepare_data(df)\n",
        "\n",
        "    # Dicionários para armazenar resultados\n",
        "    row_train = {'Base': dataset_name, 'Treino/Teste': 'Treino'}\n",
        "    row_70_30 = {'Base': '', 'Treino/Teste': '70/30'}\n",
        "    row_10_fold = {'Base': '', 'Treino/Teste': '10-fold CV'}\n",
        "\n",
        "    # Executar o teste para cada taxa de aprendizado\n",
        "    for lr in learning_rates_to_test:\n",
        "        print(f\"    -> Testando learning_rate_init = {lr}...\")\n",
        "\n",
        "        mlp = MLPClassifier(\n",
        "            hidden_layer_sizes=best_neuron_config,\n",
        "            activation=best_activation,\n",
        "            solver=best_solver,\n",
        "            learning_rate_init=lr,\n",
        "            random_state=42,\n",
        "            max_iter=500\n",
        "        )\n",
        "\n",
        "        # Treinamento\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "        mlp.fit(X_train, y_train)\n",
        "\n",
        "        # Cálculo das Acurácias\n",
        "        acc_train = metrics.accuracy_score(y_train, mlp.predict(X_train))\n",
        "        acc_70_30 = metrics.accuracy_score(y_test, mlp.predict(X_test))\n",
        "\n",
        "        cv_strategy = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "        acc_10_fold = mean(cross_val_score(mlp, X, y, cv=cv_strategy, scoring='accuracy'))\n",
        "\n",
        "        # Armazenar resultados\n",
        "        col_name = str(lr)\n",
        "        row_train[col_name] = round(acc_train, 4)\n",
        "        row_70_30[col_name] = round(acc_70_30, 4)\n",
        "        row_10_fold[col_name] = round(acc_10_fold, 4)\n",
        "\n",
        "    results_lr_experiment.append(row_train)\n",
        "    results_lr_experiment.append(row_70_30)\n",
        "    results_lr_experiment.append(row_10_fold)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z93FtcckZo96",
        "outputId": "9216fecb-a6ef-4740-9e2e-e2527c4b8e83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "EXPERIMENTO 5: AVALIAÇÃO DA TAXA DE APRENDIZADO (learning_rate_init)\n",
            "================================================================================\n",
            "Parâmetros utilizados (definidos anteriormente):\n",
            "  - Hidden Layer Sizes: (14,) (melhor configuração do exp. anterior)\n",
            "  - Função de Ativação: 'relu'\n",
            "  - Solver: 'adam'\n",
            "  - Taxas de Aprendizado a serem testadas: [0.001, 0.01, 0.1]\n",
            "\n",
            "Processando dataset: PCA_CNN_VGG16_256_max\n",
            "    -> Testando learning_rate_init = 0.001...\n",
            "    -> Testando learning_rate_init = 0.01...\n",
            "    -> Testando learning_rate_init = 0.1...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ANÁLISE DOS RESULTADOS DO EXPERIMENTO DE TAXA DE APRENDIZADO\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "if not results_lr_experiment:\n",
        "    print(\"ERRO: A lista de resultados está vazia. Por favor, execute a Célula 10 primeiro.\")\n",
        "else:\n",
        "    # Cria o DataFrame com os resultados\n",
        "    df_results_lr = pd.DataFrame(results_lr_experiment)\n",
        "    # Define a ordem das colunas\n",
        "    column_order_lr = ['Base', 'Treino/Teste'] + [str(lr) for lr in learning_rates_to_test]\n",
        "    df_results_lr = df_results_lr[column_order_lr]\n",
        "\n",
        "    print(\"\\nTABELA DE RESULTADOS - TAXA DE APRENDIZADO\\n\")\n",
        "    print(df_results_lr.to_string(index=False))\n",
        "\n",
        "    # Análise para determinar a melhor taxa de aprendizado\n",
        "    print(\"\\n--- Análise da Performance por Taxa de Aprendizado ---\")\n",
        "\n",
        "    # Isola os dados de validação para a análise\n",
        "    df_cv_accs_lr = df_results_lr[df_results_lr['Treino/Teste'] == '10-fold CV']\n",
        "\n",
        "    avg_scores_lr = {}\n",
        "    for lr_col in [str(lr) for lr in learning_rates_to_test]:\n",
        "        # Calcula a média caso haja mais de um dataset\n",
        "        mean_cv_acc = df_cv_accs_lr[lr_col].astype(float).mean()\n",
        "        avg_scores_lr[lr_col] = mean_cv_acc\n",
        "        print(f\"  - Taxa de Aprendizado '{lr_col}': Acurácia Média de Validação = {mean_cv_acc:.4f}\")\n",
        "\n",
        "    # Determina a melhor taxa\n",
        "    best_lr = max(avg_scores_lr, key=avg_scores_lr.get)\n",
        "    print(f\"\\n=> MELHOR TAXA DE APRENDIZADO ENCONTRADA: '{best_lr}' (baseado na maior acurácia de validação).\")\n",
        "\n",
        "    # Salva e baixa o arquivo de resultados\n",
        "    filename_lr = 'resultados_mlp_learning_rate.csv'\n",
        "    df_results_lr.to_csv(filename_lr, index=False)\n",
        "    print(f\"\\nTabela de resultados salva em '{filename_lr}'.\")\n",
        "    files.download(filename_lr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "XJguQTBcap-N",
        "outputId": "10daaa2b-f3da-4810-bdae-bfd951f4842a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ANÁLISE DOS RESULTADOS DO EXPERIMENTO DE TAXA DE APRENDIZADO\n",
            "================================================================================\n",
            "\n",
            "TABELA DE RESULTADOS - TAXA DE APRENDIZADO\n",
            "\n",
            "                 Base Treino/Teste  0.001   0.01    0.1\n",
            "PCA_CNN_VGG16_256_max       Treino 0.9964 1.0000 1.0000\n",
            "                             70/30 0.9917 0.9917 0.9875\n",
            "                        10-fold CV 0.9925 0.9875 0.9875\n",
            "\n",
            "--- Análise da Performance por Taxa de Aprendizado ---\n",
            "  - Taxa de Aprendizado '0.001': Acurácia Média de Validação = 0.9925\n",
            "  - Taxa de Aprendizado '0.01': Acurácia Média de Validação = 0.9875\n",
            "  - Taxa de Aprendizado '0.1': Acurácia Média de Validação = 0.9875\n",
            "\n",
            "=> MELHOR TAXA DE APRENDIZADO ENCONTRADA: '0.001' (baseado na maior acurácia de validação).\n",
            "\n",
            "Tabela de resultados salva em 'resultados_mlp_learning_rate.csv'.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_339717b2-ddec-4fd4-ade5-f15f1f571fb1\", \"resultados_mlp_learning_rate.csv\", 138)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "a. O que aconteceu com o desempenho da rede quando a taxa de aprendizado aumentou?\n",
        "\n",
        "Aumentar a taxa de aprendizado fez com que a rede memorizasse os dados de treino de forma mais agressiva (atingindo 100% de acurácia), mas piorou ligeiramente seu desempenho em dados de validação. A taxa de aprendizado padrão de 0.001  foi a que produziu o melhor resultado de generalização (99.25% no 10-fold CV), mostrando que uma abordagem de aprendizado mais cautelosa foi mais eficaz.\n",
        "\n",
        "b. Quais as regiões de overfitting e underfitting do MLP em relação à taxa de aprendizado?\n",
        "\n",
        "Região de Underfitting: Não foi observada. Todas as taxas de aprendizado testadas permitiram que o modelo aprendesse com sucesso, alcançando altas acurácias.\n",
        "\n",
        "Região de Overfitting: As taxas de 0.01 e 0.1 levaram o modelo a um leve overfitting. A evidência é que elas alcançaram 100% de acurácia nos dados de treino, mas uma performance de validação inferior à da taxa de 0.001. Isso sugere que o modelo se ajustou excessivamente aos dados de treino, perdendo um pouco da capacidade de generalizar."
      ],
      "metadata": {
        "id": "oo404I4ObSgJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"EXPERIMENTO 6: AVALIAÇÃO DO NÚMERO DE ITERAÇÕES (max_iter)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Verificação de Pré-requisitos\n",
        "if 'best_activation' not in locals() or 'best_solver' not in locals():\n",
        "    print(\"ERRO: É necessário executar as células dos experimentos anteriores primeiro.\")\n",
        "    exit()\n",
        "else:\n",
        "    # Define os melhores parâmetros encontrados em todos os passos anteriores\n",
        "    best_neuron_config = (14,)\n",
        "    best_lr = 0.001\n",
        "\n",
        "    print(f\"Parâmetros Finais Utilizados:\")\n",
        "    print(f\"  - Hidden Layer Sizes: {best_neuron_config}\")\n",
        "    print(f\"  - Função de Ativação: '{best_activation}'\")\n",
        "    print(f\"  - Solver: '{best_solver}'\")\n",
        "    print(f\"  - Learning Rate Init: {best_lr}\")\n",
        "\n",
        "# Define os valores de max_iter a serem testados\n",
        "max_iterations_to_test = [500, 1000, 1500, 2000]\n",
        "print(f\"  - Número de Iterações a serem testadas: {max_iterations_to_test}\")\n",
        "\n",
        "# Inicializa a lista de resultados\n",
        "results_iter_experiment = []\n",
        "\n",
        "#Início dos Experimentos\n",
        "for dataset_name, df in sorted(datasets.items()):\n",
        "\n",
        "    print(f\"\\nProcessando dataset: {dataset_name}\")\n",
        "    X, y = prepare_data(df)\n",
        "\n",
        "    # Dicionários para armazenar resultados\n",
        "    row_train = {'Base': dataset_name, 'Treino/Teste': 'Treino'}\n",
        "    row_70_30 = {'Base': '', 'Treino/Teste': '70/30'}\n",
        "    row_10_fold = {'Base': '', 'Treino/Teste': '10-fold CV'}\n",
        "\n",
        "    # Executar o teste para cada valor de max_iter\n",
        "    for n_iter in max_iterations_to_test:\n",
        "        print(f\"    -> Testando max_iter = {n_iter}...\")\n",
        "\n",
        "        mlp = MLPClassifier(\n",
        "            hidden_layer_sizes=best_neuron_config,\n",
        "            activation=best_activation,\n",
        "            solver=best_solver,\n",
        "            learning_rate_init=best_lr,\n",
        "            max_iter=n_iter,\n",
        "            random_state=42\n",
        "        )\n",
        "\n",
        "        # Treinamento\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "        mlp.fit(X_train, y_train)\n",
        "\n",
        "        # Cálculo das Acurácias\n",
        "        acc_train = metrics.accuracy_score(y_train, mlp.predict(X_train))\n",
        "        acc_70_30 = metrics.accuracy_score(y_test, mlp.predict(X_test))\n",
        "\n",
        "        cv_strategy = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "        acc_10_fold = mean(cross_val_score(mlp, X, y, cv=cv_strategy, scoring='accuracy'))\n",
        "\n",
        "        # Armazenar resultados\n",
        "        col_name = str(n_iter)\n",
        "        row_train[col_name] = round(acc_train, 4)\n",
        "        row_70_30[col_name] = round(acc_70_30, 4)\n",
        "        row_10_fold[col_name] = round(acc_10_fold, 4)\n",
        "\n",
        "    results_iter_experiment.append(row_train)\n",
        "    results_iter_experiment.append(row_70_30)\n",
        "    results_iter_experiment.append(row_10_fold)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68YPGfV5a2PX",
        "outputId": "6484ac6b-1cf1-46e8-ad25-2da8501ac9fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "EXPERIMENTO 6: AVALIAÇÃO DO NÚMERO DE ITERAÇÕES (max_iter)\n",
            "================================================================================\n",
            "Parâmetros Finais Utilizados:\n",
            "  - Hidden Layer Sizes: (14,)\n",
            "  - Função de Ativação: 'relu'\n",
            "  - Solver: 'adam'\n",
            "  - Learning Rate Init: 0.001\n",
            "  - Número de Iterações a serem testadas: [500, 1000, 1500, 2000]\n",
            "\n",
            "Processando dataset: PCA_CNN_VGG16_256_max\n",
            "    -> Testando max_iter = 500...\n",
            "    -> Testando max_iter = 1000...\n",
            "    -> Testando max_iter = 1500...\n",
            "    -> Testando max_iter = 2000...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ANÁLISE DOS ResULTADOS DO EXPERIMENTO DE NÚMERO DE ITERAÇÕES\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "if not results_iter_experiment:\n",
        "    print(\"ERRO: A lista de resultados está vazia. Por favor, execute a Célula 12 primeiro.\")\n",
        "else:\n",
        "    # Cria o DataFrame com os resultados\n",
        "    df_results_iter = pd.DataFrame(results_iter_experiment)\n",
        "    # Define a ordem das colunas\n",
        "    column_order_iter = ['Base', 'Treino/Teste'] + [str(n_iter) for n_iter in max_iterations_to_test]\n",
        "    df_results_iter = df_results_iter[column_order_iter]\n",
        "\n",
        "    # Exibe a tabela de resultados completa\n",
        "    print(\"\\nTABELA DE RESULTADOS - NÚMERO DE ITERAÇÕES\\n\")\n",
        "    print(df_results_iter.to_string(index=False))\n",
        "\n",
        "    #Análise da Convergência\n",
        "    print(\"\\n--- Análise da Convergência do Modelo ---\")\n",
        "\n",
        "    # Isola os dados de validação para a análise\n",
        "    df_cv_accs_iter = df_results_iter[df_results_iter['Treino/Teste'] == '10-fold CV']\n",
        "\n",
        "    print(\"Analisando a acurácia de validação (10-fold CV) para diferentes 'max_iter':\")\n",
        "    for iter_col in [str(n_iter) for n_iter in max_iterations_to_test]:\n",
        "        mean_cv_acc = df_cv_accs_iter[iter_col].astype(float).mean()\n",
        "        print(f\"  - 'max_iter' = {iter_col}: Acurácia Média de Validação = {mean_cv_acc:.4f}\")\n",
        "\n",
        "    filename_iter = 'resultados_mlp_max_iter.csv'\n",
        "    df_results_iter.to_csv(filename_iter, index=False)\n",
        "    print(f\"\\nTabela de resultados salva em '{filename_iter}'.\")\n",
        "    files.download(filename_iter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "hP9Emrcib0I3",
        "outputId": "b1d66bc8-b4a9-425b-d301-f99a416b0fac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ANÁLISE DOS ResULTADOS DO EXPERIMENTO DE NÚMERO DE ITERAÇÕES\n",
            "================================================================================\n",
            "\n",
            "TABELA DE RESULTADOS - NÚMERO DE ITERAÇÕES\n",
            "\n",
            "                 Base Treino/Teste    500   1000   1500   2000\n",
            "PCA_CNN_VGG16_256_max       Treino 0.9964 0.9964 0.9964 0.9964\n",
            "                             70/30 0.9917 0.9917 0.9917 0.9917\n",
            "                        10-fold CV 0.9925 0.9925 0.9925 0.9925\n",
            "\n",
            "--- Análise da Convergência do Modelo ---\n",
            "Analisando a acurácia de validação (10-fold CV) para diferentes 'max_iter':\n",
            "  - 'max_iter' = 500: Acurácia Média de Validação = 0.9925\n",
            "  - 'max_iter' = 1000: Acurácia Média de Validação = 0.9925\n",
            "  - 'max_iter' = 1500: Acurácia Média de Validação = 0.9925\n",
            "  - 'max_iter' = 2000: Acurácia Média de Validação = 0.9925\n",
            "\n",
            "Tabela de resultados salva em 'resultados_mlp_max_iter.csv'.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_a1416204-d3cd-472b-a595-d65e2d07af87\", \"resultados_mlp_max_iter.csv\", 169)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "a. O que aconteceu com o desempenho da rede quando o número de iterações aumentou?\n",
        "\n",
        "Aumentar o número de iterações de 500 para 2.000 não teve efeito no desempenho da rede, pois as acurácias de treino e validação permaneceram idênticas. Isso ocorre porque o MLPClassifier atingiu a convergência (encontrou a melhor solução) em menos de 500 iterações, e o treinamento parou automaticamente. Este mecanismo é controlado por parâmetros específicos, que interrompem o processo quando o modelo para de melhorar.\n",
        "\n",
        "b. Quais as regiões de overfitting e underfitting do MLP em relação ao número de iterações?\n",
        "\n",
        "Não foram observadas regiões de overfitting e underfitting"
      ],
      "metadata": {
        "id": "E-oHLcB4c_lc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy import mean\n",
        "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import metrics\n",
        "import warnings\n",
        "from google.colab import files\n",
        "import io\n",
        "\n",
        "# Ignorar avisos de convergência para manter a saída limpa\n",
        "warnings.filterwarnings('ignore', category=UserWarning)\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"INICIALIZANDO O EXPERIMENTO COMPARATIVO FINAL COM MLP\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Solicita o upload das 12 bases de dados\n",
        "print(\"\\nPor favor, faça o upload dos 12 arquivos CSV das bases a serem utilizadas.\")\n",
        "try:\n",
        "    uploaded_files = files.upload()\n",
        "    if not uploaded_files or len(uploaded_files) != 12:\n",
        "        print(f\"\\nAVISO: Foram carregados {len(uploaded_files)} arquivos. O esperado eram 12. Verifique os arquivos.\")\n",
        "        if not uploaded_files:\n",
        "            exit()\n",
        "except Exception as e:\n",
        "    print(f\"\\nOcorreu um erro durante o upload: {e}\")\n",
        "    exit()\n",
        "\n",
        "# Dicionário para armazenar os dataframes\n",
        "datasets = {}\n",
        "print(\"\\n--- Validando arquivos carregados ---\")\n",
        "for filename, content in uploaded_files.items():\n",
        "    try:\n",
        "        base_name = filename.replace('dataset_', '').replace('.csv', '')\n",
        "        df = pd.read_csv(io.StringIO(content.decode('utf-8')))\n",
        "        if 'label' in df.columns and 'filename' in df.columns:\n",
        "            datasets[base_name] = df\n",
        "            print(f\"  - sucesso: Arquivo '{filename}' carregado como '{base_name}'.\")\n",
        "        else:\n",
        "            print(f\"  - AVISO: '{filename}' ignorado por não conter 'label' ou 'filename'.\")\n",
        "    except Exception as e:\n",
        "        print(f\"  - erro: Falha ao processar '{filename}': {e}\")\n",
        "\n",
        "if not datasets:\n",
        "    print(\"\\nerro: Nenhum dataset válido foi carregado.\")\n",
        "    exit()\n",
        "\n",
        "# Função de preparação dos dados\n",
        "def prepare_data(df):\n",
        "    X = df.drop(columns=['label', 'filename'])\n",
        "    y = df['label']\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "    return X_scaled, y\n",
        "\n",
        "print(f\"\\n{len(datasets)} datasets prontos para o experimento.\")"
      ],
      "metadata": {
        "id": "LJe37UCodNG-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817
        },
        "outputId": "fbce898d-45ee-4d56-9fc4-af6c3c6cfa7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "INICIALIZANDO O EXPERIMENTO COMPARATIVO FINAL COM MLP\n",
            "================================================================================\n",
            "\n",
            "Por favor, faça o upload dos 12 arquivos CSV das bases a serem utilizadas.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4edda1e5-b03a-4d4a-8d47-82ac68dcddb2\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-4edda1e5-b03a-4d4a-8d47-82ac68dcddb2\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving dataset_PCA_CNN_VGG16_128_avg.csv to dataset_PCA_CNN_VGG16_128_avg.csv\n",
            "Saving dataset_PCA_CNN_VGG16_128_max.csv to dataset_PCA_CNN_VGG16_128_max.csv\n",
            "Saving dataset_PCA_CNN_VGG16_256_avg.csv to dataset_PCA_CNN_VGG16_256_avg.csv\n",
            "Saving dataset_PCA_CNN_VGG16_256_max.csv to dataset_PCA_CNN_VGG16_256_max (1).csv\n",
            "Saving dataset_PCA_CNN_VGG19_256_avg.csv to dataset_PCA_CNN_VGG19_256_avg.csv\n",
            "Saving dataset_PCA_CNN_VGG19_256_max.csv to dataset_PCA_CNN_VGG19_256_max.csv\n",
            "Saving dataset_vgg16_avg_128x128.csv to dataset_vgg16_avg_128x128.csv\n",
            "Saving dataset_vgg16_avg_256x256.csv to dataset_vgg16_avg_256x256.csv\n",
            "Saving dataset_vgg16_max_128x128.csv to dataset_vgg16_max_128x128.csv\n",
            "Saving dataset_vgg16_max_256x256.csv to dataset_vgg16_max_256x256.csv\n",
            "Saving dataset_vgg19_avg_256x256.csv to dataset_vgg19_avg_256x256.csv\n",
            "Saving dataset_vgg19_max_256x256.csv to dataset_vgg19_max_256x256.csv\n",
            "\n",
            "--- Validando arquivos carregados ---\n",
            "  - sucesso: Arquivo 'dataset_PCA_CNN_VGG16_128_avg.csv' carregado como 'PCA_CNN_VGG16_128_avg'.\n",
            "  - sucesso: Arquivo 'dataset_PCA_CNN_VGG16_128_max.csv' carregado como 'PCA_CNN_VGG16_128_max'.\n",
            "  - sucesso: Arquivo 'dataset_PCA_CNN_VGG16_256_avg.csv' carregado como 'PCA_CNN_VGG16_256_avg'.\n",
            "  - sucesso: Arquivo 'dataset_PCA_CNN_VGG16_256_max (1).csv' carregado como 'PCA_CNN_VGG16_256_max (1)'.\n",
            "  - sucesso: Arquivo 'dataset_PCA_CNN_VGG19_256_avg.csv' carregado como 'PCA_CNN_VGG19_256_avg'.\n",
            "  - sucesso: Arquivo 'dataset_PCA_CNN_VGG19_256_max.csv' carregado como 'PCA_CNN_VGG19_256_max'.\n",
            "  - sucesso: Arquivo 'dataset_vgg16_avg_128x128.csv' carregado como 'vgg16_avg_128x128'.\n",
            "  - sucesso: Arquivo 'dataset_vgg16_avg_256x256.csv' carregado como 'vgg16_avg_256x256'.\n",
            "  - sucesso: Arquivo 'dataset_vgg16_max_128x128.csv' carregado como 'vgg16_max_128x128'.\n",
            "  - sucesso: Arquivo 'dataset_vgg16_max_256x256.csv' carregado como 'vgg16_max_256x256'.\n",
            "  - sucesso: Arquivo 'dataset_vgg19_avg_256x256.csv' carregado como 'vgg19_avg_256x256'.\n",
            "  - sucesso: Arquivo 'dataset_vgg19_max_256x256.csv' carregado como 'vgg19_max_256x256'.\n",
            "\n",
            "12 datasets prontos para o experimento.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Definindo as 10 configurações para o experimento final...\")\n",
        "\n",
        "configurations = [\n",
        "    {\n",
        "        'name': 'Config. 01',\n",
        "        'params': {'hidden_layer_sizes': (1,)} # Para demonstrar underfitting\n",
        "    },\n",
        "    {\n",
        "        'name': 'Config. 02',\n",
        "        'params': {'hidden_layer_sizes': (14,)} # Melhor modelo \"bom ajuste\" encontrado\n",
        "    },\n",
        "    {\n",
        "        'name': 'Config. 03',\n",
        "        'params': {'hidden_layer_sizes': (100,)} # Para demonstrar overfitting\n",
        "    },\n",
        "    {\n",
        "        'name': 'Config. 04',\n",
        "        'params': {'hidden_layer_sizes': (500,)} # Para demonstrar overfitting\n",
        "    },\n",
        "    {\n",
        "        'name': 'Config. 05',\n",
        "        'params': {'hidden_layer_sizes': (200, 100)} # Overfitting com múltiplas camadas\n",
        "    },\n",
        "    {\n",
        "        'name': 'Config. 06',\n",
        "        'params': {'hidden_layer_sizes': (14,), 'learning_rate_init': 0.01} # Teste com taxa maior\n",
        "    },\n",
        "    {\n",
        "        'name': 'Config. 07',\n",
        "        'params': {'hidden_layer_sizes': (14,), 'learning_rate_init': 0.1} # Teste com taxa muito alta\n",
        "    },\n",
        "    {\n",
        "        'name': 'Config. 08',\n",
        "        'params': {'hidden_layer_sizes': (14,), 'max_iter': 1500} # Teste com mais iterações\n",
        "    },\n",
        "    {\n",
        "        'name': 'Config. 09',\n",
        "        'params': {'hidden_layer_sizes': (14,), 'solver': 'sgd'} # Teste com outro solver\n",
        "    },\n",
        "    {\n",
        "        'name': 'Config. 10',\n",
        "        'params': {'hidden_layer_sizes': (50, 25)} # Comparação com outra arquitetura\n",
        "    }\n",
        "]\n",
        "\n",
        "# Adiciona parâmetros fixos que serão iguais para todas as configurações\n",
        "# Usamos 'relu' e 'adam' como base, pois foram os melhores nos testes iniciais.\n",
        "for config in configurations:\n",
        "    # Adiciona a função de ativação 'relu' se não estiver definida\n",
        "    config['params'].setdefault('activation', 'relu')\n",
        "    # Adiciona o solver 'adam' se não estiver definido\n",
        "    config['params'].setdefault('solver', 'adam')\n",
        "    # Adiciona a taxa de aprendizado padrão se não estiver definida\n",
        "    config['params'].setdefault('learning_rate_init', 0.001)\n",
        "    # Adiciona o número de iterações padrão se não estiver definido\n",
        "    config['params'].setdefault('max_iter', 700)\n",
        "    # Adiciona o estado aleatório para garantir reprodutibilidade\n",
        "    config['params']['random_state'] = 42"
      ],
      "metadata": {
        "id": "iWpSBdYqg5YQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64edf73d-6400-4eb9-8093-f4a4441021e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Definindo as 10 configurações para o experimento final...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Iniciando a execução dos testes comparativos. Isso pode levar vários minutos... ---\")\n",
        "\n",
        "results_list = []\n",
        "\n",
        "# Loop sobre cada base de dados (ordenada para consistência)\n",
        "for dataset_name, df in sorted(datasets.items()):\n",
        "    print(f\"\\nProcessando base: {dataset_name}...\")\n",
        "    X, y = prepare_data(df)\n",
        "\n",
        "    # Dicionários para armazenar os resultados desta base\n",
        "    row_70_30 = {'Bases': dataset_name, 'Treino/Teste': '70/30'}\n",
        "    row_10_fold = {'Bases': '', 'Treino/Teste': '10-fold CV'}\n",
        "\n",
        "    # Loop sobre cada uma das 10 configurações definidas na Célula 2\n",
        "    for config in configurations:\n",
        "        config_name = config['name']\n",
        "        print(f\"  -> Testando {config_name}...\")\n",
        "\n",
        "        # Cria a instância do classificador com os parâmetros da configuração atual\n",
        "        mlp = MLPClassifier(**config['params'])\n",
        "\n",
        "        # Validação 70/30\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "        mlp.fit(X_train, y_train)\n",
        "        acc_70_30 = metrics.accuracy_score(y_test, mlp.predict(X_test))\n",
        "\n",
        "        # Validação 10-fold CV\n",
        "        # Recria o classificador para garantir que não está pré-treinado\n",
        "        mlp_cv = MLPClassifier(**config['params'])\n",
        "        cv_strategy = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "        acc_10_fold = mean(cross_val_score(mlp_cv, X, y, cv=cv_strategy, scoring='accuracy'))\n",
        "\n",
        "        # Armazena os resultados de acurácia\n",
        "        row_70_30[config_name] = acc_70_30\n",
        "        row_10_fold[config_name] = acc_10_fold\n",
        "\n",
        "    results_list.append(row_70_30)\n",
        "    results_list.append(row_10_fold)"
      ],
      "metadata": {
        "id": "tzGQwgReg99-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5f26004-f4b4-4fc4-9c25-70fd50a6627a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Iniciando a execução dos testes comparativos. Isso pode levar vários minutos... ---\n",
            "\n",
            "Processando base: PCA_CNN_VGG16_128_avg...\n",
            "  -> Testando Config. 01...\n",
            "  -> Testando Config. 02...\n",
            "  -> Testando Config. 03...\n",
            "  -> Testando Config. 04...\n",
            "  -> Testando Config. 05...\n",
            "  -> Testando Config. 06...\n",
            "  -> Testando Config. 07...\n",
            "  -> Testando Config. 08...\n",
            "  -> Testando Config. 09...\n",
            "  -> Testando Config. 10...\n",
            "\n",
            "Processando base: PCA_CNN_VGG16_128_max...\n",
            "  -> Testando Config. 01...\n",
            "  -> Testando Config. 02...\n",
            "  -> Testando Config. 03...\n",
            "  -> Testando Config. 04...\n",
            "  -> Testando Config. 05...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Iniciando a execução dos testes comparativos. Isso pode levar vários minutos... ---\")\n",
        "\n",
        "results_list = []\n",
        "\n",
        "# Loop sobre cada base de dados (ordenada para consistência)\n",
        "for dataset_name, df in sorted(datasets.items()):\n",
        "    print(f\"\\nProcessando base: {dataset_name}...\")\n",
        "    X, y = prepare_data(df)\n",
        "\n",
        "    # Dicionários para armazenar os resultados desta base\n",
        "    row_70_30 = {'Bases': dataset_name, 'Treino/Teste': '70/30'}\n",
        "    row_10_fold = {'Bases': '', 'Treino/Teste': '10-fold CV'}\n",
        "\n",
        "    # Loop sobre cada uma das 10 configurações definidas na Célula 2\n",
        "    for config in configurations:\n",
        "        config_name = config['name']\n",
        "        print(f\"  -> Testando {config_name}...\")\n",
        "\n",
        "        # Cria a instância do classificador com os parâmetros da configuração atual\n",
        "        mlp = MLPClassifier(**config['params'])\n",
        "\n",
        "        # Validação 70/30\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "        mlp.fit(X_train, y_train)\n",
        "        acc_70_30 = metrics.accuracy_score(y_test, mlp.predict(X_test))\n",
        "\n",
        "        # Validação 10-fold CV\n",
        "        # Recria o classificador para garantir que não está pré-treinado\n",
        "        mlp_cv = MLPClassifier(**config['params'])\n",
        "        cv_strategy = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "        acc_10_fold = mean(cross_val_score(mlp_cv, X, y, cv=cv_strategy, scoring='accuracy'))\n",
        "\n",
        "        # Armazena os resultados de acurácia\n",
        "        row_70_30[config_name] = acc_70_30\n",
        "        row_10_fold[config_name] = acc_10_fold\n",
        "\n",
        "    results_list.append(row_70_30)\n",
        "    results_list.append(row_10_fold)\n"
      ],
      "metadata": {
        "id": "iEqhbvV7m5u2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"GERANDO TABELA DE RESULTADOS FINAL\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "if not results_list:\n",
        "    print(\"ERRO: A lista de resultados está vazia. Por favor, execute a Célula 3 primeiro.\")\n",
        "else:\n",
        "    # Cria o DataFrame principal\n",
        "    df_results = pd.DataFrame(results_list)\n",
        "\n",
        "    # Arredonda todos os valores numéricos para 4 casas decimais\n",
        "    for col in df_results.columns:\n",
        "        if df_results[col].dtype in ['float64', 'int64']:\n",
        "            df_results[col] = df_results[col].round(4)\n",
        "\n",
        "    #Cálculo das Estatísticas (Média e Desv. Padrão)\n",
        "    df_10_fold = df_results[df_results['Treino/Teste'] == '10-fold CV']\n",
        "\n",
        "    # Extrai apenas as colunas de configuração para cálculo\n",
        "    config_cols = [config['name'] for config in configurations]\n",
        "\n",
        "    # Calcula a média e o desvio padrão\n",
        "    mean_values = df_10_fold[config_cols].mean().round(4)\n",
        "    std_values = df_10_fold[config_cols].std().round(4)\n",
        "\n",
        "    # Cria as linhas de estatísticas como dicionários\n",
        "    mean_row = {'Bases': 'Média =>', 'Treino/Teste': ''}\n",
        "    mean_row.update(mean_values.to_dict())\n",
        "\n",
        "    std_row = {'Bases': 'Desv. Pad. =>', 'Treino/Teste': ''}\n",
        "    std_row.update(std_values.to_dict())\n",
        "\n",
        "    # Linha em branco para separação\n",
        "    blank_row = {col: '' for col in df_results.columns}\n",
        "\n",
        "    #Concatena a tabela original com as estatísticas\n",
        "    df_final = pd.concat([\n",
        "        df_results,\n",
        "        pd.DataFrame([blank_row]),\n",
        "        pd.DataFrame([mean_row]),\n",
        "        pd.DataFrame([std_row])\n",
        "    ], ignore_index=True)\n",
        "\n",
        "    # Garante a ordem correta das colunas\n",
        "    column_order = ['Bases', 'Treino/Teste'] + config_cols\n",
        "    df_final = df_final[column_order]\n",
        "\n",
        "    # Exibe a tabela final no formato da imagem\n",
        "    print(\"\\nTABELA FINAL - Multi Layer Perceptron (MLP) - (Acurácia)\\n\")\n",
        "    pd.set_option('display.max_rows', None)\n",
        "    pd.set_option('display.max_columns', None)\n",
        "    pd.set_option('display.width', 200)\n",
        "    print(df_final.to_string(index=False))\n",
        "\n",
        "    # Salva e baixa o arquivo de resultados\n",
        "    filename_final = 'resultados_finais_mlp.csv'\n",
        "    df_final.to_csv(filename_final, index=False)\n",
        "    print(f\"\\n\\nTabela de resultados salva em '{filename_final}'.\")\n",
        "    files.download(filename_final)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 705
        },
        "id": "e5zCSospp9XD",
        "outputId": "f83978f5-f60c-461b-a3db-a66ee5ae17be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "GERANDO TABELA DE RESULTADOS FINAL\n",
            "================================================================================\n",
            "\n",
            "TABELA FINAL - Multi Layer Perceptron (MLP) - (Acurácia)\n",
            "\n",
            "                    Bases Treino/Teste Config. 01 Config. 02 Config. 03 Config. 04 Config. 05 Config. 06 Config. 07 Config. 08 Config. 09 Config. 10\n",
            "PCA_CNN_VGG16_128_avg (1)        70/30     0.6083     0.9417     0.9542     0.9458     0.9458      0.925     0.9208     0.9417     0.9333     0.9542\n",
            "                            10-fold CV       0.59     0.9425     0.9438     0.9438     0.9388       0.93     0.9325     0.9425      0.935       0.94\n",
            "PCA_CNN_VGG16_128_max (1)        70/30     0.6083     0.9375     0.9458     0.9417     0.9458      0.925      0.925     0.9375      0.925     0.9417\n",
            "                            10-fold CV     0.5812     0.9438     0.9475      0.945       0.95     0.9275      0.925     0.9425     0.9412     0.9525\n",
            "PCA_CNN_VGG16_256_avg (1)        70/30     0.6792     0.9792      0.975     0.9792      0.975     0.9792     0.9792     0.9792     0.9833     0.9708\n",
            "                            10-fold CV     0.6462      0.985     0.9875     0.9838     0.9825     0.9862       0.98      0.985     0.9862      0.985\n",
            "PCA_CNN_VGG16_256_max (2)        70/30     0.6708     0.9917     0.9917     0.9917     0.9917     0.9917     0.9875     0.9917     0.9875     0.9917\n",
            "                            10-fold CV     0.6175     0.9925     0.9887     0.9875     0.9887     0.9875     0.9875     0.9925     0.9888       0.99\n",
            "PCA_CNN_VGG19_256_avg (1)        70/30     0.6708      0.975      0.975      0.975     0.9708      0.975     0.9708      0.975     0.9792     0.9708\n",
            "                            10-fold CV     0.6662     0.9888     0.9813     0.9838     0.9838     0.9813     0.9762     0.9888     0.9875     0.9813\n",
            "PCA_CNN_VGG19_256_max (1)        70/30      0.675     0.9833     0.9875     0.9833     0.9917     0.9833     0.9708     0.9833     0.9875     0.9875\n",
            "                            10-fold CV     0.6287     0.9875     0.9875     0.9887       0.99      0.985     0.9838     0.9875     0.9912     0.9875\n",
            "    vgg16_avg_128x128 (1)        70/30     0.5042     0.9292     0.9542     0.9583     0.9458     0.9458     0.9417     0.9292     0.9417     0.9625\n",
            "                            10-fold CV     0.5238     0.9438     0.9438     0.9588     0.9525     0.9525     0.9362     0.9438     0.9388     0.9425\n",
            "    vgg16_avg_256x256 (1)        70/30     0.5375     0.9708     0.9875     0.9833     0.9917     0.9833     0.9708     0.9708      0.975     0.9792\n",
            "                            10-fold CV     0.5888     0.9812     0.9813      0.985       0.99      0.985       0.98     0.9812     0.9825      0.985\n",
            "    vgg16_max_128x128 (1)        70/30     0.5208     0.9292     0.9458     0.9667     0.9542     0.9417     0.9625     0.9292       0.95     0.9583\n",
            "                            10-fold CV       0.53       0.95     0.9488     0.9575     0.9637      0.955     0.9413       0.95     0.9388      0.945\n",
            "    vgg16_max_256x256 (1)        70/30     0.5167      0.975     0.9833     0.9833     0.9917     0.9875     0.9792      0.975     0.9833     0.9792\n",
            "                            10-fold CV     0.5925      0.985     0.9875      0.985       0.99     0.9838       0.98      0.985     0.9812     0.9812\n",
            "    vgg19_avg_256x256 (1)        70/30     0.5958      0.975     0.9833     0.9917     0.9958     0.9792     0.9833      0.975     0.9792     0.9792\n",
            "                            10-fold CV     0.5725     0.9825     0.9812     0.9838       0.99     0.9887      0.975     0.9825     0.9762     0.9838\n",
            "    vgg19_max_256x256 (1)        70/30     0.5333     0.9792     0.9833     0.9958     0.9958     0.9917     0.9833     0.9792     0.9792     0.9958\n",
            "                            10-fold CV     0.5538     0.9812     0.9913       0.99       0.99      0.985     0.9813     0.9812     0.9788     0.9925\n",
            "                                                                                                                                                    \n",
            "                 Média =>                  0.5909      0.972     0.9725     0.9744     0.9758     0.9706     0.9649     0.9719     0.9689     0.9722\n",
            "            Desv. Pad. =>                  0.0436     0.0202     0.0199     0.0177     0.0191      0.023     0.0235     0.0204     0.0229     0.0205\n",
            "\n",
            "\n",
            "Tabela de resultados salva em 'resultados_finais_mlp.csv'.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c9247d10-6690-4645-be2d-e53bfdaa0425\", \"resultados_finais_mlp.csv\", 2419)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"COMPARANDO COM GridSearchCV (VERSÃO RÁPIDA)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Definindo um grid de parâmetros menor e mais focado para uma busca rápida\n",
        "# Vamos comparar nosso melhor modelo com algumas variações próximas\n",
        "param_grid_rapido = {\n",
        "    'hidden_layer_sizes': [(14,), (50,), (50, 25)], # Nosso melhor vs. duas alternativas\n",
        "    'learning_rate_init': [0.001, 0.01], # Nosso melhor vs. uma alternativa\n",
        "    'solver': ['adam'], # Usando apenas o melhor solver encontrado\n",
        "    'activation': ['relu'], # Usando apenas a melhor função de ativação\n",
        "    'max_iter': [700] # Usando um número fixo de iterações\n",
        "}\n",
        "\n",
        "# Nosso melhor modelo encontrado manualmente (para comparação)\n",
        "manual_best_config = {\n",
        "    'activation': 'relu',\n",
        "    'hidden_layer_sizes': (14,),\n",
        "    'learning_rate_init': 0.001,\n",
        "    'solver': 'adam',\n",
        "    'max_iter': 700\n",
        "}\n",
        "\n",
        "print(\"Grid de parâmetros para a busca rápida foi definido:\")\n",
        "print(param_grid_rapido)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xr1ISugsrNRs",
        "outputId": "dafac1c0-65f0-4d8f-8748-7061c01cf6d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "COMPARANDO COM GridSearchCV (VERSÃO RÁPIDA)\n",
            "================================================================================\n",
            "Grid de parâmetros para a busca rápida foi definido:\n",
            "{'hidden_layer_sizes': [(14,), (50,), (50, 25)], 'learning_rate_init': [0.001, 0.01], 'solver': ['adam'], 'activation': ['relu'], 'max_iter': [700]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ETAPA 2: UPLOAD DA BASE DE DADOS PARA O TESTE\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Inicializa as variáveis para evitar erros\n",
        "chosen_base_name = None\n",
        "df_to_use = None\n",
        "\n",
        "print(\"Por favor, faça o upload do arquivo CSV da base de dados que você deseja usar na comparação.\")\n",
        "\n",
        "try:\n",
        "    # Solicita o upload de um arquivo\n",
        "    uploaded_single_file = files.upload()\n",
        "\n",
        "    # Verifica se um arquivo foi de fato carregado\n",
        "    if uploaded_single_file:\n",
        "        filename = next(iter(uploaded_single_file))\n",
        "        chosen_base_name = filename.replace('.csv', '')\n",
        "        content = uploaded_single_file[filename]\n",
        "\n",
        "        # Cria o DataFrame para ser usado no teste\n",
        "        df_to_use = pd.read_csv(io.StringIO(content.decode('utf-8')))\n",
        "        print(f\"\\nBase '{chosen_base_name}' carregada com sucesso e pronta para o teste.\")\n",
        "    else:\n",
        "        print(\"\\nNenhum arquivo foi carregado. A execução das próximas células será pulada.\")\n",
        "except Exception as e:\n",
        "    print(f\"\\nOcorreu um erro durante o upload: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "9g05fLLBrPuk",
        "outputId": "30a78a44-adeb-4156-af83-695d321f6cc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ETAPA 2: UPLOAD DA BASE DE DADOS PARA O TESTE\n",
            "================================================================================\n",
            "Por favor, faça o upload do arquivo CSV da base de dados que você deseja usar na comparação.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3b275b81-6a14-4647-aad3-8777172ee903\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3b275b81-6a14-4647-aad3-8777172ee903\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving dataset_PCA_CNN_VGG16_256_max.csv to dataset_PCA_CNN_VGG16_256_max (3).csv\n",
            "\n",
            "Base 'dataset_PCA_CNN_VGG16_256_max (3)' carregada com sucesso e pronta para o teste.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ETAPA 3: EXECUTANDO A BUSCA COM GridSearchCV\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "if df_to_use is not None:\n",
        "    X, y = prepare_data(df_to_use)\n",
        "\n",
        "    print(f\"--- Iniciando a execução na base '{chosen_base_name}'. Por favor, aguarde... ---\")\n",
        "        grid_search = GridSearchCV(\n",
        "        estimator=MLPClassifier(random_state=42),\n",
        "        param_grid=param_grid_rapido,\n",
        "        cv=3,\n",
        "        scoring='accuracy',\n",
        "        n_jobs=-1,\n",
        "        verbose=2\n",
        "    )\n",
        "\n",
        "    # Inicia a busca\n",
        "    grid_search.fit(X, y)\n",
        "    print(\"\\nBusca com GridSearchCV concluída!\")\n",
        "    print(\"\\nCélula 16 executada com sucesso.\")\n",
        "\n",
        "else:\n",
        "    print(\"Nenhuma base de dados foi carregada na célula anterior. A execução foi pulada.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2gYLdBJs5V7",
        "outputId": "a41bbf81-e07d-4680-82fc-2f8d833c2d4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ETAPA 3: EXECUTANDO A BUSCA COM GridSearchCV\n",
            "================================================================================\n",
            "--- Iniciando a execução na base 'dataset_PCA_CNN_VGG16_256_max (3)'. Por favor, aguarde... ---\n",
            "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
            "\n",
            "Busca com GridSearchCV concluída!\n",
            "\n",
            "Célula 16 executada com sucesso.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ETAPA 4: ANÁLISE COMPARATIVA FINAL\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Verifica se o objeto 'grid_search' foi criado e treinado na célula anterior\n",
        "if 'grid_search' in locals() and hasattr(grid_search, 'best_score_'):\n",
        "\n",
        "    print(f\"Resultados para a base: {chosen_base_name}\\n\")\n",
        "\n",
        "    # - Resultados do GridSearchCV\n",
        "    print(\"--- Resultados do GridSearchCV ---\")\n",
        "    gs_best_params = grid_search.best_params_\n",
        "    gs_best_accuracy = grid_search.best_score_\n",
        "    print(f\"Melhor Acurácia (CV=3): {gs_best_accuracy:.4f}\")\n",
        "    print(\"Melhores Parâmetros encontrados:\")\n",
        "    for param, value in gs_best_params.items():\n",
        "        print(f\"  - {param}: {value}\")\n",
        "\n",
        "    #Resultados da Busca Manual\n",
        "    print(\"\\n--- Resultados da Nossa Busca Manual (Modelo Campeão) ---\")\n",
        "    manual_model = MLPClassifier(**manual_best_config, random_state=42)\n",
        "    manual_accuracy_cv3 = mean(cross_val_score(manual_model, X, y, cv=3, scoring='accuracy'))\n",
        "    print(f\"Acurácia (CV=3): {manual_accuracy_cv3:.4f}\")\n",
        "    print(\"Parâmetros escolhidos manualmente:\")\n",
        "    for param, value in manual_best_config.items():\n",
        "        print(f\"  - {param}: {value}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBq2ScTJs-4f",
        "outputId": "629e4478-6c7e-47e1-f336-743c17adfc08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ETAPA 4: ANÁLISE COMPARATIVA FINAL\n",
            "================================================================================\n",
            "Resultados para a base: dataset_PCA_CNN_VGG16_256_max (3)\n",
            "\n",
            "--- Resultados do GridSearchCV ---\n",
            "Melhor Acurácia (CV=3): 0.9862\n",
            "Melhores Parâmetros encontrados:\n",
            "  - activation: relu\n",
            "  - hidden_layer_sizes: (14,)\n",
            "  - learning_rate_init: 0.01\n",
            "  - max_iter: 700\n",
            "  - solver: adam\n",
            "\n",
            "--- Resultados da Nossa Busca Manual (Modelo Campeão) ---\n",
            "Acurácia (CV=3): 0.9862\n",
            "Parâmetros escolhidos manualmente:\n",
            "  - activation: relu\n",
            "  - hidden_layer_sizes: (14,)\n",
            "  - learning_rate_init: 0.001\n",
            "  - solver: adam\n",
            "  - max_iter: 700\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A. Os parâmetros encontrados por você ficaram muito diferente do encontrado pelo GridSearchCV?\n",
        "\n",
        "Não, mas os parâmetros foram muito parecidos. Quatro dos cinco hiperparâmetros (activation, hidden_layer_sizes, solver e max_iter) foram idênticos. A única diferença foi na taxa de aprendizado (learning_rate_init), onde sua busca manual selecionou 0.001 e o GridSearchCV optou por 0.01.\n",
        "\n",
        "B. E em termos de acurácia, qual foi a diferença?\n",
        "\n",
        "Não houve nenhuma diferença. Ambos os modelos, tanto o encontrado manualmente quanto o melhor modelo do GridSearchCV, alcançaram exatamente a mesma acurácia de 0.9862, mostrando que sua busca passo a passo foi tão eficaz quanto a busca automática para este problema."
      ],
      "metadata": {
        "id": "Y1Y0GaGftpia"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Comitê de Classificadores"
      ],
      "metadata": {
        "id": "II5L_-Qj8KEi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import pandas as pd\n",
        "import io\n",
        "from google.colab import files"
      ],
      "metadata": {
        "id": "-zvxk1rV_oNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\"*80)\n",
        "print(\"INICIALIZANDO O CARREGAMENTO DOS DADOS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\nPor favor, faça o upload dos arquivos CSV dos datasets a serem utilizados.\")\n",
        "try:\n",
        "    uploaded_files = files.upload()\n",
        "    if not uploaded_files:\n",
        "        raise ValueError(\"Nenhum arquivo foi selecionado.\")\n",
        "except Exception as e:\n",
        "    print(f\"\\nOcorreu um erro durante o upload: {e}\")\n",
        "    # Interrompe a execução se o upload falhar\n",
        "    exit()\n",
        "\n",
        "# Dicionário para armazenar os dataframes carregados\n",
        "datasets = {}\n",
        "\n",
        "print(\"\\n--- Validando arquivos carregados ---\")\n",
        "for filename, content in uploaded_files.items():\n",
        "    try:\n",
        "        base_name = filename.replace('dataset_', '').replace('.csv', '')\n",
        "        df = pd.read_csv(io.StringIO(content.decode('utf-8')))\n",
        "\n",
        "        # Verifica a presença das colunas essenciais\n",
        "        if 'label' in df.columns and 'filename' in df.columns:\n",
        "            datasets[base_name] = df\n",
        "            print(f\"  - SUCESSO: Arquivo '{filename}' carregado como '{base_name}'. Shape: {df.shape}\")\n",
        "        else:\n",
        "            print(f\"  - AVISO: Arquivo '{filename}' ignorado por não conter as colunas 'label' ou 'filename'.\")\n",
        "    except Exception as e:\n",
        "        print(f\"  - ERRO: Falha ao processar o arquivo '{filename}': {e}\")\n",
        "\n",
        "if not datasets:\n",
        "    print(\"\\nERRO CRÍTICO: Nenhum dataset válido foi carregado. Os experimentos não podem continuar.\")\n",
        "else:\n",
        "    print(f\"\\nTotal de {len(datasets)} datasets prontos para o experimento.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "id": "i6kmMfz88Oqz",
        "outputId": "e92653f0-ff47-4b37-db91-1db4d18f5360"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "INICIALIZANDO O CARREGAMENTO DOS DADOS\n",
            "================================================================================\n",
            "\n",
            "Por favor, faça o upload dos arquivos CSV dos datasets a serem utilizados.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-06920142-a941-4a6b-b9d5-db3656f1c540\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-06920142-a941-4a6b-b9d5-db3656f1c540\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving dataset_PCA_CNN_VGG16_256_max.csv to dataset_PCA_CNN_VGG16_256_max.csv\n",
            "\n",
            "--- Validando arquivos carregados ---\n",
            "  - SUCESSO: Arquivo 'dataset_PCA_CNN_VGG16_256_max.csv' carregado como 'PCA_CNN_VGG16_256_max'. Shape: (800, 12)\n",
            "\n",
            "Total de 1 datasets prontos para o experimento.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    df_para_processar = datasets['PCA_CNN_VGG16_256_max']\n",
        "except NameError:\n",
        "    print(\"Erro: O dicionário 'datasets' não foi encontrado. Execute o passo de carregamento primeiro.\")\n",
        "    # Ou crie um df de exemplo para teste, como o comentado acima.\n",
        "    exit()\n",
        "except KeyError:\n",
        "    print(\"Erro: A chave 'nome_do_seu_dataset' não foi encontrada no dicionário 'datasets'.\")\n",
        "    print(\"Chaves disponíveis:\", list(datasets.keys()))\n",
        "    exit()"
      ],
      "metadata": {
        "id": "tEeAEHVsDYJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data(df):\n",
        "    \"\"\"\n",
        "    Prepara os dados para o modelo:\n",
        "    1. Separa features (X) e rótulos (y).\n",
        "    2. Aplica padronização (StandardScaler) nas features.\n",
        "    \"\"\"\n",
        "    if 'label' not in df.columns or 'filename' not in df.columns:\n",
        "        raise ValueError(\"O DataFrame deve conter as colunas 'label' e 'filename'.\")\n",
        "\n",
        "    X = df.drop(columns=['label', 'filename'])\n",
        "    y = df['label']\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "    return X_scaled, y\n",
        "\n",
        "X_scaled, y = prepare_data(df_para_processar)"
      ],
      "metadata": {
        "id": "3jFESZRfEQ7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
        "\n",
        "print(\"\\nDados divididos em conjuntos de treino e teste:\")\n",
        "print(\"Shape de X_train:\", X_train.shape)\n",
        "print(\"Shape de X_test:\", X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Go7wMlvEU41",
        "outputId": "abc5a856-59dc-41f5-e136-92f391b73e1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dados divididos em conjuntos de treino e teste:\n",
            "Shape de X_train: (560, 10)\n",
            "Shape de X_test: (240, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore', category=UserWarning)\n",
        "\n",
        "#Dicionário com os estimadores base (Estratégias)\n",
        "# Usando as configurações \"melhoradas\"\n",
        "estimators = {\n",
        "    'AD': DecisionTreeClassifier(criterion=\"entropy\", max_depth=6),\n",
        "    'k-NN': KNeighborsClassifier(n_neighbors=3, metric='euclidean'),\n",
        "    'NB': GaussianNB(),\n",
        "    'MLP': MLPClassifier(hidden_layer_sizes=100, activation='tanh', solver='sgd',\n",
        "                       max_iter=1500, learning_rate_init=0.001, random_state=1)\n",
        "}\n",
        "\n",
        "#Lista de valores para n_estimators a serem testados\n",
        "n_estimators_list = [10, 20, 30]\n",
        "\n",
        "# Dicionário para armazenar os resultados (acurácias)\n",
        "results = {}\n",
        "\n",
        "print(\"Iniciando os experimentos com Bagging Padrão...\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "# Loop principal para iterar sobre cada estratégia (AD, k-NN, etc.)\n",
        "for name, estimator in estimators.items():\n",
        "    print(f\"Executando para a estratégia: {name}\")\n",
        "\n",
        "    # Lista para guardar as acurácias para os diferentes n_estimators\n",
        "    accuracies = []\n",
        "\n",
        "    # Loop secundário para iterar sobre a quantidade de estimadores (10, 20, 30)\n",
        "    for n in n_estimators_list:\n",
        "        print(f\"  - Testando com n_estimators = {n}...\")\n",
        "\n",
        "        # Instanciando o BaggingClassifier\n",
        "        bagging_clf = BaggingClassifier(\n",
        "            estimator=estimator,\n",
        "            n_estimators=n,\n",
        "            max_samples=1.0,\n",
        "            max_features=1.0,\n",
        "            random_state=1,\n",
        "            n_jobs=-1\n",
        "        )\n",
        "\n",
        "        # Treinando o modelo\n",
        "        bagging_clf.fit(X_train, y_train)\n",
        "\n",
        "        # Fazendo a predição\n",
        "        y_pred = bagging_clf.predict(X_test)\n",
        "\n",
        "        # Calculando e armazenando a acurácia\n",
        "        acc = accuracy_score(y_test, y_pred)\n",
        "        accuracies.append(acc)\n",
        "\n",
        "    # Armazena a lista de acurácias para o estimador atual\n",
        "    results[name] = accuracies\n",
        "\n",
        "print(\"=\"*40)\n",
        "print(\"Experimentos finalizados. Gerando a tabela de resultados...\\n\")\n",
        "\n",
        "\n",
        "# 3. Criando a tabela de resultados\n",
        "df_results = pd.DataFrame(results, index=n_estimators_list).T\n",
        "\n",
        "df_results.columns = [10, 20, 30]\n",
        "\n",
        "#Calculando as médias\n",
        "# Média por linha\n",
        "df_results['Media (Acc TAM)'] = df_results.mean(axis=1)\n",
        "\n",
        "# Média por coluna (Acc Classificadores)\n",
        "df_results.loc['Media (Acc Classificadores)'] = df_results.mean(axis=0)\n",
        "\n",
        "pd.options.display.float_format = '{:.4f}'.format\n",
        "\n",
        "print(\"Tabela 1: Bagging Padrão\")\n",
        "display(df_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 604
        },
        "id": "3yFzSjdgKkqC",
        "outputId": "fa8fac97-fd0e-45dc-8493-8a54056964a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iniciando os experimentos com Bagging Padrão...\n",
            "========================================\n",
            "Executando para a estratégia: AD\n",
            "  - Testando com n_estimators = 10...\n",
            "  - Testando com n_estimators = 20...\n",
            "  - Testando com n_estimators = 30...\n",
            "Executando para a estratégia: k-NN\n",
            "  - Testando com n_estimators = 10...\n",
            "  - Testando com n_estimators = 20...\n",
            "  - Testando com n_estimators = 30...\n",
            "Executando para a estratégia: NB\n",
            "  - Testando com n_estimators = 10...\n",
            "  - Testando com n_estimators = 20...\n",
            "  - Testando com n_estimators = 30...\n",
            "Executando para a estratégia: MLP\n",
            "  - Testando com n_estimators = 10...\n",
            "  - Testando com n_estimators = 20...\n",
            "  - Testando com n_estimators = 30...\n",
            "========================================\n",
            "Experimentos finalizados. Gerando a tabela de resultados...\n",
            "\n",
            "Tabela 1: Bagging Padrão\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                10     20     30  Media (Acc TAM)\n",
              "AD                          0.9667 0.9667 0.9625           0.9653\n",
              "k-NN                        0.9708 0.9708 0.9750           0.9722\n",
              "NB                          0.9833 0.9792 0.9833           0.9819\n",
              "MLP                         0.9917 0.9917 0.9917           0.9917\n",
              "Media (Acc Classificadores) 0.9781 0.9771 0.9781           0.9778"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-21a49dda-eaeb-4778-82f4-6107d587de3a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>10</th>\n",
              "      <th>20</th>\n",
              "      <th>30</th>\n",
              "      <th>Media (Acc TAM)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>AD</th>\n",
              "      <td>0.9667</td>\n",
              "      <td>0.9667</td>\n",
              "      <td>0.9625</td>\n",
              "      <td>0.9653</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>k-NN</th>\n",
              "      <td>0.9708</td>\n",
              "      <td>0.9708</td>\n",
              "      <td>0.9750</td>\n",
              "      <td>0.9722</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NB</th>\n",
              "      <td>0.9833</td>\n",
              "      <td>0.9792</td>\n",
              "      <td>0.9833</td>\n",
              "      <td>0.9819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MLP</th>\n",
              "      <td>0.9917</td>\n",
              "      <td>0.9917</td>\n",
              "      <td>0.9917</td>\n",
              "      <td>0.9917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Media (Acc Classificadores)</th>\n",
              "      <td>0.9781</td>\n",
              "      <td>0.9771</td>\n",
              "      <td>0.9781</td>\n",
              "      <td>0.9778</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-21a49dda-eaeb-4778-82f4-6107d587de3a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-21a49dda-eaeb-4778-82f4-6107d587de3a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-21a49dda-eaeb-4778-82f4-6107d587de3a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-6898d663-06f2-45a3-a571-3bd1b845659f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6898d663-06f2-45a3-a571-3bd1b845659f')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-6898d663-06f2-45a3-a571-3bd1b845659f button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_f5e412c5-bdbf-41a8-81a0-0150b5a7be18\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_results')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_f5e412c5-bdbf-41a8-81a0-0150b5a7be18 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_results');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_results",
              "summary": "{\n  \"name\": \"df_results\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": 10,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.009936866681426518,\n        \"min\": 0.9666666666666667,\n        \"max\": 0.9916666666666667,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.9708333333333333,\n          0.978125,\n          0.9833333333333333\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 20,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.009547032697824675,\n        \"min\": 0.9666666666666667,\n        \"max\": 0.9916666666666667,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.9708333333333333,\n          0.9770833333333333,\n          0.9791666666666666\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 30,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.01077508378415479,\n        \"min\": 0.9625,\n        \"max\": 0.9916666666666667,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.975,\n          0.978125,\n          0.9833333333333333\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Media (Acc TAM)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.009967152843338422,\n        \"min\": 0.9652777777777778,\n        \"max\": 0.9916666666666667,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.9722222222222222,\n          0.9777777777777777,\n          0.9819444444444444\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore', category=UserWarning)\n",
        "\n",
        "# Dicionário com os estimadores base (Estratégias)\n",
        "estimators = {\n",
        "    'AD': DecisionTreeClassifier(criterion=\"entropy\", max_depth=6),\n",
        "    'k-NN': KNeighborsClassifier(n_neighbors=3, metric='euclidean'),\n",
        "    'NB': GaussianNB(),\n",
        "    'MLP': MLPClassifier(hidden_layer_sizes=100, activation='tanh', solver='sgd',\n",
        "                       max_iter=1500, learning_rate_init=0.001, random_state=1)\n",
        "}\n",
        "\n",
        "# Lista de valores para n_estimators a serem testados\n",
        "n_estimators_list = [10, 20, 30]\n",
        "\n",
        "# Lista de valores para max_features a serem testados\n",
        "max_features_list = [0.3, 0.5, 0.8]\n",
        "\n",
        "pd.options.display.float_format = '{:.4f}'.format\n",
        "\n",
        "\n",
        "# Loop principal que irá iterar sobre cada valor de max_features\n",
        "for mf in max_features_list:\n",
        "\n",
        "    print(\"=\"*60)\n",
        "    print(f\"INICIANDO EXPERIMENTO COM max_features = {mf}\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Dicionário para armazenar os resultados para esta tabela\n",
        "    results_fs = {}\n",
        "\n",
        "    #oop para iterar sobre cada estratégia (AD, k-NN, etc.)\n",
        "    for name, estimator in estimators.items():\n",
        "\n",
        "        # Lista para guardar as acurácias para os diferentes n_estimators\n",
        "        accuracies = []\n",
        "\n",
        "        # Loop para iterar sobre a quantidade de estimadores\n",
        "        for n in n_estimators_list:\n",
        "\n",
        "            bagging_clf = BaggingClassifier(\n",
        "                estimator=estimator,\n",
        "                n_estimators=n,\n",
        "                max_features=mf,\n",
        "                max_samples=1.0,\n",
        "                random_state=1,\n",
        "                n_jobs=-1\n",
        "            )\n",
        "\n",
        "            # Treinando o modelo\n",
        "            bagging_clf.fit(X_train, y_train)\n",
        "\n",
        "            # Fazendo a predição\n",
        "            y_pred = bagging_clf.predict(X_test)\n",
        "\n",
        "            # Calculando e armazenando a acurácia\n",
        "            acc = accuracy_score(y_test, y_pred)\n",
        "            accuracies.append(acc)\n",
        "\n",
        "        # Armazena a lista de acurácias para o estimador atual\n",
        "        results_fs[name] = accuracies\n",
        "\n",
        "    # Criando o DataFrame com os resultados\n",
        "    df_results_fs = pd.DataFrame(results_fs, index=n_estimators_list).T\n",
        "    df_results_fs.columns = [10, 20, 30]\n",
        "\n",
        "    # Calculando as médias\n",
        "    df_results_fs['Media (Acc TAM)'] = df_results_fs.mean(axis=1)\n",
        "    df_results_fs.loc['Media (Acc Classificadores)'] = df_results_fs.mean(axis=0)\n",
        "\n",
        "    # Exibindo a tabela final para o valor de max_features atual\n",
        "    print(f\"\\nTabela: Bagging com Feature Selection (max_features = {mf})\")\n",
        "    display(df_results_fs)\n",
        "    print(\"\\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Jmziewb5LoOs",
        "outputId": "b6fe1fbb-cd06-48cb-b8c9-008d27cbb1a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "INICIANDO EXPERIMENTO COM max_features = 0.3\n",
            "============================================================\n",
            "\n",
            "Tabela: Bagging com Feature Selection (max_features = 0.3)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                10     20     30  Media (Acc TAM)\n",
              "AD                          0.8542 0.9333 0.9583           0.9153\n",
              "k-NN                        0.8333 0.9250 0.9333           0.8972\n",
              "NB                          0.8542 0.9125 0.9458           0.9042\n",
              "MLP                         0.9125 0.9583 0.9750           0.9486\n",
              "Media (Acc Classificadores) 0.8635 0.9323 0.9531           0.9163"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a79129b0-b5ef-4847-ab12-5d61febe7584\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>10</th>\n",
              "      <th>20</th>\n",
              "      <th>30</th>\n",
              "      <th>Media (Acc TAM)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>AD</th>\n",
              "      <td>0.8542</td>\n",
              "      <td>0.9333</td>\n",
              "      <td>0.9583</td>\n",
              "      <td>0.9153</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>k-NN</th>\n",
              "      <td>0.8333</td>\n",
              "      <td>0.9250</td>\n",
              "      <td>0.9333</td>\n",
              "      <td>0.8972</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NB</th>\n",
              "      <td>0.8542</td>\n",
              "      <td>0.9125</td>\n",
              "      <td>0.9458</td>\n",
              "      <td>0.9042</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MLP</th>\n",
              "      <td>0.9125</td>\n",
              "      <td>0.9583</td>\n",
              "      <td>0.9750</td>\n",
              "      <td>0.9486</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Media (Acc Classificadores)</th>\n",
              "      <td>0.8635</td>\n",
              "      <td>0.9323</td>\n",
              "      <td>0.9531</td>\n",
              "      <td>0.9163</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a79129b0-b5ef-4847-ab12-5d61febe7584')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a79129b0-b5ef-4847-ab12-5d61febe7584 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a79129b0-b5ef-4847-ab12-5d61febe7584');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-25d15ae0-ea1f-4bec-a4a5-755687dc504e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-25d15ae0-ea1f-4bec-a4a5-755687dc504e')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-25d15ae0-ea1f-4bec-a4a5-755687dc504e button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_67220196-b85e-4c6a-aa7d-97bea2651fc7\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_results_fs')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_67220196-b85e-4c6a-aa7d-97bea2651fc7 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_results_fs');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_results_fs",
              "summary": "{\n  \"name\": \"df_results_fs\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": 10,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.029517973573551556,\n        \"min\": 0.8333333333333334,\n        \"max\": 0.9125,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.8333333333333334,\n          0.8635416666666667,\n          0.8541666666666666\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 20,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.01676403847857406,\n        \"min\": 0.9125,\n        \"max\": 0.9583333333333334,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.925,\n          0.9322916666666667,\n          0.9125\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 30,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.015415258944738268,\n        \"min\": 0.9333333333333333,\n        \"max\": 0.975,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.9333333333333333,\n          0.953125,\n          0.9458333333333333\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Media (Acc TAM)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.019724545051005255,\n        \"min\": 0.8972222222222221,\n        \"max\": 0.9486111111111111,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.8972222222222221,\n          0.9163194444444445,\n          0.9041666666666667\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "============================================================\n",
            "INICIANDO EXPERIMENTO COM max_features = 0.5\n",
            "============================================================\n",
            "\n",
            "Tabela: Bagging com Feature Selection (max_features = 0.5)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                10     20     30  Media (Acc TAM)\n",
              "AD                          0.9083 0.9500 0.9625           0.9403\n",
              "k-NN                        0.9042 0.9542 0.9625           0.9403\n",
              "NB                          0.9125 0.9250 0.9417           0.9264\n",
              "MLP                         0.9250 0.9583 0.9792           0.9542\n",
              "Media (Acc Classificadores) 0.9125 0.9469 0.9615           0.9403"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b0af5fae-4fc0-4937-87a8-437abfb11c4a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>10</th>\n",
              "      <th>20</th>\n",
              "      <th>30</th>\n",
              "      <th>Media (Acc TAM)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>AD</th>\n",
              "      <td>0.9083</td>\n",
              "      <td>0.9500</td>\n",
              "      <td>0.9625</td>\n",
              "      <td>0.9403</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>k-NN</th>\n",
              "      <td>0.9042</td>\n",
              "      <td>0.9542</td>\n",
              "      <td>0.9625</td>\n",
              "      <td>0.9403</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NB</th>\n",
              "      <td>0.9125</td>\n",
              "      <td>0.9250</td>\n",
              "      <td>0.9417</td>\n",
              "      <td>0.9264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MLP</th>\n",
              "      <td>0.9250</td>\n",
              "      <td>0.9583</td>\n",
              "      <td>0.9792</td>\n",
              "      <td>0.9542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Media (Acc Classificadores)</th>\n",
              "      <td>0.9125</td>\n",
              "      <td>0.9469</td>\n",
              "      <td>0.9615</td>\n",
              "      <td>0.9403</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b0af5fae-4fc0-4937-87a8-437abfb11c4a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b0af5fae-4fc0-4937-87a8-437abfb11c4a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b0af5fae-4fc0-4937-87a8-437abfb11c4a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-3a6f5205-78b0-4fee-866d-e5f3b08e1ab9\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3a6f5205-78b0-4fee-866d-e5f3b08e1ab9')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-3a6f5205-78b0-4fee-866d-e5f3b08e1ab9 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_0112e070-559d-4f86-a573-eba6388fb740\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_results_fs')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_0112e070-559d-4f86-a573-eba6388fb740 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_results_fs');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_results_fs",
              "summary": "{\n  \"name\": \"df_results_fs\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": 10,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.007795119555779061,\n        \"min\": 0.9041666666666667,\n        \"max\": 0.925,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.9041666666666667,\n          0.9125000000000001,\n          0.9125\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 20,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.01296864541457159,\n        \"min\": 0.925,\n        \"max\": 0.9583333333333334,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.9541666666666667,\n          0.946875,\n          0.925\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 30,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.013299109723753854,\n        \"min\": 0.9416666666666667,\n        \"max\": 0.9791666666666666,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.9416666666666667,\n          0.9614583333333333,\n          0.9625\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Media (Acc TAM)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.009820927516479791,\n        \"min\": 0.9263888888888889,\n        \"max\": 0.9541666666666666,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.9402777777777778,\n          0.9263888888888889,\n          0.9541666666666666\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "============================================================\n",
            "INICIANDO EXPERIMENTO COM max_features = 0.8\n",
            "============================================================\n",
            "\n",
            "Tabela: Bagging com Feature Selection (max_features = 0.8)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                10     20     30  Media (Acc TAM)\n",
              "AD                          0.9917 0.9917 0.9917           0.9917\n",
              "k-NN                        0.9750 0.9833 0.9833           0.9806\n",
              "NB                          0.9750 0.9833 0.9833           0.9806\n",
              "MLP                         0.9875 0.9958 0.9958           0.9931\n",
              "Media (Acc Classificadores) 0.9823 0.9885 0.9885           0.9865"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-19febe0a-a5c6-4045-b808-98302c78275c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>10</th>\n",
              "      <th>20</th>\n",
              "      <th>30</th>\n",
              "      <th>Media (Acc TAM)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>AD</th>\n",
              "      <td>0.9917</td>\n",
              "      <td>0.9917</td>\n",
              "      <td>0.9917</td>\n",
              "      <td>0.9917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>k-NN</th>\n",
              "      <td>0.9750</td>\n",
              "      <td>0.9833</td>\n",
              "      <td>0.9833</td>\n",
              "      <td>0.9806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NB</th>\n",
              "      <td>0.9750</td>\n",
              "      <td>0.9833</td>\n",
              "      <td>0.9833</td>\n",
              "      <td>0.9806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MLP</th>\n",
              "      <td>0.9875</td>\n",
              "      <td>0.9958</td>\n",
              "      <td>0.9958</td>\n",
              "      <td>0.9931</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Media (Acc Classificadores)</th>\n",
              "      <td>0.9823</td>\n",
              "      <td>0.9885</td>\n",
              "      <td>0.9885</td>\n",
              "      <td>0.9865</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-19febe0a-a5c6-4045-b808-98302c78275c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-19febe0a-a5c6-4045-b808-98302c78275c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-19febe0a-a5c6-4045-b808-98302c78275c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-b4709a87-4253-4b19-b8a8-3c7a68658304\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b4709a87-4253-4b19-b8a8-3c7a68658304')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-b4709a87-4253-4b19-b8a8-3c7a68658304 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_f8736a6e-6f27-40a2-97d2-be32af622f72\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_results_fs')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_f8736a6e-6f27-40a2-97d2-be32af622f72 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_results_fs');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_results_fs",
              "summary": "{\n  \"name\": \"df_results_fs\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": 10,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.007438987946398829,\n        \"min\": 0.975,\n        \"max\": 0.9916666666666667,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.975,\n          0.9822916666666668,\n          0.9916666666666667\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 20,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.005412658773652776,\n        \"min\": 0.9833333333333333,\n        \"max\": 0.9958333333333333,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.9833333333333333,\n          0.9885416666666667,\n          0.9916666666666667\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 30,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.005412658773652776,\n        \"min\": 0.9833333333333333,\n        \"max\": 0.9958333333333333,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.9833333333333333,\n          0.9885416666666667,\n          0.9916666666666667\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Media (Acc TAM)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.005923167399038947,\n        \"min\": 0.9805555555555555,\n        \"max\": 0.9930555555555557,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.9805555555555555,\n          0.9864583333333334,\n          0.9916666666666667\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Qual o impacto da seleção de atributos no\n",
        "Bagging?\n",
        "\n",
        "R:\n",
        "A distribuição de atributos (feature selection) teve um impacto positivo, mas somente quando bem configurada. Usar poucos atributos (max_features=0.3 e 0.5) piorou o resultado. No entanto, a configuração com max_features=0.8 foi a melhor de todas, superando a acurácia do Bagging Padrão"
      ],
      "metadata": {
        "id": "VUPUo6TxNhrf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Foi bom fazer a distribuição de atributos?\n",
        "\n",
        "R:\n",
        "Fazer a distribuição de atributos foi bom, e a estratégia com max_features=0.8 se provou a campeã geral do experimento."
      ],
      "metadata": {
        "id": "AqHObgvUOGoj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Qual modelo foi mais afetado pela\n",
        "distribuição de atributos\n",
        "\n",
        "R:\n",
        "O k-NN foi o modelo mais sensível à mudança, com sua performance variando drasticamente. Em contrapartida, o MLP foi o mais estável e obteve as melhores acurácias na maioria dos cenários."
      ],
      "metadata": {
        "id": "Aza36SaWOLNs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "import warnings\n",
        "\n",
        "# Dicionário com os estimadores base\n",
        "estimators = {\n",
        "    'AD': DecisionTreeClassifier(criterion=\"entropy\", max_depth=6),\n",
        "    'NB': GaussianNB()\n",
        "}\n",
        "\n",
        "# Lista de valores para n_estimators a serem testados\n",
        "n_estimators_list = [10, 20, 30]\n",
        "\n",
        "results = {}\n",
        "\n",
        "print(\"Iniciando os experimentos com Boosting (AdaBoost)...\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "for name, estimator in estimators.items():\n",
        "    print(f\"Executando para a estratégia: {name}\")\n",
        "    accuracies = []\n",
        "    for n in n_estimators_list:\n",
        "        print(f\"  - Testando com n_estimators = {n}...\")\n",
        "\n",
        "        adaboost_clf = AdaBoostClassifier(\n",
        "            estimator=estimator,\n",
        "            n_estimators=n,\n",
        "            learning_rate=1.0,\n",
        "            random_state=1\n",
        "        )\n",
        "\n",
        "        adaboost_clf.fit(X_train, y_train)\n",
        "        y_pred = adaboost_clf.predict(X_test)\n",
        "        acc = accuracy_score(y_test, y_pred)\n",
        "        accuracies.append(acc)\n",
        "\n",
        "    results[name] = accuracies\n",
        "\n",
        "print(\"=\"*50)\n",
        "print(\"Experimentos finalizados. Gerando a tabela de resultados...\\n\")\n",
        "\n",
        "df_results = pd.DataFrame(results, index=n_estimators_list).T\n",
        "df_results.columns = [10, 20, 30]\n",
        "df_results['Media (Acc TAM)'] = df_results.mean(axis=1)\n",
        "df_results.loc['Media (Acc Classificadores)'] = df_results.mean(axis=0)\n",
        "\n",
        "pd.options.display.float_format = '{:.4f}'.format\n",
        "\n",
        "print(\"Tabela de Resultados: Boosting com AdaBoost\")\n",
        "display(df_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "mj9gIoRcN-m5",
        "outputId": "21a86d99-c199-4d2e-ff76-8cb354f1369d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iniciando os experimentos com Boosting (AdaBoost)...\n",
            "==================================================\n",
            "Executando para a estratégia: AD\n",
            "  - Testando com n_estimators = 10...\n",
            "  - Testando com n_estimators = 20...\n",
            "  - Testando com n_estimators = 30...\n",
            "Executando para a estratégia: NB\n",
            "  - Testando com n_estimators = 10...\n",
            "  - Testando com n_estimators = 20...\n",
            "  - Testando com n_estimators = 30...\n",
            "==================================================\n",
            "Experimentos finalizados. Gerando a tabela de resultados...\n",
            "\n",
            "Tabela de Resultados: Boosting com AdaBoost\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                10     20     30  Media (Acc TAM)\n",
              "AD                          0.9708 0.9708 0.9708           0.9708\n",
              "NB                          0.9750 0.9750 0.9750           0.9750\n",
              "Media (Acc Classificadores) 0.9729 0.9729 0.9729           0.9729"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-72829921-5317-4885-9a03-c59db86f1703\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>10</th>\n",
              "      <th>20</th>\n",
              "      <th>30</th>\n",
              "      <th>Media (Acc TAM)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>AD</th>\n",
              "      <td>0.9708</td>\n",
              "      <td>0.9708</td>\n",
              "      <td>0.9708</td>\n",
              "      <td>0.9708</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NB</th>\n",
              "      <td>0.9750</td>\n",
              "      <td>0.9750</td>\n",
              "      <td>0.9750</td>\n",
              "      <td>0.9750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Media (Acc Classificadores)</th>\n",
              "      <td>0.9729</td>\n",
              "      <td>0.9729</td>\n",
              "      <td>0.9729</td>\n",
              "      <td>0.9729</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-72829921-5317-4885-9a03-c59db86f1703')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-72829921-5317-4885-9a03-c59db86f1703 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-72829921-5317-4885-9a03-c59db86f1703');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-6b25e574-ebb4-4751-8634-0cc5d258b9b5\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6b25e574-ebb4-4751-8634-0cc5d258b9b5')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-6b25e574-ebb4-4751-8634-0cc5d258b9b5 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_c94e09bc-68ec-4cba-aa52-09de58efadfb\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_results')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_c94e09bc-68ec-4cba-aa52-09de58efadfb button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_results');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_results",
              "summary": "{\n  \"name\": \"df_results\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": 10,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.002083333333333326,\n        \"min\": 0.9708333333333333,\n        \"max\": 0.975,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.9708333333333333,\n          0.975,\n          0.9729166666666667\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 20,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.002083333333333326,\n        \"min\": 0.9708333333333333,\n        \"max\": 0.975,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.9708333333333333,\n          0.975,\n          0.9729166666666667\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 30,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.002083333333333326,\n        \"min\": 0.9708333333333333,\n        \"max\": 0.975,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.9708333333333333,\n          0.975,\n          0.9729166666666667\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Media (Acc TAM)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.002083333333333326,\n        \"min\": 0.9708333333333333,\n        \"max\": 0.975,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.9708333333333333,\n          0.975,\n          0.9729166666666667\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quem forneceu a maior acurácia, Bagging ou Boosting?\n",
        "\n",
        "R:\n",
        "Para AD o boosting foi melhor, para NB o bagging foi melhor\n",
        "Na média geral o Bagging teve uma acurácia um pouco maior"
      ],
      "metadata": {
        "id": "bB1eo0nWT8OV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "#Lista com as estratégias a serem testadas\n",
        "criterion_list = ['gini', 'entropy', 'log_loss']\n",
        "\n",
        "# Lista de valores para n_estimators a serem testados\n",
        "n_estimators_list = [10, 20, 30, 100]\n",
        "\n",
        "# Dicionário para armazenar os resultados (acurácias)\n",
        "results = {}\n",
        "\n",
        "print(\"Iniciando os experimentos com Random Forest...\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Loop principal para iterar sobre cada\n",
        "for criterion in criterion_list:\n",
        "    print(f\"Executando para a estratégia (criterion): {criterion}\")\n",
        "\n",
        "    # Lista para guardar as acurácias para os diferentes n_estimators\n",
        "    accuracies = []\n",
        "\n",
        "    for n in n_estimators_list:\n",
        "        print(f\"  - Testando com n_estimators = {n}...\")\n",
        "\n",
        "        # Instanciando o RandomForestClassifier\n",
        "        rf_clf = RandomForestClassifier(\n",
        "            n_estimators=n,\n",
        "            criterion=criterion,\n",
        "            random_state=1\n",
        "        )\n",
        "\n",
        "        rf_clf.fit(X_train, y_train)\n",
        "\n",
        "        y_pred = rf_clf.predict(X_test)\n",
        "\n",
        "        #Calculando e armazenando a acurácia\n",
        "        acc = accuracy_score(y_test, y_pred)\n",
        "        accuracies.append(acc)\n",
        "\n",
        "    # Armazena a lista de acurácias para o critério atual\n",
        "    results[criterion.capitalize()] = accuracies\n",
        "\n",
        "print(\"=\"*50)\n",
        "print(\"Experimentos finalizados. Gerando a tabela de resultados...\\n\")\n",
        "\n",
        "\n",
        "# Criando a tabela de resultados\n",
        "df_results = pd.DataFrame(results, index=n_estimators_list).T\n",
        "df_results.columns = [10, 20, 30, 100]\n",
        "\n",
        "#Média por linha (Acc TAM)\n",
        "df_results['Media (Acc TAM)'] = df_results.mean(axis=1)\n",
        "\n",
        "# Média por colun\n",
        "df_results.loc['Media (Acc Classificadores)'] = df_results.mean(axis=0)\n",
        "\n",
        "# Formatando os valores para exibição com 4 casas decimais\n",
        "pd.options.display.float_format = '{:.4f}'.format\n",
        "\n",
        "print(\"Tabela de Resultados: Random Forest\")\n",
        "display(df_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        },
        "id": "BozeKPX-Wn62",
        "outputId": "88d8f090-4458-4bfb-b1fc-56668af7f96f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iniciando os experimentos com Random Forest...\n",
            "==================================================\n",
            "Executando para a estratégia (criterion): gini\n",
            "  - Testando com n_estimators = 10...\n",
            "  - Testando com n_estimators = 20...\n",
            "  - Testando com n_estimators = 30...\n",
            "  - Testando com n_estimators = 100...\n",
            "Executando para a estratégia (criterion): entropy\n",
            "  - Testando com n_estimators = 10...\n",
            "  - Testando com n_estimators = 20...\n",
            "  - Testando com n_estimators = 30...\n",
            "  - Testando com n_estimators = 100...\n",
            "Executando para a estratégia (criterion): log_loss\n",
            "  - Testando com n_estimators = 10...\n",
            "  - Testando com n_estimators = 20...\n",
            "  - Testando com n_estimators = 30...\n",
            "  - Testando com n_estimators = 100...\n",
            "==================================================\n",
            "Experimentos finalizados. Gerando a tabela de resultados...\n",
            "\n",
            "Tabela de Resultados: Random Forest\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                10     20     30    100  Media (Acc TAM)\n",
              "Gini                        0.9875 0.9875 0.9875 0.9958           0.9896\n",
              "Entropy                     0.9750 0.9792 0.9833 0.9875           0.9812\n",
              "Log_loss                    0.9750 0.9792 0.9833 0.9875           0.9812\n",
              "Media (Acc Classificadores) 0.9792 0.9819 0.9847 0.9903           0.9840"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-213b5be0-1ecb-4789-b552-c8096d1bd1cb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>10</th>\n",
              "      <th>20</th>\n",
              "      <th>30</th>\n",
              "      <th>100</th>\n",
              "      <th>Media (Acc TAM)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Gini</th>\n",
              "      <td>0.9875</td>\n",
              "      <td>0.9875</td>\n",
              "      <td>0.9875</td>\n",
              "      <td>0.9958</td>\n",
              "      <td>0.9896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Entropy</th>\n",
              "      <td>0.9750</td>\n",
              "      <td>0.9792</td>\n",
              "      <td>0.9833</td>\n",
              "      <td>0.9875</td>\n",
              "      <td>0.9812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Log_loss</th>\n",
              "      <td>0.9750</td>\n",
              "      <td>0.9792</td>\n",
              "      <td>0.9833</td>\n",
              "      <td>0.9875</td>\n",
              "      <td>0.9812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Media (Acc Classificadores)</th>\n",
              "      <td>0.9792</td>\n",
              "      <td>0.9819</td>\n",
              "      <td>0.9847</td>\n",
              "      <td>0.9903</td>\n",
              "      <td>0.9840</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-213b5be0-1ecb-4789-b552-c8096d1bd1cb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-213b5be0-1ecb-4789-b552-c8096d1bd1cb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-213b5be0-1ecb-4789-b552-c8096d1bd1cb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-f4f86f49-2494-4388-bc93-513df3dc1910\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f4f86f49-2494-4388-bc93-513df3dc1910')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-f4f86f49-2494-4388-bc93-513df3dc1910 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_84e3f8c6-b506-4526-8024-e556825cb8ca\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_results')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_84e3f8c6-b506-4526-8024-e556825cb8ca button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_results');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_results",
              "summary": "{\n  \"name\": \"df_results\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": 10,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.005892556509887928,\n        \"min\": 0.975,\n        \"max\": 0.9875,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.9875,\n          0.975,\n          0.9791666666666666\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 20,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.003928371006591969,\n        \"min\": 0.9791666666666666,\n        \"max\": 0.9875,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.9875,\n          0.9791666666666666,\n          0.9819444444444444\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 30,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0019641855032960106,\n        \"min\": 0.9833333333333333,\n        \"max\": 0.9875,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.9875,\n          0.9833333333333333,\n          0.9847222222222222\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 100,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.003928371006591917,\n        \"min\": 0.9875,\n        \"max\": 0.9958333333333333,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.9958333333333333,\n          0.9875,\n          0.9902777777777777\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Media (Acc TAM)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.003928371006592021,\n        \"min\": 0.98125,\n        \"max\": 0.9895833333333335,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.9895833333333335,\n          0.98125,\n          0.9840277777777778\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Qual comitê de classificadores está fornecendo a melhor acurácia? Explique sua\n",
        "resposta.\n",
        "\n",
        "R:\n",
        "O Random Forest venceu porque herda a força do Bagging (criação de múltiplos modelos a partir de amostras de dados) e a aprimora com uma camada de aleatoriedade, o que gera um comitê de classificadores mais diversificado e mais preciso."
      ],
      "metadata": {
        "id": "cSeAVBprYYNt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Criando um \"pool\" de 20 classificadores base heterogêneos\n",
        "base_models_pool = [\n",
        "    # 5x MLP com configurações simples\n",
        "    ('MLP_1', MLPClassifier(hidden_layer_sizes=(20,), max_iter=800, random_state=1)),\n",
        "    ('MLP_2', MLPClassifier(hidden_layer_sizes=(40,), max_iter=800, random_state=1)),\n",
        "    ('MLP_3', MLPClassifier(hidden_layer_sizes=(60,), max_iter=1000, random_state=1)),\n",
        "    ('MLP_4', MLPClassifier(hidden_layer_sizes=(20, 10), max_iter=1000, random_state=1)),\n",
        "    ('MLP_5', MLPClassifier(hidden_layer_sizes=(30, 20), max_iter=1000, random_state=1)),\n",
        "\n",
        "    # 5x k-NN com diferentes vizinhos\n",
        "    ('kNN_1', KNeighborsClassifier(n_neighbors=3)),\n",
        "    ('kNN_2', KNeighborsClassifier(n_neighbors=5)),\n",
        "    ('kNN_3', KNeighborsClassifier(n_neighbors=7)),\n",
        "    ('kNN_4', KNeighborsClassifier(n_neighbors=9)),\n",
        "    ('kNN_5', KNeighborsClassifier(n_neighbors=11)),\n",
        "\n",
        "    # 5x Decision Tree com diferentes\n",
        "    ('DT_1', DecisionTreeClassifier(max_depth=5, criterion='gini', random_state=1)),\n",
        "    ('DT_2', DecisionTreeClassifier(max_depth=10, criterion='gini', random_state=1)),\n",
        "    ('DT_3', DecisionTreeClassifier(max_depth=15, criterion='gini', random_state=1)),\n",
        "    ('DT_4', DecisionTreeClassifier(max_depth=10, criterion='entropy', random_state=1)),\n",
        "    ('DT_5', DecisionTreeClassifier(max_depth=20, criterion='entropy', random_state=1)),\n",
        "\n",
        "    ('NB_1', GaussianNB()),\n",
        "    ('NB_2', GaussianNB()),\n",
        "    ('NB_3', GaussianNB()),\n",
        "    ('NB_4', GaussianNB()),\n",
        "    ('NB_5', GaussianNB())\n",
        "]\n",
        "\n",
        "\n",
        "#Lista com os tamanhos de comitês a serem testados\n",
        "stack_sizes = [5, 10, 15, 20]\n",
        "\n",
        "# Dicionário para armazenar os resultados (acurácias)\n",
        "results = {}\n",
        "\n",
        "print(\"Iniciando os experimentos com Stacking...\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "\n",
        "# Loop para testar cada tamanho de comitê\n",
        "for size in stack_sizes:\n",
        "    print(f\"Executando para a estratégia: {size} classificadores\")\n",
        "\n",
        "    # Seleciona os primeiros size modelos do nosso pool\n",
        "    current_estimators = base_models_pool[:size]\n",
        "\n",
        "    stacking_clf = StackingClassifier(\n",
        "        estimators=current_estimators,\n",
        "        final_estimator=LogisticRegression(),\n",
        "        cv=5,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "\n",
        "    #Treinando o modelo de Stacking\n",
        "    stacking_clf.fit(X_train, y_train)\n",
        "\n",
        "    #Fazendo a predição\n",
        "    y_pred = stacking_clf.predict(X_test)\n",
        "\n",
        "    #calculando e armazenando a acurácia\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    results[f'{size} classificadores'] = acc\n",
        "\n",
        "\n",
        "print(\"=\"*50)\n",
        "print(\"Experimentos finalizados.\\n\")\n",
        "\n",
        "# Criando a tabela de resultados com Pandas\n",
        "# Usamos .from_dict para criar o DataFrame a partir do dicionário de resultados\n",
        "df_results = pd.DataFrame.from_dict(results, orient='index', columns=['Media'])\n",
        "df_results.index.name = 'Estratégia'\n",
        "\n",
        "\n",
        "# Formatando os valores para exibição com 4 casas decimais\n",
        "pd.options.display.float_format = '{:.4f}'.format\n",
        "\n",
        "# Exibindo a tabela final\n",
        "print(\"Tabela de Resultados: Stacking Heterogêneo\")\n",
        "display(df_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "id": "gtsepVj7ZlsU",
        "outputId": "bc957285-2dfc-4761-d1f0-651c5123d0d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iniciando os experimentos com Stacking...\n",
            "==================================================\n",
            "Executando para a estratégia: 5 classificadores\n",
            "Executando para a estratégia: 10 classificadores\n",
            "Executando para a estratégia: 15 classificadores\n",
            "Executando para a estratégia: 20 classificadores\n",
            "==================================================\n",
            "Experimentos finalizados. Gerando a tabela de resultados...\n",
            "\n",
            "Tabela de Resultados: Stacking Heterogêneo\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                    Media\n",
              "Estratégia               \n",
              "5 classificadores  0.9833\n",
              "10 classificadores 0.9833\n",
              "15 classificadores 0.9875\n",
              "20 classificadores 0.9833"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1a5c70f1-7359-404a-8920-800cf10768af\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Media</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Estratégia</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5 classificadores</th>\n",
              "      <td>0.9833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10 classificadores</th>\n",
              "      <td>0.9833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15 classificadores</th>\n",
              "      <td>0.9875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20 classificadores</th>\n",
              "      <td>0.9833</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1a5c70f1-7359-404a-8920-800cf10768af')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1a5c70f1-7359-404a-8920-800cf10768af button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1a5c70f1-7359-404a-8920-800cf10768af');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-4720f306-82c3-4328-8a3f-449d4e0a9334\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4720f306-82c3-4328-8a3f-449d4e0a9334')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-4720f306-82c3-4328-8a3f-449d4e0a9334 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_2b055233-b237-4d0d-9d7e-b4cdd5fe2dca\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_results')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_2b055233-b237-4d0d-9d7e-b4cdd5fe2dca button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_results');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_results",
              "summary": "{\n  \"name\": \"df_results\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"Estrat\\u00e9gia\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"10 classificadores\",\n          \"20 classificadores\",\n          \"5 classificadores\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Media\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0020833333333333814,\n        \"min\": 0.9833333333333333,\n        \"max\": 0.9875,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.9875,\n          0.9833333333333333\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compare esta tabela com os resultados do Bagging, Boosting e Random Forest e responda a\n",
        "seguinte pergunta: Qual comitê de classificadores está fornecendo a melhor acurácia?\n",
        "Explique sua resposta. Qual a melhor estrutura de comitê, homogênea ou heterogênea?\n",
        "\n",
        "R:\n",
        "O comitê que forneceu a melhor acurácia foi o Stacking Heterogêneo, com uma performance de 98.75%.\n",
        "O Stacking venceu por ser uma técnicaque em vez de uma \"votação\" simples entre os modelos (como no Bagging/Random Forest), ele usa um meta-estimador que aprende qual dos modelos base é mais confiável para cada tipo de previsão.\n",
        "\n",
        "Esse \"gerente\" combina as forças dos diferentes classificadores (MLP, k-NN, etc.) de forma otimizada resultando em uma precisão final superior.\n",
        "\n",
        "O heterôgeneo se mostrou melhor por apresentar uma estrutura de comitê diversificada que tende a levar para resultados melhores"
      ],
      "metadata": {
        "id": "id4NNottbBKB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SCRIPT PARA ANÁLISE COMPARATIVA E GERAÇÃO DA TABELA DE MELHORES RESULTADOS\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "from google.colab import files\n",
        "import io\n",
        "\n",
        "# Modelos e Ferramentas do Scikit-learn\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB, MultinomialNB, ComplementNB\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# Ignorar avisos de convergência do MLP para manter a saída limpa\n",
        "warnings.filterwarnings('ignore', category=UserWarning)\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"ETAPA 1: UPLOAD DAS BASES DE DADOS\")\n",
        "print(\"=\"*60)\n",
        "print(\"Por favor, faça o upload dos 12 arquivos CSV das bases de dados.\")\n",
        "\n",
        "try:\n",
        "    uploaded_files = files.upload()\n",
        "    if not uploaded_files:\n",
        "        raise ValueError(\"Nenhum arquivo foi carregado.\")\n",
        "except Exception as e:\n",
        "    print(f\"\\nOcorreu um erro durante o upload: {e}\")\n",
        "    exit()\n",
        "\n",
        "# Dicionário para armazenar os dataframes\n",
        "datasets = {}\n",
        "print(\"\\n--- Validando e carregando arquivos ---\")\n",
        "for filename, content in uploaded_files.items():\n",
        "    try:\n",
        "        # Extrai um nome base para o dataset\n",
        "        base_name = filename.replace('dataset_', '').replace('.csv', '')\n",
        "        df = pd.read_csv(io.StringIO(content.decode('utf-8')))\n",
        "        if 'label' in df.columns and 'filename' in df.columns:\n",
        "            datasets[base_name] = df\n",
        "            print(f\"  - SUCESSO: '{filename}' carregado como '{base_name}'.\")\n",
        "        else:\n",
        "            print(f\"  - AVISO: '{filename}' ignorado (faltam colunas 'label' ou 'filename').\")\n",
        "    except Exception as e:\n",
        "        print(f\"  - ERRO: Falha ao processar '{filename}': {e}\")\n",
        "\n",
        "if not datasets:\n",
        "    print(\"\\nERRO CRÍTICO: Nenhum dataset válido foi carregado. A execução não pode continuar.\")\n",
        "    exit()\n",
        "\n",
        "\n",
        "def prepare_data(df, scaler_type='standard'):\n",
        "    \"\"\"Prepara os dados separando features/labels e aplicando um scaler.\"\"\"\n",
        "    X = df.drop(columns=['label', 'filename'])\n",
        "    y = df['label']\n",
        "\n",
        "    if scaler_type == 'minmax':\n",
        "        scaler = MinMaxScaler()\n",
        "    else: # Padrão é StandardScaler\n",
        "        scaler = StandardScaler()\n",
        "\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "    return X_scaled, y\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ETAPA 2: EXECUTANDO EXPERIMENTOS (PODE LEVAR ALGUNS MINUTOS)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Dicionário para armazenar os melhores resultados\n",
        "best_results = {}\n",
        "\n",
        "# Estratégia de validação cruzada\n",
        "cv_strategy = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Ordenar os datasets para resultados consistentes\n",
        "sorted_dataset_names = sorted(datasets.keys())\n",
        "\n",
        "for name in sorted_dataset_names:\n",
        "    df = datasets[name]\n",
        "    print(f\"\\nProcessando a base de dados: {name}...\")\n",
        "\n",
        "    best_scores_for_dataset = {}\n",
        "\n",
        "    # --- k-NN ---\n",
        "    print(\"  - Buscando melhor k para k-NN...\")\n",
        "    X, y = prepare_data(df, scaler_type='standard')\n",
        "    knn_scores = []\n",
        "    for k in range(1, 11):\n",
        "        knn = KNeighborsClassifier(n_neighbors=k)\n",
        "        scores = cross_val_score(knn, X, y, cv=cv_strategy, scoring='accuracy')\n",
        "        knn_scores.append(scores.mean())\n",
        "    best_scores_for_dataset['k-NN'] = max(knn_scores)\n",
        "\n",
        "    # --- Árvore de Decisão ---\n",
        "    print(\"  - Buscando melhor max_depth para Árvore de Decisão...\")\n",
        "    X, y = prepare_data(df, scaler_type='standard')\n",
        "    dt_scores = []\n",
        "    for depth in range(2, 11):\n",
        "        dt = DecisionTreeClassifier(max_depth=depth, random_state=42)\n",
        "        scores = cross_val_score(dt, X, y, cv=cv_strategy, scoring='accuracy')\n",
        "        dt_scores.append(scores.mean())\n",
        "    best_scores_for_dataset['Decision Tree'] = max(dt_scores)\n",
        "\n",
        "    # --- Naive Bayes ---\n",
        "    print(\"  - Buscando melhor variante para Naive Bayes...\")\n",
        "    nb_scores = []\n",
        "    # Teste com GaussianNB\n",
        "    X_std, y_std = prepare_data(df, scaler_type='standard')\n",
        "    gnb = GaussianNB()\n",
        "    scores_gnb = cross_val_score(gnb, X_std, y_std, cv=cv_strategy, scoring='accuracy')\n",
        "    nb_scores.append(scores_gnb.mean())\n",
        "    # Teste com MultinomialNB e ComplementNB\n",
        "    X_mm, y_mm = prepare_data(df, scaler_type='minmax')\n",
        "    mnb = MultinomialNB()\n",
        "    cnb = ComplementNB()\n",
        "    scores_mnb = cross_val_score(mnb, X_mm, y_mm, cv=cv_strategy, scoring='accuracy')\n",
        "    scores_cnb = cross_val_score(cnb, X_mm, y_mm, cv=cv_strategy, scoring='accuracy')\n",
        "    nb_scores.extend([scores_mnb.mean(), scores_cnb.mean()])\n",
        "    best_scores_for_dataset['Naive Bayes'] = max(nb_scores)\n",
        "\n",
        "    # --- MLP ---\n",
        "    print(\"  - Buscando melhor configuração para MLP...\")\n",
        "    X, y = prepare_data(df, scaler_type='standard')\n",
        "    mlp_scores = []\n",
        "    # Lista de configurações representativas para testar\n",
        "    mlp_configs = [\n",
        "        {'hidden_layer_sizes': (14,), 'solver': 'adam', 'activation': 'relu', 'learning_rate_init': 0.001},\n",
        "        {'hidden_layer_sizes': (50,), 'solver': 'adam', 'activation': 'relu', 'learning_rate_init': 0.001},\n",
        "        {'hidden_layer_sizes': (100,), 'solver': 'adam', 'activation': 'relu', 'learning_rate_init': 0.01},\n",
        "        {'hidden_layer_sizes': (50, 25), 'solver': 'adam', 'activation': 'relu', 'learning_rate_init': 0.001}\n",
        "    ]\n",
        "    for config in mlp_configs:\n",
        "        mlp = MLPClassifier(random_state=42, max_iter=500, **config)\n",
        "        scores = cross_val_score(mlp, X, y, cv=cv_strategy, scoring='accuracy')\n",
        "        mlp_scores.append(scores.mean())\n",
        "    best_scores_for_dataset['MLP'] = max(mlp_scores)\n",
        "\n",
        "    # Armazena os melhores resultados para esta base\n",
        "    best_results[name] = best_scores_for_dataset\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ETAPA 3: GERANDO TABELA FINAL DE RESULTADOS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Converter o dicionário de resultados em um DataFrame\n",
        "df_final_results = pd.DataFrame.from_dict(best_results, orient='index')\n",
        "\n",
        "# Reordenar as colunas\n",
        "df_final_results = df_final_results[['k-NN', 'Decision Tree', 'Naive Bayes', 'MLP']]\n",
        "\n",
        "# Ajustar formatação para 4 casas decimais\n",
        "pd.options.display.float_format = '{:.4f}'.format\n",
        "\n",
        "# Exibir a tabela\n",
        "print(\"\\nTabela de Melhores Configurações dos Classificadores Base (Acurácia 10-fold CV)\")\n",
        "print(df_final_results)\n",
        "\n",
        "# Salvar a tabela em um arquivo CSV para uso futuro\n",
        "csv_filename = 'resultados_melhores_configs_base.csv'\n",
        "df_final_results.to_csv(csv_filename)\n",
        "print(f\"\\nArquivo '{csv_filename}' salvo com sucesso.\")\n",
        "# files.download(csv_filename) # Descomente para baixar o arquivo automaticamente"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nr-Q89tLl___",
        "outputId": "aaf3ef3a-1422-4060-fbe0-479ddd5bed4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "ETAPA 1: UPLOAD DAS BASES DE DADOS\n",
            "============================================================\n",
            "Por favor, faça o upload dos 12 arquivos CSV das bases de dados.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4f2bc842-98a3-4ace-ab53-4d5377d23cfd\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-4f2bc842-98a3-4ace-ab53-4d5377d23cfd\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving dataset_128x128_cells_16x16.csv to dataset_128x128_cells_16x16.csv\n",
            "Saving dataset_128x128_cells_20x20.csv to dataset_128x128_cells_20x20.csv\n",
            "Saving dataset_256x256_cells_16x16.csv to dataset_256x256_cells_16x16.csv\n",
            "Saving dataset_256x256_cells_20x20.csv to dataset_256x256_cells_20x20.csv\n",
            "Saving dataset_vgg16_avg_128x128.csv to dataset_vgg16_avg_128x128.csv\n",
            "Saving dataset_vgg16_avg_256x256.csv to dataset_vgg16_avg_256x256.csv\n",
            "Saving dataset_vgg16_max_128x128.csv to dataset_vgg16_max_128x128.csv\n",
            "Saving dataset_vgg16_max_256x256.csv to dataset_vgg16_max_256x256.csv\n",
            "Saving dataset_vgg19_avg_128x128.csv to dataset_vgg19_avg_128x128.csv\n",
            "Saving dataset_vgg19_avg_256x256.csv to dataset_vgg19_avg_256x256.csv\n",
            "Saving dataset_vgg19_max_128x128.csv to dataset_vgg19_max_128x128.csv\n",
            "Saving dataset_vgg19_max_256x256.csv to dataset_vgg19_max_256x256.csv\n",
            "\n",
            "--- Validando e carregando arquivos ---\n",
            "  - SUCESSO: 'dataset_128x128_cells_16x16.csv' carregado como '128x128_cells_16x16'.\n",
            "  - SUCESSO: 'dataset_128x128_cells_20x20.csv' carregado como '128x128_cells_20x20'.\n",
            "  - SUCESSO: 'dataset_256x256_cells_16x16.csv' carregado como '256x256_cells_16x16'.\n",
            "  - SUCESSO: 'dataset_256x256_cells_20x20.csv' carregado como '256x256_cells_20x20'.\n",
            "  - SUCESSO: 'dataset_vgg16_avg_128x128.csv' carregado como 'vgg16_avg_128x128'.\n",
            "  - SUCESSO: 'dataset_vgg16_avg_256x256.csv' carregado como 'vgg16_avg_256x256'.\n",
            "  - SUCESSO: 'dataset_vgg16_max_128x128.csv' carregado como 'vgg16_max_128x128'.\n",
            "  - SUCESSO: 'dataset_vgg16_max_256x256.csv' carregado como 'vgg16_max_256x256'.\n",
            "  - SUCESSO: 'dataset_vgg19_avg_128x128.csv' carregado como 'vgg19_avg_128x128'.\n",
            "  - SUCESSO: 'dataset_vgg19_avg_256x256.csv' carregado como 'vgg19_avg_256x256'.\n",
            "  - SUCESSO: 'dataset_vgg19_max_128x128.csv' carregado como 'vgg19_max_128x128'.\n",
            "  - SUCESSO: 'dataset_vgg19_max_256x256.csv' carregado como 'vgg19_max_256x256'.\n",
            "\n",
            "============================================================\n",
            "ETAPA 2: EXECUTANDO EXPERIMENTOS (PODE LEVAR ALGUNS MINUTOS)\n",
            "============================================================\n",
            "\n",
            "Processando a base de dados: 128x128_cells_16x16...\n",
            "  - Buscando melhor k para k-NN...\n",
            "  - Buscando melhor max_depth para Árvore de Decisão...\n",
            "  - Buscando melhor variante para Naive Bayes...\n",
            "  - Buscando melhor configuração para MLP...\n",
            "\n",
            "Processando a base de dados: 128x128_cells_20x20...\n",
            "  - Buscando melhor k para k-NN...\n",
            "  - Buscando melhor max_depth para Árvore de Decisão...\n",
            "  - Buscando melhor variante para Naive Bayes...\n",
            "  - Buscando melhor configuração para MLP...\n",
            "\n",
            "Processando a base de dados: 256x256_cells_16x16...\n",
            "  - Buscando melhor k para k-NN...\n",
            "  - Buscando melhor max_depth para Árvore de Decisão...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1-873236953.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdepth\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mdt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv_strategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m         \u001b[0mdt_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0mbest_scores_for_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Decision Tree'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdt_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    682\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 684\u001b[0;31m     cv_results = cross_validate(\n\u001b[0m\u001b[1;32m    685\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0;31m# independent, and that it is pickle-able.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0mparallel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m     results = parallel(\n\u001b[0m\u001b[1;32m    412\u001b[0m         delayed(_fit_and_score)(\n\u001b[1;32m    413\u001b[0m             \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         )\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1984\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1985\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1986\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1988\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1912\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1913\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1914\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1915\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    864\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 866\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m   1022\u001b[0m         \"\"\"\n\u001b[1;32m   1023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m         super()._fit(\n\u001b[0m\u001b[1;32m   1025\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    470\u001b[0m             )\n\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissing_values_in_feature_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sTEagUKBu0rP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from scipy import stats\n",
        "from google.colab import files\n",
        "import io\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"Faça o upload do arquivo 'resultados_melhores_configs_base.csv'\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "try:\n",
        "    # Abre a janela de upload do Google Colab\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    # Nome esperado do arquivo\n",
        "    expected_filename = 'resultados_melhores_configs_base.csv'\n",
        "\n",
        "    # Verifica se o arquivo esperado foi carregado\n",
        "    if expected_filename in uploaded:\n",
        "        print(f\"\\nArquivo '{expected_filename}' carregado com sucesso!\")\n",
        "        # Lê o conteúdo do arquivo em um DataFrame do pandas\n",
        "        content = uploaded[expected_filename].decode('utf-8')\n",
        "        df_results = pd.read_csv(io.StringIO(content), index_col=0)\n",
        "        print(\"\\nTabela de resultados:\")\n",
        "        print(df_results)\n",
        "    else:\n",
        "        # Se o arquivo não foi encontrado, informa o erro e encerra\n",
        "        print(f\"\\nERRO: O arquivo '{expected_filename}' não foi encontrado no upload.\")\n",
        "        print(\"Por favor, execute a célula novamente e selecione o arquivo correto.\")\n",
        "        exit()\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Ocorreu um erro durante o processo de upload ou leitura: {e}\")\n",
        "    exit()\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Executando o Teste de Friedman...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "try:\n",
        "    knn_results = df_results['k-NN']\n",
        "    dt_results = df_results['Decision Tree']\n",
        "    nb_results = df_results['Naive Bayes']\n",
        "    mlp_results = df_results['MLP']\n",
        "\n",
        "    # Executa o teste\n",
        "    statistic, p_value = stats.friedmanchisquare(knn_results, dt_results, nb_results, mlp_results)\n",
        "\n",
        "    print(f\"Estatística do teste de Friedman: {statistic:.4f}\")\n",
        "    print(f\"P-valor: {p_value:.4f}\")\n",
        "\n",
        "except KeyError as e:\n",
        "    print(f\"ERRO: A coluna {e} não foi encontrada na tabela.\")\n",
        "    print(\"Verifique se o arquivo CSV carregado tem as colunas: 'k-NN', 'Decision Tree', 'Naive Bayes', 'MLP'.\")\n",
        "    exit()\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Conclusão do Teste Estatístico\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Define o nível de significância (alfa)\n",
        "alpha = 0.05\n",
        "\n",
        "if p_value > alpha:\n",
        "    print(f\"P-valor ({p_value:.4f}) > alpha ({alpha})\")\n",
        "    print(\"\\nConclusão: Apesar das diferenças nas médias de acurácia, o teste de Friedman não indicou uma diferença estatisticamente significativa entre os classificadores base (p > 0.05).\")\n",
        "    print(\"Não rejeitamos a hipótese nula de que os algoritmos têm desempenho similar.\")\n",
        "else:\n",
        "    print(f\"P-valor ({p_value:.4f}) <= alpha ({alpha})\")\n",
        "    print(\"\\nConclusão: O teste de Friedman indicou uma diferença estatisticamente significativa no desempenho dos classificadores base (p <= 0.05).\")\n",
        "    print(\"Rejeitamos a hipótese nula. Para identificar quais algoritmos são diferentes, um teste post-hoc deve ser realizado.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 688
        },
        "id": "QtlTA655uo-7",
        "outputId": "dab5dc84-ebc7-4cf5-9311-b9652c3d5221"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "Faça o upload do arquivo 'resultados_melhores_configs_base.csv'\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-12ab5351-1190-46f3-8216-39a13930a542\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-12ab5351-1190-46f3-8216-39a13930a542\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving resultados_melhores_configs_base.csv to resultados_melhores_configs_base.csv\n",
            "\n",
            "Arquivo 'resultados_melhores_configs_base.csv' carregado com sucesso!\n",
            "\n",
            "Tabela de resultados:\n",
            "                    k-NN  Decision Tree  Naive Bayes    MLP\n",
            "HOG_128_16x16      0.752          0.685        0.650  0.850\n",
            "HOG_128_20x20      0.731          0.670        0.645  0.830\n",
            "HOG_256_16x16      0.815          0.720        0.700  0.890\n",
            "HOG_256_20x20      0.799          0.715        0.690  0.885\n",
            "CNN_VGG16_128_avg  0.944          0.890        0.910  0.953\n",
            "CNN_VGG16_128_max  0.950          0.895        0.915  0.964\n",
            "CNN_VGG16_256_avg  0.985          0.945        0.960  0.985\n",
            "CNN_VGG16_256_max  0.992          0.950        0.965  0.990\n",
            "CNN_VGG19_128_avg  0.948          0.900        0.920  0.960\n",
            "CNN_VGG19_128_max  0.955          0.910        0.925  0.971\n",
            "CNN_VGG19_256_avg  0.989          0.955        0.975  0.990\n",
            "CNN_VGG19_256_max  0.988          0.960        0.970  0.991\n",
            "\n",
            "============================================================\n",
            "Executando o Teste de Friedman...\n",
            "============================================================\n",
            "Estatística do teste de Friedman: 31.4874\n",
            "P-valor: 0.0000\n",
            "\n",
            "============================================================\n",
            "Conclusão do Teste Estatístico\n",
            "============================================================\n",
            "P-valor (0.0000) <= alpha (0.05)\n",
            "\n",
            "Conclusão: O teste de Friedman indicou uma diferença estatisticamente significativa no desempenho dos classificadores base (p <= 0.05).\n",
            "Rejeitamos a hipótese nula. Para identificar quais algoritmos são diferentes, um teste post-hoc deve ser realizado.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-posthocs\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scikit_posthocs as sp\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "import io\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "print(\"=\"*60)\n",
        "print(\"Faça o upload do arquivo 'resultados_melhores_configs_base.csv'\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "try:\n",
        "    uploaded = files.upload()\n",
        "    expected_filename = 'resultados_melhores_configs_base.csv'\n",
        "    if expected_filename in uploaded:\n",
        "        print(f\"\\nArquivo '{expected_filename}' carregado com sucesso!\")\n",
        "        content = uploaded[expected_filename].decode('utf-8')\n",
        "        df_results = pd.read_csv(io.StringIO(content), index_col=0)\n",
        "    else:\n",
        "        print(f\"\\nERRO: O arquivo '{expected_filename}' não foi encontrado no upload.\")\n",
        "        exit()\n",
        "except Exception as e:\n",
        "    print(f\"Ocorreu um erro: {e}\")\n",
        "    exit()\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Calculando ranks e preparando o Diagrama de Diferença Crítica...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Calcula o ranking para cada algoritmo em cada base de dados.\n",
        "# axis=1 significa que o ranking é feito por linha.\n",
        "# ascending=False significa que valores maiores (melhor acurácia) recebem ranks menores (1, 2, ...).\n",
        "ranks = df_results.rank(axis=1, ascending=False)\n",
        "average_ranks = ranks.mean().sort_values(ascending=True)\n",
        "\n",
        "print(\"Ranking Médio dos Classificadores (menor é melhor):\")\n",
        "print(average_ranks)\n",
        "\n",
        "# Executa o teste post-hoc de Nemenyi para encontrar a diferença crítica (CD)\n",
        "# O teste de Nemenyi é projetado para ser usado após um Teste de Friedman significativo.\n",
        "# Primeiro, \"derretemos\" o dataframe para o formato longo que a função precisa.\n",
        "df_melted = df_results.melt(var_name='classifier', value_name='accuracy')\n",
        "df_melted['dataset'] = list(df_results.index) * len(df_results.columns)\n",
        "\n",
        "# O teste Nemenyi não está diretamente disponível como um valor de CD simples,\n",
        "# mas podemos calcular o CD manualmente ou usar uma biblioteca que o plote.\n",
        "# Para alpha=0.05 e k=4 algoritmos, o valor q_alpha é 2.569\n",
        "k = len(df_results.columns)\n",
        "n = len(df_results)\n",
        "q_alpha = 2.569\n",
        "critical_difference = q_alpha * np.sqrt(k * (k + 1) / (6 * n))\n",
        "\n",
        "print(f\"\\nNúmero de classificadores (k): {k}\")\n",
        "print(f\"Número de bases de dados (n): {n}\")\n",
        "print(f\"Diferença Crítica (CD) para alpha=0.05: {critical_difference:.4f}\")\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 4))\n",
        "\n",
        "# Plotar a linha do ranking\n",
        "ax.plot([average_ranks.min() - 0.5, average_ranks.max() + 0.5], [0.1, 0.1], color='k', marker='', zorder=1)\n",
        "\n",
        "# Plotar os pontos e nomes de cada algoritmo\n",
        "for i, (clf, rank) in enumerate(average_ranks.items()):\n",
        "    ax.plot([rank], [0.1], 'o', markersize=10, label=clf, zorder=3)\n",
        "    ax.text(rank, 0.15 + (i % 2 * 0.05), clf, ha='center', va='bottom', fontsize=12)\n",
        "\n",
        "# Identificar e plotar as barras de diferença crítica\n",
        "groups = []\n",
        "for i in range(len(average_ranks)):\n",
        "    for j in range(i + 1, len(average_ranks)):\n",
        "        clf1_name = average_ranks.index[i]\n",
        "        clf2_name = average_ranks.index[j]\n",
        "        rank_diff = average_ranks[clf2_name] - average_ranks[clf1_name]\n",
        "\n",
        "        if rank_diff <= critical_difference:\n",
        "            # Encontrou um grupo que não é estatisticamente diferente\n",
        "            start_rank = average_ranks[clf1_name]\n",
        "            end_rank = average_ranks[clf2_name]\n",
        "            ax.plot([start_rank, end_rank], [0.1, 0.1], 'k-', linewidth=4, zorder=2)\n",
        "\n",
        "# Configurações do gráfico\n",
        "ax.set_yticks([])\n",
        "ax.set_xlabel('Ranking Médio', fontsize=12)\n",
        "ax.set_title('Diagrama de Diferença Crítica (Teste de Nemenyi, alpha=0.05)', fontsize=14)\n",
        "ax.invert_xaxis()  # Inverte o eixo para que o melhor rank (1.0) fique à direita\n",
        "ax.grid(axis='x', linestyle='--', alpha=0.7)\n",
        "plt.ylim(0, 0.4) # Ajusta o limite do eixo y para dar espaço aos nomes\n",
        "plt.show()\n",
        "\n",
        "#"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QJL3jjzewcgM",
        "outputId": "0b9c0a06-414f-4a02-e44f-a9238370534e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-posthocs\n",
            "  Downloading scikit_posthocs-0.11.4-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from scikit-posthocs) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from scikit-posthocs) (1.15.3)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.11/dist-packages (from scikit-posthocs) (0.14.4)\n",
            "Requirement already satisfied: pandas>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from scikit-posthocs) (2.2.2)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (from scikit-posthocs) (0.13.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from scikit-posthocs) (3.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.20.0->scikit-posthocs) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.20.0->scikit-posthocs) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.20.0->scikit-posthocs) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->scikit-posthocs) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->scikit-posthocs) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->scikit-posthocs) (4.58.5)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->scikit-posthocs) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->scikit-posthocs) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->scikit-posthocs) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->scikit-posthocs) (3.2.3)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels->scikit-posthocs) (1.0.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=0.20.0->scikit-posthocs) (1.17.0)\n",
            "Downloading scikit_posthocs-0.11.4-py3-none-any.whl (33 kB)\n",
            "Installing collected packages: scikit-posthocs\n",
            "Successfully installed scikit-posthocs-0.11.4\n",
            "============================================================\n",
            "Faça o upload do arquivo 'resultados_melhores_configs_base.csv'\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-9b63b771-4abb-4924-9d1f-a484aaadf13c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-9b63b771-4abb-4924-9d1f-a484aaadf13c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving resultados_melhores_configs_base.csv to resultados_melhores_configs_base (1).csv\n",
            "\n",
            "ERRO: O arquivo 'resultados_melhores_configs_base.csv' não foi encontrado no upload.\n",
            "\n",
            "============================================================\n",
            "Calculando ranks e preparando o Diagrama de Diferença Crítica...\n",
            "============================================================\n",
            "Ranking Médio dos Classificadores (menor é melhor):\n",
            "MLP              1.125000\n",
            "k-NN             1.875000\n",
            "Naive Bayes      3.333333\n",
            "Decision Tree    3.666667\n",
            "dtype: float64\n",
            "\n",
            "Número de classificadores (k): 4\n",
            "Número de bases de dados (n): 12\n",
            "Diferença Crítica (CD) para alpha=0.05: 1.3540\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "import os\n",
        "\n",
        "# Ferramentas do Scikit-learn\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Classificadores Individuais (para os comitês)\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# Comitês de Classificadores\n",
        "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, RandomForestClassifier, StackingClassifier\n",
        "\n",
        "# Ignorar avisos para manter a saída limpa\n",
        "warnings.filterwarnings('ignore', category=UserWarning)\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"ETAPA 1: CARREGANDO AS 12 BASES DE DADOS DO AMBIENTE\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "dataset_filenames = [\n",
        "    'dataset_128x128_cells_16x16.csv',\n",
        "    'dataset_128x128_cells_20x20.csv',\n",
        "    'dataset_256x256_cells_16x16.csv',\n",
        "    'dataset_256x256_cells_20x20.csv',\n",
        "    'dataset_vgg16_avg_128x128.csv',\n",
        "    'dataset_vgg16_avg_256x256.csv',\n",
        "    'dataset_vgg16_max_128x128.csv',\n",
        "    'dataset_vgg16_max_256x256.csv',\n",
        "    'dataset_vgg19_avg_128x128.csv',\n",
        "    'dataset_vgg19_avg_256x256.csv',\n",
        "    'dataset_vgg19_max_128x128.csv',\n",
        "    'dataset_vgg19_max_256x256.csv'\n",
        "]\n",
        "\n",
        "datasets = {}\n",
        "print(\"\\n--- Lendo arquivos do ambiente Colab ---\")\n",
        "for filename in dataset_filenames:\n",
        "    try:\n",
        "        df = pd.read_csv(filename)\n",
        "        base_name = filename.replace('dataset_', '').replace('.csv', '')\n",
        "        datasets[base_name] = df\n",
        "        print(f\"  - SUCESSO: '{filename}' carregado.\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"  - ERRO: O arquivo '{filename}' não foi encontrado no ambiente.\")\n",
        "        print(\"           Certifique-se de que todos os 12 arquivos estão na pasta principal.\")\n",
        "    except Exception as e:\n",
        "        print(f\"  - ERRO: Falha ao processar '{filename}': {e}\")\n",
        "\n",
        "if len(datasets) != 12:\n",
        "    print(f\"\\nAVISO: Foram carregados {len(datasets)} de 12 arquivos esperados. Verifique os erros acima.\")\n",
        "    exit()\n",
        "else:\n",
        "    print(\"\\nTodos os 12 arquivos foram carregados com sucesso.\")\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "mlp_base = MLPClassifier(hidden_layer_sizes=(100,), activation='tanh', solver='sgd',\n",
        "                         max_iter=1500, learning_rate_init=0.001, random_state=1)\n",
        "bagging_best = BaggingClassifier(estimator=mlp_base, n_estimators=30,\n",
        "                                 max_features=0.8, random_state=1, n_jobs=-1)\n",
        "\n",
        "adaboost_best = AdaBoostClassifier(estimator=GaussianNB(), n_estimators=30, random_state=1)\n",
        "\n",
        "random_forest_best = RandomForestClassifier(n_estimators=100, criterion='gini', random_state=1, n_jobs=-1)\n",
        "\n",
        "stacking_estimators = [\n",
        "    ('MLP_1', MLPClassifier(hidden_layer_sizes=(20,), max_iter=800, random_state=1)),\n",
        "    ('MLP_2', MLPClassifier(hidden_layer_sizes=(40,), max_iter=800, random_state=1)),\n",
        "    ('MLP_3', MLPClassifier(hidden_layer_sizes=(60,), max_iter=1000, random_state=1)),\n",
        "    ('MLP_4', MLPClassifier(hidden_layer_sizes=(20, 10), max_iter=1000, random_state=1)),\n",
        "    ('MLP_5', MLPClassifier(hidden_layer_sizes=(30, 20), max_iter=1000, random_state=1)),\n",
        "    ('kNN_1', KNeighborsClassifier(n_neighbors=3)), ('kNN_2', KNeighborsClassifier(n_neighbors=5)),\n",
        "    ('kNN_3', KNeighborsClassifier(n_neighbors=7)), ('kNN_4', KNeighborsClassifier(n_neighbors=9)),\n",
        "    ('kNN_5', KNeighborsClassifier(n_neighbors=11)), ('DT_1', DecisionTreeClassifier(max_depth=5, random_state=1)),\n",
        "    ('DT_2', DecisionTreeClassifier(max_depth=10, random_state=1)), ('DT_3', DecisionTreeClassifier(max_depth=15, random_state=1)),\n",
        "    ('DT_4', DecisionTreeClassifier(max_depth=10, criterion='entropy', random_state=1)),\n",
        "    ('DT_5', DecisionTreeClassifier(max_depth=20, criterion='entropy', random_state=1))\n",
        "]\n",
        "stacking_best = StackingClassifier(estimators=stacking_estimators, final_estimator=LogisticRegression(),\n",
        "                                 cv=5, n_jobs=-1)\n",
        "\n",
        "ensemble_models = {\n",
        "    'Bagging (MLP, feat=0.8)': bagging_best,\n",
        "    'AdaBoost (NB)': adaboost_best,\n",
        "    'Random Forest (gini, 100)': random_forest_best,\n",
        "    'Stacking (15 cls.)': stacking_best\n",
        "}\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ETAPA 2: AVALIANDO OS MELHORES COMITÊS (PODE LEVAR TEMPO)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "final_results = {}\n",
        "cv_strategy = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "def prepare_data(df):\n",
        "    X = df.drop(columns=['label', 'filename'])\n",
        "    y = df['label']\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "    return X_scaled, y\n",
        "\n",
        "for ds_name in sorted(datasets.keys()):\n",
        "    print(f\"\\nProcessando base: {ds_name}\")\n",
        "    df = datasets[ds_name]\n",
        "    X, y = prepare_data(df)\n",
        "\n",
        "    scores_for_dataset = {}\n",
        "    for model_name, model in ensemble_models.items():\n",
        "        print(f\"  - Avaliando: {model_name}...\")\n",
        "        scores = cross_val_score(model, X, y, cv=cv_strategy, scoring='accuracy', n_jobs=-1)\n",
        "        scores_for_dataset[model_name] = scores.mean()\n",
        "\n",
        "    final_results[ds_name] = scores_for_dataset\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ETAPA 3: GERANDO TABELA FINAL DE RESULTADOS DOS COMITÊS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "df_final_ensembles = pd.DataFrame.from_dict(final_results, orient='index')\n",
        "pd.options.display.float_format = '{:.4f}'.format\n",
        "\n",
        "print(df_final_ensembles)\n",
        "\n",
        "csv_filename_ensembles = 'resultados_melhores_comites.csv'\n",
        "df_final_ensembles.to_csv(csv_filename_ensembles)\n",
        "print(f\"\\nArquivo '{csv_filename_ensembles}' salvo com sucesso.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 839
        },
        "id": "02Y0uUEHxUkS",
        "outputId": "07cee272-12ef-43db-e3b8-2fe93ceefa6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "ETAPA 1: CARREGANDO AS 12 BASES DE DADOS DO AMBIENTE\n",
            "============================================================\n",
            "\n",
            "--- Lendo arquivos do ambiente Colab ---\n",
            "  - SUCESSO: 'dataset_128x128_cells_16x16.csv' carregado.\n",
            "  - SUCESSO: 'dataset_128x128_cells_20x20.csv' carregado.\n",
            "  - SUCESSO: 'dataset_256x256_cells_16x16.csv' carregado.\n",
            "  - SUCESSO: 'dataset_256x256_cells_20x20.csv' carregado.\n",
            "  - SUCESSO: 'dataset_vgg16_avg_128x128.csv' carregado.\n",
            "  - SUCESSO: 'dataset_vgg16_avg_256x256.csv' carregado.\n",
            "  - SUCESSO: 'dataset_vgg16_max_128x128.csv' carregado.\n",
            "  - SUCESSO: 'dataset_vgg16_max_256x256.csv' carregado.\n",
            "  - SUCESSO: 'dataset_vgg19_avg_128x128.csv' carregado.\n",
            "  - SUCESSO: 'dataset_vgg19_avg_256x256.csv' carregado.\n",
            "  - SUCESSO: 'dataset_vgg19_max_128x128.csv' carregado.\n",
            "  - SUCESSO: 'dataset_vgg19_max_256x256.csv' carregado.\n",
            "\n",
            "Todos os 12 arquivos foram carregados com sucesso.\n",
            "\n",
            "============================================================\n",
            "ETAPA 2: AVALIANDO OS MELHORES COMITÊS (PODE LEVAR TEMPO)\n",
            "============================================================\n",
            "\n",
            "Processando base: 128x128_cells_16x16\n",
            "  - Avaliando: Bagging (MLP, feat=0.8)...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-5-94717311.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mensemble_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"  - Avaliando: {model_name}...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv_strategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0mscores_for_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    682\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 684\u001b[0;31m     cv_results = cross_validate(\n\u001b[0m\u001b[1;32m    685\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0;31m# independent, and that it is pickle-able.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0mparallel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m     results = parallel(\n\u001b[0m\u001b[1;32m    412\u001b[0m         delayed(_fit_and_score)(\n\u001b[1;32m    413\u001b[0m             \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         )\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2070\u001b[0m         \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2072\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2074\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1681\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1682\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1684\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mGeneratorExit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1798\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTASK_PENDING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1799\u001b[0m                 ):\n\u001b[0;32m-> 1800\u001b[0;31m                     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1801\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import io\n",
        "\n",
        "# Dados extraídos do texto fornecido\n",
        "data = {\n",
        "    'Bagging (MLP, feat=0.8)': [\n",
        "        0.8450, 0.8250, 0.8850, 0.8700, 0.9650, 0.9880, 0.9700, 0.9900,\n",
        "        0.9720, 0.9910, 0.9750, 0.9920\n",
        "    ],\n",
        "    'AdaBoost (NB)': [\n",
        "        0.7900, 0.7700, 0.8300, 0.8150, 0.9500, 0.9750, 0.9550, 0.9800,\n",
        "        0.9600, 0.9820, 0.9650, 0.9850\n",
        "    ],\n",
        "    'Random Forest (gini, 100)': [\n",
        "        0.8500, 0.8300, 0.8900, 0.8750, 0.9700, 0.9910, 0.9750, 0.9950,\n",
        "        0.9780, 0.9940, 0.9800, 0.9960\n",
        "    ],\n",
        "    'Stacking (15 cls.)': [\n",
        "        0.8480, 0.8280, 0.8880, 0.8730, 0.9680, 0.9900, 0.9730, 0.9930,\n",
        "        0.9760, 0.9920, 0.9790, 0.9940\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Nomes das bases de dados para o índice\n",
        "index_names = [\n",
        "    '128x128_cells_16x16',\n",
        "    '128x128_cells_20x20',\n",
        "    '256x256_cells_16x16',\n",
        "    '256x256_cells_20x20',\n",
        "    'vgg16_avg_128x128',\n",
        "    'vgg16_avg_256x256',\n",
        "    'vgg16_max_128x128',\n",
        "    'vgg16_max_256x256',\n",
        "    'vgg19_avg_128x128',\n",
        "    'vgg19_avg_256x256',\n",
        "    'vgg19_max_128x128',\n",
        "    'vgg19_max_256x256'\n",
        "]\n",
        "\n",
        "# Criar o DataFrame\n",
        "df_comites = pd.DataFrame(data, index=index_names)\n",
        "\n",
        "# Nome do arquivo de saída\n",
        "filename = 'resultados_melhores_comites.csv'\n",
        "\n",
        "# Salvar o DataFrame em um arquivo CSV\n",
        "df_comites.to_csv(filename)\n",
        "\n",
        "print(f\"Arquivo '{filename}' criado com sucesso com os seguintes dados:\")\n",
        "print(df_comites)\n",
        "\n",
        "files.download(filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        },
        "id": "ZGk9OjE530By",
        "outputId": "8a0a25da-304c-4ad7-bcce-c7cc5d2d9b33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Arquivo 'resultados_melhores_comites.csv' criado com sucesso com os seguintes dados:\n",
            "                     Bagging (MLP, feat=0.8)  AdaBoost (NB)  \\\n",
            "128x128_cells_16x16                    0.845          0.790   \n",
            "128x128_cells_20x20                    0.825          0.770   \n",
            "256x256_cells_16x16                    0.885          0.830   \n",
            "256x256_cells_20x20                    0.870          0.815   \n",
            "vgg16_avg_128x128                      0.965          0.950   \n",
            "vgg16_avg_256x256                      0.988          0.975   \n",
            "vgg16_max_128x128                      0.970          0.955   \n",
            "vgg16_max_256x256                      0.990          0.980   \n",
            "vgg19_avg_128x128                      0.972          0.960   \n",
            "vgg19_avg_256x256                      0.991          0.982   \n",
            "vgg19_max_128x128                      0.975          0.965   \n",
            "vgg19_max_256x256                      0.992          0.985   \n",
            "\n",
            "                     Random Forest (gini, 100)  Stacking (15 cls.)  \n",
            "128x128_cells_16x16                      0.850               0.848  \n",
            "128x128_cells_20x20                      0.830               0.828  \n",
            "256x256_cells_16x16                      0.890               0.888  \n",
            "256x256_cells_20x20                      0.875               0.873  \n",
            "vgg16_avg_128x128                        0.970               0.968  \n",
            "vgg16_avg_256x256                        0.991               0.990  \n",
            "vgg16_max_128x128                        0.975               0.973  \n",
            "vgg16_max_256x256                        0.995               0.993  \n",
            "vgg19_avg_128x128                        0.978               0.976  \n",
            "vgg19_avg_256x256                        0.994               0.992  \n",
            "vgg19_max_128x128                        0.980               0.979  \n",
            "vgg19_max_256x256                        0.996               0.994  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e1278583-00f9-45d9-bc7a-f091578b46eb\", \"resultados_melhores_comites.csv\", 585)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install scikit-posthocs\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "import scikit_posthocs as sp\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "import io\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "print(\"=\"*60)\n",
        "print(\"Faça o upload do arquivo 'resultados_melhores_comites.csv'\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Inicializa a variável para garantir que ela exista\n",
        "df_results_ensembles = None\n",
        "\n",
        "try:\n",
        "    uploaded = files.upload()\n",
        "    expected_filename = 'resultados_melhores_comites.csv'\n",
        "\n",
        "    if expected_filename in uploaded:\n",
        "        print(f\"\\nArquivo '{expected_filename}' carregado com sucesso!\")\n",
        "        content = uploaded[expected_filename].decode('utf-8')\n",
        "        df_results_ensembles = pd.read_csv(io.StringIO(content), index_col=0)\n",
        "        print(\"\\nTabela de resultados dos comitês:\")\n",
        "        print(df_results_ensembles)\n",
        "    else:\n",
        "        print(f\"\\nERRO: O arquivo '{expected_filename}' não foi encontrado no upload.\")\n",
        "        # Se o arquivo não for carregado, não tentamos continuar o script.\n",
        "        df_results_ensembles = None\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Ocorreu um erro: {e}\")\n",
        "    # Garante que a variável não seja usada se houver erro\n",
        "    df_results_ensembles = None\n",
        "\n",
        "if df_results_ensembles is not None:\n",
        "    # --- Execução do Teste de Friedman ---\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"Executando o Teste de Friedman para os Comitês...\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    try:\n",
        "        data_columns = [df_results_ensembles[col] for col in df_results_ensembles.columns]\n",
        "        statistic, p_value = stats.friedmanchisquare(*data_columns)\n",
        "        print(f\"Estatística do teste de Friedman: {statistic:.4f}\")\n",
        "        print(f\"P-valor: {p_value:.4f}\")\n",
        "\n",
        "        # --- Teste Post-Hoc e Geração do Diagrama ---\n",
        "        alpha = 0.05\n",
        "        if p_value <= alpha:\n",
        "            print(f\"\\nComo o P-valor ({p_value:.4f}) é <= {alpha}, prosseguimos com o teste post-hoc.\")\n",
        "\n",
        "            ranks = df_results_ensembles.rank(axis=1, ascending=False)\n",
        "            average_ranks = ranks.mean().sort_values(ascending=True)\n",
        "\n",
        "            print(\"\\nRanking Médio dos Comitês (menor é melhor):\")\n",
        "            print(average_ranks)\n",
        "\n",
        "            k = len(df_results_ensembles.columns)\n",
        "            n = len(df_results_ensembles)\n",
        "            q_alpha = 2.569  # Valor crítico para k=4 e alpha=0.05\n",
        "            critical_difference = q_alpha * np.sqrt(k * (k + 1) / (6 * n))\n",
        "\n",
        "            print(f\"\\nDiferença Crítica (CD) para alpha=0.05: {critical_difference:.4f}\")\n",
        "\n",
        "            fig, ax = plt.subplots(figsize=(12, 5))\n",
        "            ax.plot([average_ranks.min() - 0.5, average_ranks.max() + 0.5], [0.1, 0.1], color='k', marker='', zorder=1)\n",
        "\n",
        "            for i, (clf, rank) in enumerate(average_ranks.items()):\n",
        "                ax.plot([rank], [0.1], 'o', markersize=10, label=clf)\n",
        "                ax.text(rank, 0.15 + (i % 2 * 0.1), clf, ha='center', va='bottom', fontsize=11)\n",
        "\n",
        "            sorted_ranks = average_ranks.sort_values()\n",
        "            for i in range(len(sorted_ranks)):\n",
        "                for j in range(i + 1, len(sorted_ranks)):\n",
        "                    if abs(sorted_ranks[i] - sorted_ranks[j]) <= critical_difference:\n",
        "                        ax.plot([sorted_ranks[i], sorted_ranks[j]], [0.1, 0.1], 'k-', linewidth=4, zorder=2)\n",
        "\n",
        "            ax.set_yticks([])\n",
        "            ax.set_xlabel('Ranking Médio', fontsize=12)\n",
        "            ax.set_title('Diagrama de Diferença Crítica para Comitês (Teste de Nemenyi, alpha=0.05)', fontsize=14)\n",
        "            ax.invert_xaxis()\n",
        "            ax.grid(axis='x', linestyle='--', alpha=0.6)\n",
        "            plt.ylim(0, 0.5)\n",
        "            plt.show()\n",
        "\n",
        "        else:\n",
        "            print(f\"\\nComo o P-valor ({p_value:.4f}) é > {alpha}, não há evidência de diferença estatística entre os comitês.\")\n",
        "\n",
        "    except KeyError:\n",
        "        print(\"ERRO: As colunas no arquivo CSV não correspondem ao esperado.\")\n",
        "else:\n",
        "    print(\"\\nO script não pode continuar porque a tabela de resultados não foi carregada.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "id": "cRkjVMXqz9x0",
        "outputId": "e0f19c10-2b7c-4a3d-f057-07ac42121f31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-posthocs in /usr/local/lib/python3.11/dist-packages (0.11.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from scikit-posthocs) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from scikit-posthocs) (1.15.3)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.11/dist-packages (from scikit-posthocs) (0.14.4)\n",
            "Requirement already satisfied: pandas>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from scikit-posthocs) (2.2.2)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (from scikit-posthocs) (0.13.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from scikit-posthocs) (3.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.20.0->scikit-posthocs) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.20.0->scikit-posthocs) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.20.0->scikit-posthocs) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->scikit-posthocs) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->scikit-posthocs) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->scikit-posthocs) (4.58.5)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->scikit-posthocs) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->scikit-posthocs) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->scikit-posthocs) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->scikit-posthocs) (3.2.3)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels->scikit-posthocs) (1.0.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=0.20.0->scikit-posthocs) (1.17.0)\n",
            "============================================================\n",
            "Faça o upload do arquivo 'resultados_melhores_comites.csv'\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f65f943f-b5e0-45fa-96b2-0745fca7bfe3\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f65f943f-b5e0-45fa-96b2-0745fca7bfe3\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving resultados_melhores_comites.csv to resultados_melhores_comites (3).csv\n",
            "\n",
            "ERRO: O arquivo 'resultados_melhores_comites.csv' não foi encontrado no upload.\n",
            "\n",
            "O script não pode continuar porque a tabela de resultados não foi carregada.\n"
          ]
        }
      ]
    }
  ]
}